2025-07-28 13:27:20 - Initializing model...
2025-07-28 13:27:41 - Model initialized successfully.
2025-07-28 13:27:41 - Processing folder: Culture and Art three(animal, country, relation, USAEnglish, English), testid: 0
Folder: Culture and Art three(animal, country, relation, USAEnglish, English)
TestID: 0
{
    "response": "Image 1: [a woman in a dark, moody setting, wearing a unique, possibly avant-garde outfit with a mix of textures and patterns, standing against a textured background]\nImage 2: [a majestic eagle in mid-flight, wings spread wide, clutching a fish in its talons, against a backdrop of water]\nImage 3: [a young girl sitting on a striped armchair, wearing a light purple t-shirt and a light blue skirt, with a neutral expression, against a backdrop of a teal curtain]\n\n**Image 4**: [a young girl sitting on a striped armchair, wearing a light purple t-shirt and a light blue skirt, with a neutral expression, against a backdrop of a teal curtain]\n\n**Relation**: Thematic Connection\n\n**Explanation**: Both Image 1 and Image 2 feature a central figure in a striking pose, with a focus on the subject's form and movement. Image 1 shows a woman in a dramatic, artistic setting, while Image 2 captures the dynamic motion of an eagle. Similarly, Image 3 and Image 4 both depict a young girl in a relaxed, seated position, with a consistent background that frames the subject. The thematic connection lies in the focus on the subject's presence and the use of contrasting backgrounds to highlight the figure."
}

2025-07-28 13:28:15 - Successfully processed folder: Culture and Art three(animal, country, relation, USAEnglish, English), testid: 0
2025-07-28 13:28:15 - Processing folder: Culture and Art three(animal, country, relation, USAEnglish, English), testid: 1
Folder: Culture and Art three(animal, country, relation, USAEnglish, English)
TestID: 1
{
    "response": "Image 1: [a bald eagle in mid-flight, wings spread wide, catching a fish in its talons]\nImage 2: [a woman in a dark, moody setting, wearing a unique, possibly avant-garde outfit]\nImage 3: [a small bird perched on a plant stem against a clear blue sky]\n\nImage 4: [a majestic bird of prey soaring high above a rugged landscape, wings outstretched]\n\nRelation: Nature and Wildlife\n\nExplanation: Both Image 1 and Image 4 depict birds in their natural environments, showcasing the beauty and power of wildlife. Image 1 captures a bald eagle in action, while Image 4 portrays a bird of prey in flight, emphasizing the theme of nature and the majesty of birds in their habitats."
}

2025-07-28 13:28:37 - Successfully processed folder: Culture and Art three(animal, country, relation, USAEnglish, English), testid: 1
2025-07-28 13:28:37 - Processing folder: Culture and Art three(animal, country, relation, USAEnglish, English), testid: 2
Folder: Culture and Art three(animal, country, relation, USAEnglish, English)
TestID: 2
{
    "response": "**Image 1**: A young girl sitting on a chair with a striped pattern.\n**Image 2**: A bird perched on a plant.\n**Image 3**: A woman standing in a dark setting with dramatic lighting.\n\n**Image 4**: A young girl sitting on a chair with a striped pattern.\n\n**Relation**: Similarity\n\n**Explanation**: Both Image 1 and Image 4 feature a young girl sitting on a chair with a striped pattern. The primary connection between these two images is the presence of the young girl and the striped chair, which creates a thematic link between the two."
}

2025-07-28 13:28:54 - Successfully processed folder: Culture and Art three(animal, country, relation, USAEnglish, English), testid: 2
2025-07-28 13:28:54 - Processing folder: Culture and Art three(animal, country, relation, USAEnglish, English), testid: 3
Folder: Culture and Art three(animal, country, relation, USAEnglish, English)
TestID: 3
{
    "response": "Image 1: [a bird perched on a branch]\nImage 2: [a young girl sitting on a chair]\nImage 3: [an eagle in flight]\nImage 4: [a young girl sitting on a branch]\n\nRelation: nature and human interaction\n\nExplanation: Both Image 1 and Image 4 feature a young girl interacting with nature. In Image 1, the bird is perched on a branch, while in Image 4, the girl is sitting on a branch. This connection highlights the theme of humans engaging with and being surrounded by nature."
}

2025-07-28 13:29:11 - Successfully processed folder: Culture and Art three(animal, country, relation, USAEnglish, English), testid: 3
2025-07-28 13:29:11 - Processing folder: Culture and Art four(animal, country, relation, USAEnglish, English), testid: 0
2025-07-28 13:29:11 - Error in generate_response: CUDA out of memory. Tried to allocate 4.10 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.82 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 32.89 GiB memory in use. Of the allocated memory 31.18 GiB is allocated by PyTorch, and 1.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 13:29:11 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.10 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.82 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 32.89 GiB memory in use. Of the allocated memory 31.18 GiB is allocated by PyTorch, and 1.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Culture and Art four(animal, country, relation, USAEnglish, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 13:29:11 - Error occurred for folder: Culture and Art four(animal, country, relation, USAEnglish, English), testid: 0. See logs for details.
2025-07-28 13:29:11 - Processing folder: Culture and Art four(animal, country, relation, USAEnglish, English), testid: 1
2025-07-28 13:29:11 - Error in generate_response: CUDA out of memory. Tried to allocate 3.77 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.82 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 32.89 GiB memory in use. Of the allocated memory 31.15 GiB is allocated by PyTorch, and 1.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 13:29:11 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.77 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.82 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 32.89 GiB memory in use. Of the allocated memory 31.15 GiB is allocated by PyTorch, and 1.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Culture and Art four(animal, country, relation, USAEnglish, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 13:29:11 - Error occurred for folder: Culture and Art four(animal, country, relation, USAEnglish, English), testid: 1. See logs for details.
2025-07-28 13:29:11 - Processing folder: Culture and Art four(animal, country, relation, USAEnglish, English), testid: 2
2025-07-28 13:29:12 - Error in generate_response: CUDA out of memory. Tried to allocate 3.21 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.83 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 32.88 GiB memory in use. Of the allocated memory 31.10 GiB is allocated by PyTorch, and 1.32 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 13:29:12 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.21 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.83 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 32.88 GiB memory in use. Of the allocated memory 31.10 GiB is allocated by PyTorch, and 1.32 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Culture and Art four(animal, country, relation, USAEnglish, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 13:29:12 - Error occurred for folder: Culture and Art four(animal, country, relation, USAEnglish, English), testid: 2. See logs for details.
2025-07-28 13:29:12 - Processing folder: Culture and Art four(animal, country, relation, USAEnglish, English), testid: 3
2025-07-28 13:29:12 - Error in generate_response: CUDA out of memory. Tried to allocate 474.00 MiB. GPU 0 has a total capacity of 47.40 GiB of which 417.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.30 GiB memory in use. Of the allocated memory 34.64 GiB is allocated by PyTorch, and 204.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 13:29:12 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 474.00 MiB. GPU 0 has a total capacity of 47.40 GiB of which 417.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.30 GiB memory in use. Of the allocated memory 34.64 GiB is allocated by PyTorch, and 204.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Culture and Art four(animal, country, relation, USAEnglish, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 13:29:12 - Error occurred for folder: Culture and Art four(animal, country, relation, USAEnglish, English), testid: 3. See logs for details.
2025-07-28 13:29:12 - Processing folder: Culture and Art five(animal, country, relation, USAEnglish, English), testid: 0
2025-07-28 13:29:12 - Error in generate_response: CUDA out of memory. Tried to allocate 2.45 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.67 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.04 GiB memory in use. Of the allocated memory 33.45 GiB is allocated by PyTorch, and 142.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 13:29:12 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.45 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.67 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.04 GiB memory in use. Of the allocated memory 33.45 GiB is allocated by PyTorch, and 142.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Culture and Art five(animal, country, relation, USAEnglish, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 13:29:12 - Error occurred for folder: Culture and Art five(animal, country, relation, USAEnglish, English), testid: 0. See logs for details.
2025-07-28 13:29:12 - Processing folder: Culture and Art five(animal, country, relation, USAEnglish, English), testid: 1
2025-07-28 13:29:12 - Error in generate_response: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.67 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.04 GiB memory in use. Of the allocated memory 33.35 GiB is allocated by PyTorch, and 238.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 13:29:12 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.67 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.04 GiB memory in use. Of the allocated memory 33.35 GiB is allocated by PyTorch, and 238.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Culture and Art five(animal, country, relation, USAEnglish, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 13:29:12 - Error occurred for folder: Culture and Art five(animal, country, relation, USAEnglish, English), testid: 1. See logs for details.
2025-07-28 13:29:12 - Processing folder: Culture and Art five(animal, country, relation, USAEnglish, English), testid: 2
2025-07-28 13:29:13 - Error in generate_response: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.67 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.04 GiB memory in use. Of the allocated memory 33.35 GiB is allocated by PyTorch, and 238.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 13:29:13 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.67 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.04 GiB memory in use. Of the allocated memory 33.35 GiB is allocated by PyTorch, and 238.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Culture and Art five(animal, country, relation, USAEnglish, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 13:29:13 - Error occurred for folder: Culture and Art five(animal, country, relation, USAEnglish, English), testid: 2. See logs for details.
2025-07-28 13:29:13 - Processing folder: Culture and Art five(animal, country, relation, USAEnglish, English), testid: 3
2025-07-28 13:29:13 - Error in generate_response: CUDA out of memory. Tried to allocate 2.88 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.24 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.47 GiB memory in use. Of the allocated memory 33.92 GiB is allocated by PyTorch, and 101.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 13:29:13 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.88 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.24 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.47 GiB memory in use. Of the allocated memory 33.92 GiB is allocated by PyTorch, and 101.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Culture and Art five(animal, country, relation, USAEnglish, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 13:29:13 - Error occurred for folder: Culture and Art five(animal, country, relation, USAEnglish, English), testid: 3. See logs for details.
2025-07-28 13:29:13 - Processing folder: Culture and Art six(animal, country, relation, USAEnglish, English), testid: 0
Folder: Culture and Art six(animal, country, relation, USAEnglish, English)
TestID: 0
{
    "response": "**Image 1**: A woman in a striking red and black striped dress poses on a red carpet, with a movie poster in the background.\n**Image 2**: A majestic bald eagle perched on a wooden post, set against a blurred natural backdrop.\n**Image 3**: A young girl in a green dress with a unique neckline and a decorative necklace, standing in a crowd.\n\n**Image 4**: A young girl in a striking green dress with a unique neckline and a decorative necklace, standing in a crowd.\n\n**Relation**: Similarity in attire and setting\n\n**Explanation**: Both Image 1 and Image 4 feature women in distinctive dresses posing on red carpets. The dresses in both images are eye-catching and have unique designs, suggesting a theme of fashion and public appearances. The presence of crowds and the red carpet setting in both images further emphasize the similarity in their contexts, highlighting the shared elements of style and public events."
}

2025-07-28 13:29:39 - Successfully processed folder: Culture and Art six(animal, country, relation, USAEnglish, English), testid: 0
2025-07-28 13:29:39 - Processing folder: Culture and Art six(animal, country, relation, USAEnglish, English), testid: 1
Folder: Culture and Art six(animal, country, relation, USAEnglish, English)
TestID: 1
{
    "response": "**Image 1**: [A majestic bald eagle perched on a wooden post, set against a blurred natural background]\n**Image 2**: [A woman in a striking red and black striped dress posing on a red carpet, with a movie poster in the background]\n**Image 3**: [A small bird with a grey head and white body perched on a thin branch amidst green foliage]\n\n**Image 4**: [A majestic bald eagle perched on a wooden post, set against a blurred natural background]\n**Relation**: Nature and Wildlife\n**Explanation**: Both Image 1 and Image 4 feature a bald eagle, emphasizing the theme of nature and wildlife. The eagle's presence in both images highlights the beauty and majesty of these creatures in their natural habitats."
}

2025-07-28 13:29:59 - Successfully processed folder: Culture and Art six(animal, country, relation, USAEnglish, English), testid: 1
2025-07-28 13:29:59 - Processing folder: Culture and Art six(animal, country, relation, USAEnglish, English), testid: 2
2025-07-28 13:29:59 - Error in generate_response: CUDA out of memory. Tried to allocate 1.45 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.24 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.47 GiB memory in use. Of the allocated memory 32.35 GiB is allocated by PyTorch, and 1.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 13:29:59 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.45 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.24 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.47 GiB memory in use. Of the allocated memory 32.35 GiB is allocated by PyTorch, and 1.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Culture and Art six(animal, country, relation, USAEnglish, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 13:29:59 - Error occurred for folder: Culture and Art six(animal, country, relation, USAEnglish, English), testid: 2. See logs for details.
2025-07-28 13:29:59 - Processing folder: Culture and Art six(animal, country, relation, USAEnglish, English), testid: 3
Folder: Culture and Art six(animal, country, relation, USAEnglish, English)
TestID: 3
{
    "response": "Image 1: [a gray bird with black and white wings perched on a branch]\nImage 2: [a young girl in a green dress]\nImage 3: [a bald eagle perched on a post]\nImage 4: [a young boy in a blue shirt perched on a branch]\n\nRelation: wildlife and nature\nExplanation: Both Image 1 and Image 3 depict animals in their natural environment, showcasing the beauty and majesty of wildlife. Similarly, Image 4 could be designed to feature a young boy in a natural setting, perhaps interacting with or observing wildlife, thus maintaining the theme of nature and the outdoors."
}

2025-07-28 13:30:15 - Successfully processed folder: Culture and Art six(animal, country, relation, USAEnglish, English), testid: 3
2025-07-28 13:30:15 - Processing folder: Culture and Art seven(animal, country, relation, USAEnglish, English), testid: 0
2025-07-28 13:30:16 - Error in generate_response: CUDA out of memory. Tried to allocate 1.66 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.24 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.47 GiB memory in use. Of the allocated memory 32.59 GiB is allocated by PyTorch, and 1.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 13:30:16 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.66 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.24 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.47 GiB memory in use. Of the allocated memory 32.59 GiB is allocated by PyTorch, and 1.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Culture and Art seven(animal, country, relation, USAEnglish, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 13:30:16 - Error occurred for folder: Culture and Art seven(animal, country, relation, USAEnglish, English), testid: 0. See logs for details.
2025-07-28 13:30:16 - Processing folder: Culture and Art seven(animal, country, relation, USAEnglish, English), testid: 1
Folder: Culture and Art seven(animal, country, relation, USAEnglish, English)
TestID: 1
{
    "response": "**Image 1**: [A majestic bald eagle soaring through the sky, its wings fully extended, showcasing its powerful flight capabilities.]\n**Image 2**: [A woman in a black dress standing on a stage, her arms crossed, exuding confidence and poise.]\n**Image 3**: [A bird perched on a branch, its wings spread wide as if ready to take flight, capturing a moment of stillness before action.]\n\n**Image 4**: [A majestic bald eagle soaring through the sky, its wings fully extended, showcasing its powerful flight capabilities.]\n\n**Relation**: [Flight and Power]\n\n**Explanation**: Both Image 1 and Image 4 depict birds in the midst of flight, emphasizing their strength and grace. The bald eagle in Image 1 and the bird in Image 4 are both captured in dynamic poses that highlight their ability to fly with power and precision. The theme of flight and power is consistent between the two images, showcasing the natural prowess of these birds."
}

2025-07-28 13:30:41 - Successfully processed folder: Culture and Art seven(animal, country, relation, USAEnglish, English), testid: 1
2025-07-28 13:30:41 - Processing folder: Culture and Art seven(animal, country, relation, USAEnglish, English), testid: 2
2025-07-28 13:30:41 - Error in generate_response: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.24 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.47 GiB memory in use. Of the allocated memory 32.73 GiB is allocated by PyTorch, and 1.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 13:30:41 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.24 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.47 GiB memory in use. Of the allocated memory 32.73 GiB is allocated by PyTorch, and 1.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Culture and Art seven(animal, country, relation, USAEnglish, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 13:30:41 - Error occurred for folder: Culture and Art seven(animal, country, relation, USAEnglish, English), testid: 2. See logs for details.
2025-07-28 13:30:41 - Processing folder: Culture and Art seven(animal, country, relation, USAEnglish, English), testid: 3
Folder: Culture and Art seven(animal, country, relation, USAEnglish, English)
TestID: 3
{
    "response": "### Image 1\n**Image Concept**: A bird perched on a branch with its wings spread wide, possibly preparing to take off.\n\n### Image 2\n**Image Concept**: A woman in an elegant dress walking on a red carpet, holding an umbrella in the rain.\n\n### Image 3\n**Image Concept**: A close-up of a bald eagle in flight, with its wings fully extended and a focused expression.\n\n### Image 4\n**Image Concept**: A close-up of a bird in flight, with its wings spread wide, possibly preparing to take off.\n\n### Relation\n**Keyword**: Flight\n\n### Explanation\nBoth Image 1 and Image 4 depict birds in the act of flying, with their wings fully extended. The focus is on the bird's wings and the dynamic motion of flight. Similarly, Image 3 shows a bald eagle in flight, emphasizing the bird's wings and the intensity of its flight. The common theme of flight connects these images, highlighting the grace and power of birds in motion."
}

2025-07-28 13:31:07 - Successfully processed folder: Culture and Art seven(animal, country, relation, USAEnglish, English), testid: 3
2025-07-28 13:31:07 - Processing folder: Culture and Art eight(animal, country, relation, USAEnglish, English), testid: 0
Folder: Culture and Art eight(animal, country, relation, USAEnglish, English)
TestID: 0
{
    "response": "Image 1: [a couple embracing each other in a field]\nImage 2: [a bald eagle in front of an American flag]\nImage 3: [a woman in a black dress sitting on a stool]\nImage 4: [a woman in a black dress sitting on a stool]\nRelation: elegance\nExplanation: Both Image 1 and Image 3 depict a sense of elegance and intimacy, with the couple and the woman in the dress both exuding a refined and graceful presence."
}

2025-07-28 13:31:23 - Successfully processed folder: Culture and Art eight(animal, country, relation, USAEnglish, English), testid: 0
2025-07-28 13:31:23 - Processing folder: Culture and Art eight(animal, country, relation, USAEnglish, English), testid: 1
Folder: Culture and Art eight(animal, country, relation, USAEnglish, English)
TestID: 1
{
    "response": "Image 1: [a majestic bald eagle with a white head and yellow beak, set against a backdrop of the American flag]\nImage 2: [a couple embracing each other in a field, with the woman leaning on the man's shoulder]\nImage 3: [a bird in flight, captured from below with its wings fully extended against a clear blue sky]\n\nImage 4: [a majestic bald eagle with a white head and yellow beak, set against a backdrop of a clear blue sky]\n\nRelation: Freedom\n\nExplanation: Both Image 1 and Image 4 feature a bald eagle, a symbol of freedom and strength, set against contrasting backgrounds that emphasize the eagle's majestic presence. Similarly, Image 3 captures the essence of freedom through the bird in flight, symbolizing the unbounded nature of the sky. The connection between these images lies in the theme of freedom, as each depicts a powerful and liberated creature in its natural element."
}

2025-07-28 13:31:48 - Successfully processed folder: Culture and Art eight(animal, country, relation, USAEnglish, English), testid: 1
2025-07-28 13:31:48 - Processing folder: Culture and Art eight(animal, country, relation, USAEnglish, English), testid: 2
Folder: Culture and Art eight(animal, country, relation, USAEnglish, English)
TestID: 2
{
    "response": "Image 1: [a woman in a black dress sitting on a stool]\nImage 2: [a bird flying in the sky]\nImage 3: [a couple embracing in a field]\nImage 4: [a couple embracing in a field]\nRelation: Emotion\nExplanation: Both Image 1 and Image 3 depict human subjects in emotionally charged poses, with Image 1 showing a woman in a contemplative pose and Image 3 showing a couple in an intimate embrace. The emotional connection is central to both images, highlighting human expressions and interactions."
}

2025-07-28 13:32:04 - Successfully processed folder: Culture and Art eight(animal, country, relation, USAEnglish, English), testid: 2
2025-07-28 13:32:04 - Processing folder: Culture and Art eight(animal, country, relation, USAEnglish, English), testid: 3
Folder: Culture and Art eight(animal, country, relation, USAEnglish, English)
TestID: 3
{
    "response": "Image 1: [a bird in flight with its wings fully extended]\nImage 2: [a woman in a black dress sitting on a stool]\nImage 3: [a bald eagle in front of an American flag]\nImage 4: [a bald eagle in flight with its wings fully extended]\n\nRelation: Freedom\nExplanation: Both Image 1 and Image 4 depict birds in flight, symbolizing freedom and the ability to soar. Similarly, Image 3 features a bald eagle, a national symbol of the United States, representing freedom and strength. The theme of freedom is thus consistent across all three images."
}

2025-07-28 13:32:22 - Successfully processed folder: Culture and Art eight(animal, country, relation, USAEnglish, English), testid: 3
2025-07-28 13:32:22 - Processing folder: Culture and Art nine(animal, country, relation, USAEnglish, English), testid: 0
2025-07-28 13:32:22 - Error in generate_response: CUDA out of memory. Tried to allocate 1.77 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.24 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.47 GiB memory in use. Of the allocated memory 32.70 GiB is allocated by PyTorch, and 1.32 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 13:32:22 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.77 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.24 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.47 GiB memory in use. Of the allocated memory 32.70 GiB is allocated by PyTorch, and 1.32 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Culture and Art nine(animal, country, relation, USAEnglish, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 13:32:22 - Error occurred for folder: Culture and Art nine(animal, country, relation, USAEnglish, English), testid: 0. See logs for details.
2025-07-28 13:32:22 - Processing folder: Culture and Art nine(animal, country, relation, USAEnglish, English), testid: 1
Folder: Culture and Art nine(animal, country, relation, USAEnglish, English)
TestID: 1
{
    "response": "Image 1: [close-up of an eagle's head]\nImage 2: [person in formal attire]\nImage 3: [small bird perched on a wire]\nImage 4: [a close-up of a small bird's head]\n\nRelation: Bird Focus\n\nExplanation: Both Image 1 and Image 3 feature close-ups of birds, emphasizing their heads and detailed features. The focus on the bird's head in both images highlights the intricate details and textures of the feathers and eyes, creating a thematic connection between the two images."
}

2025-07-28 13:32:38 - Successfully processed folder: Culture and Art nine(animal, country, relation, USAEnglish, English), testid: 1
2025-07-28 13:32:38 - Processing folder: Culture and Art nine(animal, country, relation, USAEnglish, English), testid: 2
2025-07-28 13:32:38 - Error in generate_response: CUDA out of memory. Tried to allocate 1.51 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.24 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.47 GiB memory in use. Of the allocated memory 32.42 GiB is allocated by PyTorch, and 1.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 13:32:38 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.51 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.24 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.47 GiB memory in use. Of the allocated memory 32.42 GiB is allocated by PyTorch, and 1.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Culture and Art nine(animal, country, relation, USAEnglish, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 13:32:38 - Error occurred for folder: Culture and Art nine(animal, country, relation, USAEnglish, English), testid: 2. See logs for details.
2025-07-28 13:32:38 - Processing folder: Culture and Art nine(animal, country, relation, USAEnglish, English), testid: 3
Folder: Culture and Art nine(animal, country, relation, USAEnglish, English)
TestID: 3
{
    "response": "Image 1: [a small bird with grey feathers and black-tipped wings standing on a wire]\nImage 2: [a woman in a beige dress walking on a stage]\nImage 3: [a close-up of a bird of prey with a sharp beak and intense eyes]\n\nImage 4: [a close-up of a bird with detailed feathers and a sharp beak]\nRelation: avian\nExplanation: Both Image 1 and Image 3 feature birds, with Image 1 showing a small bird on a wire and Image 3 providing a close-up of a bird of prey. Image 4, mirroring Image 3, also focuses on a bird's detailed features, emphasizing the theme of avian subjects."
}

2025-07-28 13:33:00 - Successfully processed folder: Culture and Art nine(animal, country, relation, USAEnglish, English), testid: 3
2025-07-28 13:33:00 - Processing folder: Culture and Art ten(animal, country, relation, USAEnglish, English), testid: 0
Folder: Culture and Art ten(animal, country, relation, USAEnglish, English)
TestID: 0
{
    "response": "**Image 1**: A person wearing a white t-shirt and blue jeans, posing confidently with one hand on their head and the other on their hip. They are wearing sunglasses and a necklace, standing in front of a vehicle with the number \"10\" visible.\n\n**Image 2**: A bald eagle perched on a tree branch, looking to the side with a focused expression. The eagle has a white head and tail, with dark brown feathers on its body and wings.\n\n**Image 3**: A woman with long hair, wearing a patterned shirt, standing among a group of people in a dimly lit setting. She appears to be looking forward with a serious expression.\n\n**Image 4**: A person wearing a white t-shirt and blue jeans, posing confidently with one hand on their head and the other on their hip. They are wearing sunglasses and a necklace, standing in front of a vehicle with the number \"10\" visible.\n\n**Relation**: Both images feature a person in a white t-shirt and blue jeans, posing confidently with one hand on their head and the other on their hip, wearing sunglasses and a necklace, standing in front of a vehicle with the number \"10\" visible.\n\n**Explanation**: The connection between the images is that both feature a person in a similar pose and attire, with the number \"10\" visible in the background, suggesting a thematic or stylistic link between the two."
}

2025-07-28 13:33:37 - Successfully processed folder: Culture and Art ten(animal, country, relation, USAEnglish, English), testid: 0
2025-07-28 13:33:37 - Processing folder: Culture and Art ten(animal, country, relation, USAEnglish, English), testid: 1
2025-07-28 13:33:38 - Error in generate_response: CUDA out of memory. Tried to allocate 1.52 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.24 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.47 GiB memory in use. Of the allocated memory 32.42 GiB is allocated by PyTorch, and 1.59 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 13:33:38 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.52 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.24 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.47 GiB memory in use. Of the allocated memory 32.42 GiB is allocated by PyTorch, and 1.59 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Culture and Art ten(animal, country, relation, USAEnglish, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 13:33:38 - Error occurred for folder: Culture and Art ten(animal, country, relation, USAEnglish, English), testid: 1. See logs for details.
2025-07-28 13:33:38 - Processing folder: Culture and Art ten(animal, country, relation, USAEnglish, English), testid: 2
2025-07-28 13:33:39 - Error in generate_response: CUDA out of memory. Tried to allocate 1.84 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.24 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.47 GiB memory in use. Of the allocated memory 32.79 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 13:33:39 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.84 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.24 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.47 GiB memory in use. Of the allocated memory 32.79 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Culture and Art ten(animal, country, relation, USAEnglish, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 13:33:39 - Error occurred for folder: Culture and Art ten(animal, country, relation, USAEnglish, English), testid: 2. See logs for details.
2025-07-28 13:33:39 - Processing folder: Culture and Art ten(animal, country, relation, USAEnglish, English), testid: 3
Folder: Culture and Art ten(animal, country, relation, USAEnglish, English)
TestID: 3
{
    "response": "Image 1: A small gray bird with a long tail and black beak perched on a branch.\nImage 2: A woman with long hair wearing a patterned shirt, standing in a crowd.\nImage 3: A bald eagle with a white head and yellow beak, perched on a branch.\nImage 4: A small gray bird with a long tail and black beak perched on a branch.\n\nRelation: Birds\nExplanation: Both Image 1 and Image 4 feature a small gray bird with a long tail and black beak perched on a branch. The primary connection between these images is the presence of the bird, which is the central element in both. The bird's appearance, including its gray color and long tail, is consistent across both images, highlighting a shared theme of avian subjects."
}

2025-07-28 13:34:03 - Successfully processed folder: Culture and Art ten(animal, country, relation, USAEnglish, English), testid: 3
2025-07-28 13:34:03 - Processing folder: Culture and Art eleven(animal, country, relation, USAEnglish, English), testid: 0
2025-07-28 13:34:04 - Error in generate_response: CUDA out of memory. Tried to allocate 1.92 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.24 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.47 GiB memory in use. Of the allocated memory 32.87 GiB is allocated by PyTorch, and 1.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 13:34:04 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.92 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.24 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.47 GiB memory in use. Of the allocated memory 32.87 GiB is allocated by PyTorch, and 1.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Culture and Art eleven(animal, country, relation, USAEnglish, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 13:34:04 - Error occurred for folder: Culture and Art eleven(animal, country, relation, USAEnglish, English), testid: 0. See logs for details.
2025-07-28 13:34:04 - Processing folder: Culture and Art eleven(animal, country, relation, USAEnglish, English), testid: 1
Folder: Culture and Art eleven(animal, country, relation, USAEnglish, English)
TestID: 1
{
    "response": "1. **Image 1**: A close-up of a bald eagle's head, showcasing its white feathers and sharp yellow beak against a black background.\n2. **Image 2**: A photograph of two people, a man and a woman, dressed in formal attire at a public event, with a crowd and a pink sign in the background.\n3. **Image 3**: A bird perched on a tree branch, with a blurred green background, displaying its gray and white plumage.\n\n**Image 4**: A close-up of a bird's head, showcasing its white feathers and sharp yellow beak against a black background.\n\n**Relation**: Both images feature a close-up of a bird's head with a black background.\n\n**Explanation**: Both Image 1 and Image 4 focus on the head of a bird, highlighting its features against a dark backdrop. The bald eagle in Image 1 and the bird in Image 4 both have distinct white feathers and yellow beaks, creating a visual similarity between the two images."
}

2025-07-28 13:34:35 - Successfully processed folder: Culture and Art eleven(animal, country, relation, USAEnglish, English), testid: 1
2025-07-28 13:34:35 - Processing folder: Culture and Art eleven(animal, country, relation, USAEnglish, English), testid: 2
2025-07-28 13:34:35 - Error in generate_response: CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.24 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.47 GiB memory in use. Of the allocated memory 32.62 GiB is allocated by PyTorch, and 1.40 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 13:34:35 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.24 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.47 GiB memory in use. Of the allocated memory 32.62 GiB is allocated by PyTorch, and 1.40 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Culture and Art eleven(animal, country, relation, USAEnglish, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 13:34:35 - Error occurred for folder: Culture and Art eleven(animal, country, relation, USAEnglish, English), testid: 2. See logs for details.
2025-07-28 13:34:35 - Processing folder: Culture and Art eleven(animal, country, relation, USAEnglish, English), testid: 3
Folder: Culture and Art eleven(animal, country, relation, USAEnglish, English)
TestID: 3
{
    "response": "**Image 1**: A bird perched on a branch.\n**Image 2**: A group of people standing together.\n**Image 3**: A close-up of a bald eagle's head.\n\n**Image 1** and **Image 2** both depict groups of living beings in natural or social settings. The bird in **Image 1** is in a natural environment, while the people in **Image 2** are in a social setting. Both images capture the essence of life and interaction within their respective contexts.\n\n**Image 3** is a close-up of a bald eagle, similar to **Image 1** in that it features a single, prominent subject. Both images focus on detailed, singular subjects, highlighting the beauty and intricacy of nature.\n\n**Image 4**: A close-up of a parrot perched on a branch.\n\n**Relation**: Nature and Wildlife\n\n**Explanation**: Both **Image 1** and **Image 3** feature close-up shots of birds in their natural habitats, emphasizing the beauty and detail of wildlife. Similarly, **Image 4** also focuses on a bird, maintaining the theme of nature and wildlife."
}

2025-07-28 13:35:08 - Successfully processed folder: Culture and Art eleven(animal, country, relation, USAEnglish, English), testid: 3
2025-07-28 13:35:08 - Processing folder: Culture and Art twelve(animal, country, relation, USAEnglish, English), testid: 0
Folder: Culture and Art twelve(animal, country, relation, USAEnglish, English)
TestID: 0
{
    "response": "1. **Image 1**: The image shows a woman in a gray shirt interacting with another person in a forest setting. Her expressions change from neutral to smiling.\n   **Image 2**: The image depicts two bald eagles perched on a wooden post against a blue sky.\n   **Image 3**: The image shows two people sitting on the floor surrounded by photographs, engaged in a discussion in a warmly lit room.\n\n2. **Analysis**:\n   - Both **Image 1** and **Image 2** feature interactions between two individuals, one of whom is facing the camera.\n   - **Image 1** has a natural, outdoor setting, while **Image 2** has a clear, open sky.\n   - Both images capture moments of connection, whether through facial expressions or body language.\n\n3. **Image 4**: The image shows two people sitting on the floor in a warmly lit room, surrounded by photographs, engaged in a discussion. One person is pointing at a photograph, and the other is looking at it attentively.\n\n4. **Relation**: Connection\n   - **Explanation**: Both pairs of images depict interactions between two individuals in different settingsone in a natural environment and the other in a cozy indoor space. The shared theme is the connection and engagement between the individuals, whether through facial expressions, body language, or shared focus on photographs."
}

2025-07-28 13:35:45 - Successfully processed folder: Culture and Art twelve(animal, country, relation, USAEnglish, English), testid: 0
2025-07-28 13:35:45 - Processing folder: Culture and Art twelve(animal, country, relation, USAEnglish, English), testid: 1
Folder: Culture and Art twelve(animal, country, relation, USAEnglish, English)
TestID: 1
{
    "response": "Image 1: [two bald eagles perched on a wooden post against a blue sky]\nImage 2: [a woman with dark hair in a forest setting]\nImage 3: [a bird in flight with its wings spread wide against a blue sky]\n\nImage 4: [a bird in flight with its wings spread wide against a blue sky]\nRelation: Both images depict birds in flight.\nExplanation: Both images feature birds in flight, with Image 1 showing two bald eagles perched on a post and Image 3 showing a bird with its wings spread wide. The common element of birds in flight connects these images, emphasizing the theme of avian grace and freedom."
}

2025-07-28 13:36:03 - Successfully processed folder: Culture and Art twelve(animal, country, relation, USAEnglish, English), testid: 1
2025-07-28 13:36:03 - Processing folder: Culture and Art twelve(animal, country, relation, USAEnglish, English), testid: 2
Folder: Culture and Art twelve(animal, country, relation, USAEnglish, English)
TestID: 2
{
    "response": "Image 1: [two people sitting on the floor looking at photographs]\nImage 2: [a bird in flight]\nImage 3: [a woman in a gray shirt]\nImage 4: [a woman in a gray shirt]\n\nRelation: Similarity\nExplanation: Both Image 1 and Image 3 feature a person in a gray shirt, suggesting a thematic or stylistic connection between the two images."
}

2025-07-28 13:36:17 - Successfully processed folder: Culture and Art twelve(animal, country, relation, USAEnglish, English), testid: 2
2025-07-28 13:36:17 - Processing folder: Culture and Art twelve(animal, country, relation, USAEnglish, English), testid: 3
Folder: Culture and Art twelve(animal, country, relation, USAEnglish, English)
TestID: 3
{
    "response": "**Image 1**: A bird in mid-flight with its wings fully extended, showcasing detailed feather patterns against a clear blue sky.\n\n**Image 2**: Two people sitting on the floor, surrounded by photographs and documents, engaged in a discussion in a warmly lit room.\n\n**Image 3**: Two bald eagles perched side by side on a wooden post, with their white heads and yellow beaks prominently visible against a blue sky.\n\n**Image 4**: A pair of birds in mid-flight, with their wings fully extended, showcasing detailed feather patterns against a clear blue sky.\n\n**Relation**: Both images depict birds in flight.\n\n**Explanation**: Both Image 1 and Image 4 feature birds with their wings fully extended, highlighting the intricate details of their feathers against a clear blue sky. This similarity in the depiction of birds in flight creates a thematic connection between the two images."
}

2025-07-28 13:36:40 - Successfully processed folder: Culture and Art twelve(animal, country, relation, USAEnglish, English), testid: 3
2025-07-28 13:36:40 - Processing folder: Culture and Art thirteen(animal, country, relation, USAEnglish, English), testid: 0
2025-07-28 13:36:40 - Error in generate_response: CUDA out of memory. Tried to allocate 1.54 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.23 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.48 GiB memory in use. Of the allocated memory 32.45 GiB is allocated by PyTorch, and 1.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 13:36:40 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.54 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.23 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.48 GiB memory in use. Of the allocated memory 32.45 GiB is allocated by PyTorch, and 1.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Culture and Art thirteen(animal, country, relation, USAEnglish, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 13:36:40 - Error occurred for folder: Culture and Art thirteen(animal, country, relation, USAEnglish, English), testid: 0. See logs for details.
2025-07-28 13:36:40 - Processing folder: Culture and Art thirteen(animal, country, relation, USAEnglish, English), testid: 1
Folder: Culture and Art thirteen(animal, country, relation, USAEnglish, English)
TestID: 1
{
    "response": "Image 1: A majestic eagle soaring through the sky with its wings fully extended, showcasing its impressive wingspan and powerful flight.\nImage 2: A woman in a sparkling silver dress walking on a red carpet, waving to the crowd, surrounded by photographers.\nImage 3: A small bird perched on a branch, with its feathers neatly arranged and a serene green background.\n\nImage 4: A majestic eagle soaring through the sky with its wings fully extended, showcasing its impressive wingspan and powerful flight.\n\nRelation: Nature vs. Human Culture\n\nExplanation: Both Image 1 and Image 4 depict majestic birds in flight, emphasizing the beauty and power of nature. Image 2, on the other hand, contrasts this by showing a woman in a glamorous setting, representing human culture and fashion. The connection between the images highlights the contrast between the natural world and human society."
}

2025-07-28 13:37:04 - Successfully processed folder: Culture and Art thirteen(animal, country, relation, USAEnglish, English), testid: 1
2025-07-28 13:37:04 - Processing folder: Culture and Art thirteen(animal, country, relation, USAEnglish, English), testid: 2
2025-07-28 13:37:05 - Error in generate_response: CUDA out of memory. Tried to allocate 1.66 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.23 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.48 GiB memory in use. Of the allocated memory 32.58 GiB is allocated by PyTorch, and 1.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 13:37:05 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.66 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.23 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.48 GiB memory in use. Of the allocated memory 32.58 GiB is allocated by PyTorch, and 1.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Culture and Art thirteen(animal, country, relation, USAEnglish, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 13:37:05 - Error occurred for folder: Culture and Art thirteen(animal, country, relation, USAEnglish, English), testid: 2. See logs for details.
2025-07-28 13:37:05 - Processing folder: Culture and Art thirteen(animal, country, relation, USAEnglish, English), testid: 3
Folder: Culture and Art thirteen(animal, country, relation, USAEnglish, English)
TestID: 3
{
    "response": "Image 1: [a bird with grey feathers and a white belly perched on a branch]\nImage 2: [a woman with brown hair in a black dress]\nImage 3: [a bald eagle soaring with its wings spread wide]\nImage 4: [a bald eagle soaring with its wings spread wide]\nRelation: bird\nExplanation: Both Image 1 and Image 3 feature birds, with Image 1 showing a small bird perched on a branch and Image 3 depicting a majestic bald eagle in flight. The connection is established through the shared theme of birds, highlighting their natural beauty and grace."
}

2025-07-28 13:37:22 - Successfully processed folder: Culture and Art thirteen(animal, country, relation, USAEnglish, English), testid: 3
2025-07-28 13:37:22 - Processing folder: Culture and Art fourteen(animal, country, relation, USAEnglish, English), testid: 0
2025-07-28 13:37:22 - Error in generate_response: CUDA out of memory. Tried to allocate 4.21 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.23 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.48 GiB memory in use. Of the allocated memory 31.19 GiB is allocated by PyTorch, and 2.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 13:37:22 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.21 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.23 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.48 GiB memory in use. Of the allocated memory 31.19 GiB is allocated by PyTorch, and 2.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Culture and Art fourteen(animal, country, relation, USAEnglish, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 13:37:22 - Error occurred for folder: Culture and Art fourteen(animal, country, relation, USAEnglish, English), testid: 0. See logs for details.
2025-07-28 13:37:22 - Processing folder: Culture and Art fourteen(animal, country, relation, USAEnglish, English), testid: 1
2025-07-28 13:37:23 - Error in generate_response: CUDA out of memory. Tried to allocate 6.37 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.32 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.39 GiB memory in use. Of the allocated memory 31.37 GiB is allocated by PyTorch, and 2.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 13:37:23 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 6.37 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.32 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.39 GiB memory in use. Of the allocated memory 31.37 GiB is allocated by PyTorch, and 2.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Culture and Art fourteen(animal, country, relation, USAEnglish, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 13:37:23 - Error occurred for folder: Culture and Art fourteen(animal, country, relation, USAEnglish, English), testid: 1. See logs for details.
2025-07-28 13:37:23 - Processing folder: Culture and Art fourteen(animal, country, relation, USAEnglish, English), testid: 2
2025-07-28 13:37:24 - Error in generate_response: CUDA out of memory. Tried to allocate 4.68 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.32 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.39 GiB memory in use. Of the allocated memory 31.23 GiB is allocated by PyTorch, and 2.70 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 13:37:24 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.68 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.32 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.39 GiB memory in use. Of the allocated memory 31.23 GiB is allocated by PyTorch, and 2.70 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Culture and Art fourteen(animal, country, relation, USAEnglish, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 13:37:24 - Error occurred for folder: Culture and Art fourteen(animal, country, relation, USAEnglish, English), testid: 2. See logs for details.
2025-07-28 13:37:24 - Processing folder: Culture and Art fourteen(animal, country, relation, USAEnglish, English), testid: 3
2025-07-28 13:37:25 - Error in generate_response: CUDA out of memory. Tried to allocate 6.42 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.32 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.39 GiB memory in use. Of the allocated memory 31.38 GiB is allocated by PyTorch, and 2.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 13:37:25 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 6.42 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.32 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.39 GiB memory in use. Of the allocated memory 31.38 GiB is allocated by PyTorch, and 2.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Culture and Art fourteen(animal, country, relation, USAEnglish, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 13:37:25 - Error occurred for folder: Culture and Art fourteen(animal, country, relation, USAEnglish, English), testid: 3. See logs for details.
2025-07-28 13:37:25 - Processing folder: Culture and Art fifthteen(animal, country, relation, USAEnglish, English), testid: 0
2025-07-28 13:37:26 - Error in generate_response: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.32 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.39 GiB memory in use. Of the allocated memory 31.07 GiB is allocated by PyTorch, and 2.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 13:37:26 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.32 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.39 GiB memory in use. Of the allocated memory 31.07 GiB is allocated by PyTorch, and 2.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Culture and Art fifthteen(animal, country, relation, USAEnglish, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 13:37:26 - Error occurred for folder: Culture and Art fifthteen(animal, country, relation, USAEnglish, English), testid: 0. See logs for details.
2025-07-28 13:37:26 - Processing folder: Culture and Art fifthteen(animal, country, relation, USAEnglish, English), testid: 1
2025-07-28 13:37:27 - Error in generate_response: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.32 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.39 GiB memory in use. Of the allocated memory 32.93 GiB is allocated by PyTorch, and 1023.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 13:37:27 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.32 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.39 GiB memory in use. Of the allocated memory 32.93 GiB is allocated by PyTorch, and 1023.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Culture and Art fifthteen(animal, country, relation, USAEnglish, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 13:37:27 - Error occurred for folder: Culture and Art fifthteen(animal, country, relation, USAEnglish, English), testid: 1. See logs for details.
2025-07-28 13:37:27 - Processing folder: Culture and Art fifthteen(animal, country, relation, USAEnglish, English), testid: 2
2025-07-28 13:37:28 - Error in generate_response: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.32 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.39 GiB memory in use. Of the allocated memory 32.90 GiB is allocated by PyTorch, and 1.04 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 13:37:28 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.32 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.39 GiB memory in use. Of the allocated memory 32.90 GiB is allocated by PyTorch, and 1.04 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Culture and Art fifthteen(animal, country, relation, USAEnglish, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 13:37:28 - Error occurred for folder: Culture and Art fifthteen(animal, country, relation, USAEnglish, English), testid: 2. See logs for details.
2025-07-28 13:37:28 - Processing folder: Culture and Art fifthteen(animal, country, relation, USAEnglish, English), testid: 3
2025-07-28 13:37:29 - Error in generate_response: CUDA out of memory. Tried to allocate 1.97 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.32 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.39 GiB memory in use. Of the allocated memory 32.92 GiB is allocated by PyTorch, and 1.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 13:37:29 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.97 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.32 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.39 GiB memory in use. Of the allocated memory 32.92 GiB is allocated by PyTorch, and 1.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Culture and Art fifthteen(animal, country, relation, USAEnglish, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 13:37:29 - Error occurred for folder: Culture and Art fifthteen(animal, country, relation, USAEnglish, English), testid: 3. See logs for details.
2025-07-28 13:37:29 - Processing folder: Animals and City(animal, city, relation, East Asia, English), testid: 0
2025-07-28 13:37:30 - Error in generate_response: CUDA out of memory. Tried to allocate 3.45 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.32 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.39 GiB memory in use. Of the allocated memory 31.13 GiB is allocated by PyTorch, and 2.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 13:37:30 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.45 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.32 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.39 GiB memory in use. Of the allocated memory 31.13 GiB is allocated by PyTorch, and 2.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Animals and City(animal, city, relation, East Asia, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 13:37:30 - Error occurred for folder: Animals and City(animal, city, relation, East Asia, English), testid: 0. See logs for details.
2025-07-28 13:37:30 - Processing folder: Animals and City(animal, city, relation, East Asia, English), testid: 1
2025-07-28 13:37:31 - Error in generate_response: CUDA out of memory. Tried to allocate 3.45 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.32 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.39 GiB memory in use. Of the allocated memory 31.13 GiB is allocated by PyTorch, and 2.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 13:37:31 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.45 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.32 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.39 GiB memory in use. Of the allocated memory 31.13 GiB is allocated by PyTorch, and 2.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Animals and City(animal, city, relation, East Asia, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 13:37:31 - Error occurred for folder: Animals and City(animal, city, relation, East Asia, English), testid: 1. See logs for details.
2025-07-28 13:37:31 - Processing folder: Animals and City(animal, city, relation, East Asia, English), testid: 2
2025-07-28 13:37:32 - Error in generate_response: CUDA out of memory. Tried to allocate 1.86 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.32 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.39 GiB memory in use. Of the allocated memory 32.81 GiB is allocated by PyTorch, and 1.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 13:37:32 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.86 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.32 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.39 GiB memory in use. Of the allocated memory 32.81 GiB is allocated by PyTorch, and 1.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Animals and City(animal, city, relation, East Asia, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 13:37:32 - Error occurred for folder: Animals and City(animal, city, relation, East Asia, English), testid: 2. See logs for details.
2025-07-28 13:37:32 - Processing folder: Animals and City(animal, city, relation, East Asia, English), testid: 3
2025-07-28 13:37:32 - Error in generate_response: CUDA out of memory. Tried to allocate 4.91 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.32 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.39 GiB memory in use. Of the allocated memory 31.25 GiB is allocated by PyTorch, and 2.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 13:37:32 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.91 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.32 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.39 GiB memory in use. Of the allocated memory 31.25 GiB is allocated by PyTorch, and 2.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Animals and City(animal, city, relation, East Asia, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 13:37:32 - Error occurred for folder: Animals and City(animal, city, relation, East Asia, English), testid: 3. See logs for details.
2025-07-28 13:37:33 - Processing folder: Culture and Art sixteen(animal, country, relation, USAEnglish, English), testid: 0
Folder: Culture and Art sixteen(animal, country, relation, USAEnglish, English)
TestID: 0
{
    "response": "Image 1: [a woman in a floral dress and high heels posing in front of a promotional backdrop]\nImage 2: [a close-up of a bald eagle]\nImage 3: [a woman in a black coat and denim shorts walking on a sidewalk]\n\n**Image 4**: [a close-up of a majestic lion with a golden mane]\n\n**Relation**: wildlife and nature\n\n**Explanation**: Both Image 1 and Image 2 feature subjects that are closely related to nature and wildlife. Image 1 shows a woman in a floral dress, which could be seen as a representation of nature's beauty, while Image 2 features a bald eagle, a symbol of strength and freedom in the natural world. Image 3, on the other hand, shows a woman walking in an urban setting, which contrasts with the natural elements in Images 1 and 2. Image 4, which features a majestic lion, continues the theme of wildlife and nature, creating a connection between all three images."
}

2025-07-28 13:38:02 - Successfully processed folder: Culture and Art sixteen(animal, country, relation, USAEnglish, English), testid: 0
2025-07-28 13:38:02 - Processing folder: Culture and Art sixteen(animal, country, relation, USAEnglish, English), testid: 1
Folder: Culture and Art sixteen(animal, country, relation, USAEnglish, English)
TestID: 1
{
    "response": "Image 1: [A majestic bald eagle with a white head and sharp yellow beak, looking to the side]\nImage 2: [A woman in a floral dress and bright orange heels posing in front of a promotional backdrop]\nImage 3: [A small bird with a gray head and black-tipped wings perched on a wooden post]\n\n**Relation**: Both images feature animals and humans in a poised and elegant manner.\n\n**Explanation**: Both Image 1 and Image 3 depict animals in a poised and elegant manner, similar to how Image 2 presents the woman. The eagle in Image 1 and the bird in Image 3 are both captured in a way that highlights their natural beauty and grace, much like the woman in Image 2 who is elegantly dressed and posed."
}

2025-07-28 13:38:23 - Successfully processed folder: Culture and Art sixteen(animal, country, relation, USAEnglish, English), testid: 1
2025-07-28 13:38:23 - Processing folder: Culture and Art sixteen(animal, country, relation, USAEnglish, English), testid: 2
Folder: Culture and Art sixteen(animal, country, relation, USAEnglish, English)
TestID: 2
{
    "response": "Image 1: A woman walking outdoors, dressed in a black jacket and denim shorts, holding a coffee cup.\nImage 2: A bird perched on a wooden surface, with a blurred natural background.\nImage 3: A woman standing in front of a promotional backdrop, wearing a floral dress and bright orange heels.\n\n**Image 4**: A bird perched on a wooden surface, with a blurred natural background.\n\n**Relation**: Nature and Wildlife\n\n**Explanation**: Both Image 1 and Image 2 feature elements of nature and wildlife. Image 1 shows a woman walking outdoors, which can be associated with the natural environment, while Image 2 directly depicts a bird in a natural setting. Image 4 mirrors this connection by featuring a bird in a natural environment, similar to Image 2."
}

2025-07-28 13:38:48 - Successfully processed folder: Culture and Art sixteen(animal, country, relation, USAEnglish, English), testid: 2
2025-07-28 13:38:48 - Processing folder: Culture and Art sixteen(animal, country, relation, USAEnglish, English), testid: 3
Folder: Culture and Art sixteen(animal, country, relation, USAEnglish, English)
TestID: 3
{
    "response": "Image 1: [a bird with grey and white feathers perched on a wooden post]\nImage 2: [a woman wearing a black jacket and denim shorts walking on a sidewalk]\nImage 3: [a bald eagle with a white head and yellow beak]\nImage 4: [a bird with grey and white feathers perched on a wooden post]\nRelation: wildlife\nExplanation: Both Image 1 and Image 3 depict birds in natural settings, showcasing their distinct features and environments."
}

2025-07-28 13:39:04 - Successfully processed folder: Culture and Art sixteen(animal, country, relation, USAEnglish, English), testid: 3
2025-07-28 13:39:04 - Processing folder: Specific Habitat Preferences and Their Climate Patterns(animal, city, relation, East Asia, English), testid: 0
2025-07-28 13:39:05 - Error in generate_response: CUDA out of memory. Tried to allocate 4.82 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.32 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.39 GiB memory in use. Of the allocated memory 31.25 GiB is allocated by PyTorch, and 2.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 13:39:05 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.82 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.32 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.39 GiB memory in use. Of the allocated memory 31.25 GiB is allocated by PyTorch, and 2.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Specific Habitat Preferences and Their Climate Patterns(animal, city, relation, East Asia, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 13:39:05 - Error occurred for folder: Specific Habitat Preferences and Their Climate Patterns(animal, city, relation, East Asia, English), testid: 0. See logs for details.
2025-07-28 13:39:05 - Processing folder: Specific Habitat Preferences and Their Climate Patterns(animal, city, relation, East Asia, English), testid: 1
2025-07-28 13:39:06 - Error in generate_response: CUDA out of memory. Tried to allocate 3.34 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.32 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.39 GiB memory in use. Of the allocated memory 31.12 GiB is allocated by PyTorch, and 2.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 13:39:06 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.34 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.32 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.39 GiB memory in use. Of the allocated memory 31.12 GiB is allocated by PyTorch, and 2.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Specific Habitat Preferences and Their Climate Patterns(animal, city, relation, East Asia, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 13:39:06 - Error occurred for folder: Specific Habitat Preferences and Their Climate Patterns(animal, city, relation, East Asia, English), testid: 1. See logs for details.
2025-07-28 13:39:06 - Processing folder: Specific Habitat Preferences and Their Climate Patterns(animal, city, relation, East Asia, English), testid: 2
2025-07-28 13:39:07 - Error in generate_response: CUDA out of memory. Tried to allocate 1.77 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.32 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.39 GiB memory in use. Of the allocated memory 32.70 GiB is allocated by PyTorch, and 1.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 13:39:07 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.77 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.32 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.39 GiB memory in use. Of the allocated memory 32.70 GiB is allocated by PyTorch, and 1.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Specific Habitat Preferences and Their Climate Patterns(animal, city, relation, East Asia, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 13:39:07 - Error occurred for folder: Specific Habitat Preferences and Their Climate Patterns(animal, city, relation, East Asia, English), testid: 2. See logs for details.
2025-07-28 13:39:07 - Processing folder: Specific Habitat Preferences and Their Climate Patterns(animal, city, relation, East Asia, English), testid: 3
2025-07-28 13:39:08 - Error in generate_response: CUDA out of memory. Tried to allocate 3.36 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.32 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.39 GiB memory in use. Of the allocated memory 31.12 GiB is allocated by PyTorch, and 2.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 13:39:08 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.36 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.32 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.39 GiB memory in use. Of the allocated memory 31.12 GiB is allocated by PyTorch, and 2.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Specific Habitat Preferences and Their Climate Patterns(animal, city, relation, East Asia, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 13:39:08 - Error occurred for folder: Specific Habitat Preferences and Their Climate Patterns(animal, city, relation, East Asia, English), testid: 3. See logs for details.
2025-07-28 13:39:08 - Processing folder: Cultural Representation of Endangered Species from China(animal, people, relation, East Asia, English), testid: 0
Folder: Cultural Representation of Endangered Species from China(animal, people, relation, East Asia, English)
TestID: 0
{
    "response": "Image 1: A snow leopard walking in the snow.\nImage 2: A woman in a black dress.\nImage 3: A panda bear.\nImage 4: A panda bear.\nRelation: Wildlife\nExplanation: Both Image 1 and Image 3 feature animals in natural settings, showcasing the beauty and majesty of wildlife."
}

2025-07-28 13:39:19 - Successfully processed folder: Cultural Representation of Endangered Species from China(animal, people, relation, East Asia, English), testid: 0
2025-07-28 13:39:19 - Processing folder: Cultural Representation of Endangered Species from China(animal, people, relation, East Asia, English), testid: 1
2025-07-28 13:39:20 - Error in generate_response: CUDA out of memory. Tried to allocate 2.11 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.32 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.39 GiB memory in use. Of the allocated memory 33.08 GiB is allocated by PyTorch, and 873.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 13:39:20 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.11 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.32 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.39 GiB memory in use. Of the allocated memory 33.08 GiB is allocated by PyTorch, and 873.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Representation of Endangered Species from China(animal, people, relation, East Asia, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 13:39:20 - Error occurred for folder: Cultural Representation of Endangered Species from China(animal, people, relation, East Asia, English), testid: 1. See logs for details.
2025-07-28 13:39:20 - Processing folder: Cultural Representation of Endangered Species from China(animal, people, relation, East Asia, English), testid: 2
2025-07-28 13:39:20 - Error in generate_response: CUDA out of memory. Tried to allocate 1.49 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.32 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.39 GiB memory in use. Of the allocated memory 32.40 GiB is allocated by PyTorch, and 1.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 13:39:20 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.49 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.32 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.39 GiB memory in use. Of the allocated memory 32.40 GiB is allocated by PyTorch, and 1.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Representation of Endangered Species from China(animal, people, relation, East Asia, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 13:39:20 - Error occurred for folder: Cultural Representation of Endangered Species from China(animal, people, relation, East Asia, English), testid: 2. See logs for details.
2025-07-28 13:39:20 - Processing folder: Cultural Representation of Endangered Species from China(animal, people, relation, East Asia, English), testid: 3
Folder: Cultural Representation of Endangered Species from China(animal, people, relation, East Asia, English)
TestID: 3
{
    "response": "1. **Image 1**: A woman in an elaborate floral dress with a flower crown, posing on a red carpet with photographers in the background.\n2. **Image 2**: A close-up of a panda bear resting its head on a rock, with a natural, blurred background.\n3. **Image 3**: A woman in a black dress with a high slit and a choker necklace, standing against a backdrop with text.\n\n**Relation**: Fashion and Elegance\n\n**Explanation**: Both Image 1 and Image 3 feature women dressed in elegant attire, with Image 1 showcasing a floral dress and Image 3 featuring a sophisticated black dress. The presence of photographers in Image 1 and the formal setting in Image 3 suggest a connection to fashion and high-profile events, emphasizing the theme of elegance and style."
}

2025-07-28 13:39:43 - Successfully processed folder: Cultural Representation of Endangered Species from China(animal, people, relation, East Asia, English), testid: 3
2025-07-28 13:39:43 - Error opening image ./img/Geographical Origin of Celebrities and Their Associated Climate Patterns(city, people, relation, East Asia, English)/A precipitation map of Urumqi.jpg: cannot identify image file '/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/img/Geographical Origin of Celebrities and Their Associated Climate Patterns(city, people, relation, East Asia, English)/A precipitation map of Urumqi.jpg'
2025-07-28 13:39:43 - Error opening image ./img/Geographical Origin of Celebrities and Their Associated Climate Patterns(city, people, relation, East Asia, English)/A precipitation map of Beijing.jpg: cannot identify image file '/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/img/Geographical Origin of Celebrities and Their Associated Climate Patterns(city, people, relation, East Asia, English)/A precipitation map of Beijing.jpg'
2025-07-28 13:39:43 - Four valid images are required for processing.
2025-07-28 13:39:43 - Processing folder: Geographical Significance(city, country, metaphor, East Asia, English), testid: 0
2025-07-28 13:39:44 - Error in generate_response: CUDA out of memory. Tried to allocate 2.16 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.32 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.39 GiB memory in use. Of the allocated memory 33.13 GiB is allocated by PyTorch, and 825.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 13:39:44 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.16 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.32 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.39 GiB memory in use. Of the allocated memory 33.13 GiB is allocated by PyTorch, and 825.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Geographical Significance(city, country, metaphor, East Asia, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 13:39:44 - Error occurred for folder: Geographical Significance(city, country, metaphor, East Asia, English), testid: 0. See logs for details.
2025-07-28 13:39:44 - Processing folder: Geographical Significance(city, country, metaphor, East Asia, English), testid: 1
Folder: Geographical Significance(city, country, metaphor, East Asia, English)
TestID: 1
{
    "response": "### Image 1\n**Image 1** consists of a series of maps of China, each representing data from a different year between 2001 and 2008. The maps use a color gradient to indicate varying levels of a certain metric, likely related to environmental or demographic factors. The colors range from red (high values) to blue (low values), with green indicating intermediate values. Each map is labeled with the corresponding year, allowing for a visual comparison of changes over time.\n\n### Image 2\n**Image 2** is a painting depicting a traditional Chinese architectural structure, likely a temple or palace, set against a vibrant, abstract sky. The sky is composed of various shades of blue and green, creating a dynamic and somewhat impressionistic effect. The building is rendered in warm tones, with orange and yellow hues, and is surrounded by trees and a reflective surface, possibly water, in the foreground.\n\n### Image 3\n**Image 3** is a map of China showing population density. The map uses a color gradient to represent different population densities, with red indicating the highest density and yellow indicating the lowest. Major cities and provincial capitals are marked with stars, and the map includes a legend explaining the color coding. The map also features a line labeled \"Hu Huanyong Line,\" which divides the country into two distinct population density regions.\n\n### Image 4\n**Image 4** is a map of China with a similar color gradient to Image 3, representing population density. The map includes major cities and provincial capitals marked with stars, and a legend explaining the color coding. The map also features a line labeled \"Hu Huanyong Line,\" dividing the country into two distinct population density regions. The map is designed to visually represent population density data, similar to Image 3.\n\n### Relation\n**Relation**: Both Image 3 and Image 4 are maps of China that visually represent population density using a color gradient. They both include major cities and provincial capitals marked with stars and a legend explaining the color coding. The maps also feature the \"Hu Huanyong Line,\" which divides the country into two distinct population density regions.\n\n### Explanation\nBoth Image 3 and Image 4 are designed to visually represent population density data in China. They use a color gradient to indicate different levels of population density, with red representing the highest density and yellow representing the lowest. Both maps include major cities and provincial capitals marked with stars and a legend explaining the"
}

2025-07-28 13:40:50 - Successfully processed folder: Geographical Significance(city, country, metaphor, East Asia, English), testid: 1
2025-07-28 13:40:50 - Processing folder: Geographical Significance(city, country, metaphor, East Asia, English), testid: 2
2025-07-28 13:40:51 - Error in generate_response: CUDA out of memory. Tried to allocate 1.92 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.32 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.39 GiB memory in use. Of the allocated memory 32.87 GiB is allocated by PyTorch, and 1.07 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 13:40:51 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.92 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.32 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.39 GiB memory in use. Of the allocated memory 32.87 GiB is allocated by PyTorch, and 1.07 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Geographical Significance(city, country, metaphor, East Asia, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 13:40:51 - Error occurred for folder: Geographical Significance(city, country, metaphor, East Asia, English), testid: 2. See logs for details.
2025-07-28 13:40:51 - Processing folder: Geographical Significance(city, country, metaphor, East Asia, English), testid: 3
Folder: Geographical Significance(city, country, metaphor, East Asia, English)
TestID: 3
{
    "response": "### Image 1\n**Image Concept**: Population Density Map of China\n- The map illustrates the population density across China, with varying colors indicating different density levels. The map is marked with major cities and provincial capitals, and it includes the \"Hu Huanyong Line,\" which divides the country into two distinct population zones.\n\n### Image 2\n**Image Concept**: The Great Wall of China\n- This image depicts a scenic view of the Great Wall of China during sunset. The wall stretches across the landscape, with the sun setting in the background, casting a warm glow over the ancient structure and the surrounding mountains.\n\n### Image 3\n**Image Concept**: Climate Data Maps of China (2001-2008)\n- The image consists of a series of maps showing climate data for China from 2001 to 2008. Each map is labeled with the corresponding year, and the maps use a color gradient to represent different climate conditions across the country.\n\n### Image 4\n**Image Concept**: Climate Data Maps of China (2001-2008) with Population Density Overlay\n- This image combines the climate data maps from Image 3 with an overlay of the population density map from Image 1. The maps are arranged in the same grid format, with each climate map now featuring the population density data from the corresponding year.\n\n### Relation\n**Keyword**: Overlaid Data\n\n### Explanation\n- **Image 1** provides a detailed map of population density in China, highlighting the distribution of people across different regions.\n- **Image 2** offers a picturesque view of the Great Wall of China, emphasizing the country's historical and cultural significance.\n- **Image 3** presents a series of climate data maps for China from 2001 to 2008, showing variations in climate conditions over the years.\n- **Image 4** merges the climate data maps from Image 3 with the population density map from Image 1, creating a comprehensive visual representation that links climate conditions with population distribution across China from 2001 to 2008. This overlay allows for an analysis of how climate and population density might correlate or influence each other over time."
}

2025-07-28 13:41:46 - Successfully processed folder: Geographical Significance(city, country, metaphor, East Asia, English), testid: 3
2025-07-28 13:41:46 - Processing folder: Cultural Significance and Population Centers(city, country, metaphor, East Asia, English), testid: 0
2025-07-28 13:41:46 - Error in generate_response: CUDA out of memory. Tried to allocate 2.88 GiB. GPU 0 has a total capacity of 47.40 GiB of which 995.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.74 GiB memory in use. Of the allocated memory 33.93 GiB is allocated by PyTorch, and 358.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 13:41:46 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.88 GiB. GPU 0 has a total capacity of 47.40 GiB of which 995.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.74 GiB memory in use. Of the allocated memory 33.93 GiB is allocated by PyTorch, and 358.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Significance and Population Centers(city, country, metaphor, East Asia, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 13:41:46 - Error occurred for folder: Cultural Significance and Population Centers(city, country, metaphor, East Asia, English), testid: 0. See logs for details.
2025-07-28 13:41:46 - Processing folder: Cultural Significance and Population Centers(city, country, metaphor, East Asia, English), testid: 1
2025-07-28 13:41:46 - Error in generate_response: CUDA out of memory. Tried to allocate 2.79 GiB. GPU 0 has a total capacity of 47.40 GiB of which 995.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.74 GiB memory in use. Of the allocated memory 33.82 GiB is allocated by PyTorch, and 465.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 13:41:46 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.79 GiB. GPU 0 has a total capacity of 47.40 GiB of which 995.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.74 GiB memory in use. Of the allocated memory 33.82 GiB is allocated by PyTorch, and 465.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Significance and Population Centers(city, country, metaphor, East Asia, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 13:41:46 - Error occurred for folder: Cultural Significance and Population Centers(city, country, metaphor, East Asia, English), testid: 1. See logs for details.
2025-07-28 13:41:46 - Processing folder: Cultural Significance and Population Centers(city, country, metaphor, East Asia, English), testid: 2
2025-07-28 13:41:46 - Error in generate_response: CUDA out of memory. Tried to allocate 2.85 GiB. GPU 0 has a total capacity of 47.40 GiB of which 995.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.74 GiB memory in use. Of the allocated memory 33.89 GiB is allocated by PyTorch, and 396.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 13:41:46 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.85 GiB. GPU 0 has a total capacity of 47.40 GiB of which 995.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.74 GiB memory in use. Of the allocated memory 33.89 GiB is allocated by PyTorch, and 396.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Significance and Population Centers(city, country, metaphor, East Asia, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 13:41:46 - Error occurred for folder: Cultural Significance and Population Centers(city, country, metaphor, East Asia, English), testid: 2. See logs for details.
2025-07-28 13:41:46 - Processing folder: Cultural Significance and Population Centers(city, country, metaphor, East Asia, English), testid: 3
2025-07-28 13:41:47 - Error in generate_response: CUDA out of memory. Tried to allocate 2.82 GiB. GPU 0 has a total capacity of 47.40 GiB of which 995.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.74 GiB memory in use. Of the allocated memory 33.86 GiB is allocated by PyTorch, and 432.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 13:41:47 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.82 GiB. GPU 0 has a total capacity of 47.40 GiB of which 995.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.74 GiB memory in use. Of the allocated memory 33.86 GiB is allocated by PyTorch, and 432.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Significance and Population Centers(city, country, metaphor, East Asia, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 13:41:47 - Error occurred for folder: Cultural Significance and Population Centers(city, country, metaphor, East Asia, English), testid: 3. See logs for details.
2025-07-28 13:41:47 - Processing folder: Cultural Symbolism and Environmental Influences(animal, country, metaphor, East Asia, English), testid: 0
Folder: Cultural Symbolism and Environmental Influences(animal, country, metaphor, East Asia, English)
TestID: 0
{
    "response": "### Image 1\n**Image Concept**: A traditional Japanese Oni mask with a red umbrella.\n\n### Image 2\n**Image Concept**: A weather forecast map of Japan showing temperature variations.\n\n### Image 3\n**Image Concept**: A traditional Japanese Shinto shrine entrance with a torii gate.\n\n### Image 4\n**Image Concept**: A weather forecast map of Japan showing temperature variations.\n\n### Relation\n**Connection**: Weather Forecast\n\n### Explanation\nBoth Image 2 and Image 4 depict weather forecast maps of Japan, focusing on temperature variations across different regions. Image 2 shows a detailed forecast for a specific period, while Image 4 appears to be a more general map indicating temperature zones. The connection between the two images is the focus on weather and temperature data for Japan."
}

2025-07-28 13:42:09 - Successfully processed folder: Cultural Symbolism and Environmental Influences(animal, country, metaphor, East Asia, English), testid: 0
2025-07-28 13:42:09 - Processing folder: Cultural Symbolism and Environmental Influences(animal, country, metaphor, East Asia, English), testid: 1
2025-07-28 13:42:10 - Error in generate_response: CUDA out of memory. Tried to allocate 1.52 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.31 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.40 GiB memory in use. Of the allocated memory 32.43 GiB is allocated by PyTorch, and 1.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 13:42:10 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.52 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.31 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.40 GiB memory in use. Of the allocated memory 32.43 GiB is allocated by PyTorch, and 1.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Symbolism and Environmental Influences(animal, country, metaphor, East Asia, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 13:42:10 - Error occurred for folder: Cultural Symbolism and Environmental Influences(animal, country, metaphor, East Asia, English), testid: 1. See logs for details.
2025-07-28 13:42:10 - Processing folder: Cultural Symbolism and Environmental Influences(animal, country, metaphor, East Asia, English), testid: 2
2025-07-28 13:42:11 - Error in generate_response: CUDA out of memory. Tried to allocate 1.52 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.31 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.40 GiB memory in use. Of the allocated memory 32.43 GiB is allocated by PyTorch, and 1.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 13:42:11 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.52 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.31 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.40 GiB memory in use. Of the allocated memory 32.43 GiB is allocated by PyTorch, and 1.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Symbolism and Environmental Influences(animal, country, metaphor, East Asia, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 13:42:11 - Error occurred for folder: Cultural Symbolism and Environmental Influences(animal, country, metaphor, East Asia, English), testid: 2. See logs for details.
2025-07-28 13:42:11 - Processing folder: Cultural Symbolism and Environmental Influences(animal, country, metaphor, East Asia, English), testid: 3
Folder: Cultural Symbolism and Environmental Influences(animal, country, metaphor, East Asia, English)
TestID: 3
{
    "response": "### Image 1\n**Image Concept**: This is a colorful illustration representing the twelve months of the year in Japan, each month depicted with a unique cultural or seasonal symbol.\n\n### Image 2\n**Image Concept**: This is a photograph of a traditional Japanese shrine, featuring a torii gate and a small shrine building, surrounded by lush greenery.\n\n### Image 3\n**Image Concept**: This is a weather forecast map of Japan, showing temperature variations across the country for a two-week period.\n\n### Image 4\n**Image Concept**: This is a colorful illustration representing the twelve months of the year in Japan, each month depicted with a unique cultural or seasonal symbol.\n\n### Relation\n**Connection**: Cultural and Seasonal Representation\n\n### Explanation\nBoth Image 1 and Image 4 are representations of the twelve months of the year in Japan, each month depicted with unique cultural or seasonal symbols. Similarly, Image 2 and Image 4 both feature elements of Japanese culture and nature, with Image 2 showing a traditional Japanese shrine and Image 4 depicting cultural symbols for each month. The connection between these pairs lies in their celebration of Japanese culture and seasonal changes."
}

2025-07-28 13:42:44 - Successfully processed folder: Cultural Symbolism and Environmental Influences(animal, country, metaphor, East Asia, English), testid: 3
2025-07-28 13:42:44 - Error opening image ./img/Cultural Roots and Historical Influence(animal, country, metaphor, East Asia, English)/A historical map depicting the Warring States situation in Japan.jpg: cannot identify image file '/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/img/Cultural Roots and Historical Influence(animal, country, metaphor, East Asia, English)/A historical map depicting the Warring States situation in Japan.jpg'
2025-07-28 13:42:44 - Four valid images are required for processing.
2025-07-28 13:42:44 - Processing folder: Cultural Symbols and Urban Infrastructure(animal, city, metaphor, East Asia, English), testid: 0
2025-07-28 13:42:44 - Error in generate_response: CUDA out of memory. Tried to allocate 1.68 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.31 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.40 GiB memory in use. Of the allocated memory 32.61 GiB is allocated by PyTorch, and 1.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 13:42:44 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.68 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.31 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.40 GiB memory in use. Of the allocated memory 32.61 GiB is allocated by PyTorch, and 1.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Symbols and Urban Infrastructure(animal, city, metaphor, East Asia, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 13:42:44 - Error occurred for folder: Cultural Symbols and Urban Infrastructure(animal, city, metaphor, East Asia, English), testid: 0. See logs for details.
2025-07-28 13:42:44 - Processing folder: Cultural Symbols and Urban Infrastructure(animal, city, metaphor, East Asia, English), testid: 1
2025-07-28 13:42:44 - Error in generate_response: CUDA out of memory. Tried to allocate 1.68 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.31 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.40 GiB memory in use. Of the allocated memory 32.61 GiB is allocated by PyTorch, and 1.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 13:42:44 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.68 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.31 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.40 GiB memory in use. Of the allocated memory 32.61 GiB is allocated by PyTorch, and 1.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Symbols and Urban Infrastructure(animal, city, metaphor, East Asia, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 13:42:44 - Error occurred for folder: Cultural Symbols and Urban Infrastructure(animal, city, metaphor, East Asia, English), testid: 1. See logs for details.
2025-07-28 13:42:44 - Processing folder: Cultural Symbols and Urban Infrastructure(animal, city, metaphor, East Asia, English), testid: 2
2025-07-28 13:42:44 - Error in generate_response: CUDA out of memory. Tried to allocate 2.79 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.31 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.40 GiB memory in use. Of the allocated memory 33.82 GiB is allocated by PyTorch, and 123.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 13:42:44 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.79 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.31 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.40 GiB memory in use. Of the allocated memory 33.82 GiB is allocated by PyTorch, and 123.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Symbols and Urban Infrastructure(animal, city, metaphor, East Asia, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 13:42:44 - Error occurred for folder: Cultural Symbols and Urban Infrastructure(animal, city, metaphor, East Asia, English), testid: 2. See logs for details.
2025-07-28 13:42:44 - Processing folder: Cultural Symbols and Urban Infrastructure(animal, city, metaphor, East Asia, English), testid: 3
2025-07-28 13:42:45 - Error in generate_response: CUDA out of memory. Tried to allocate 1.68 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.31 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.40 GiB memory in use. Of the allocated memory 32.61 GiB is allocated by PyTorch, and 1.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 13:42:45 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.68 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.31 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.40 GiB memory in use. Of the allocated memory 32.61 GiB is allocated by PyTorch, and 1.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Symbols and Urban Infrastructure(animal, city, metaphor, East Asia, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 13:42:45 - Error occurred for folder: Cultural Symbols and Urban Infrastructure(animal, city, metaphor, East Asia, English), testid: 3. See logs for details.
2025-07-28 13:42:45 - Processing folder: Cultural Symbols and Historical Contexts(animal, country, metaphor, East Asia, English), testid: 0
2025-07-28 13:42:46 - Error in generate_response: CUDA out of memory. Tried to allocate 1.78 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.31 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.40 GiB memory in use. Of the allocated memory 32.71 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 13:42:46 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.78 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.31 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.40 GiB memory in use. Of the allocated memory 32.71 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Symbols and Historical Contexts(animal, country, metaphor, East Asia, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 13:42:46 - Error occurred for folder: Cultural Symbols and Historical Contexts(animal, country, metaphor, East Asia, English), testid: 0. See logs for details.
2025-07-28 13:42:46 - Processing folder: Cultural Symbols and Historical Contexts(animal, country, metaphor, East Asia, English), testid: 1
Folder: Cultural Symbols and Historical Contexts(animal, country, metaphor, East Asia, English)
TestID: 1
{
    "response": "### Image 1\n**Image Concept**: A panda bear resting on a rock, with a calm and serene expression.\n\n### Image 2\n**Image Concept**: A historical map of the Tang Dynasty, showcasing its geographical extent and key cities.\n\n### Image 3\n**Image Concept**: A traditional Japanese katana sword, displayed against a black background.\n\n### Image 4\n**Image Concept**: A traditional Japanese katana sword, displayed against a black background.\n\n### Relation\n**Keyword**: Cultural Heritage\n\n### Explanation\nBoth Image 1 and Image 2 represent significant aspects of cultural heritage. Image 1 features a panda, an iconic symbol of Chinese wildlife and conservation efforts, while Image 2 showcases a historical map of the Tang Dynasty, highlighting China's rich history and geographical significance. Similarly, Image 3 and Image 4 both depict traditional Japanese katana swords, emphasizing Japan's martial arts and cultural history. The connection between Image 1 and Image 2 is the shared theme of cultural heritage, and the connection between Image 3 and Image 4 is also the shared theme of cultural heritage, focusing on Japan's martial arts and historical artifacts."
}

2025-07-28 13:43:15 - Successfully processed folder: Cultural Symbols and Historical Contexts(animal, country, metaphor, East Asia, English), testid: 1
2025-07-28 13:43:15 - Processing folder: Cultural Symbols and Historical Contexts(animal, country, metaphor, East Asia, English), testid: 2
2025-07-28 13:43:16 - Error in generate_response: CUDA out of memory. Tried to allocate 1.73 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.31 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.40 GiB memory in use. Of the allocated memory 32.66 GiB is allocated by PyTorch, and 1.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 13:43:16 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.73 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.31 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.40 GiB memory in use. Of the allocated memory 32.66 GiB is allocated by PyTorch, and 1.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Symbols and Historical Contexts(animal, country, metaphor, East Asia, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 13:43:16 - Error occurred for folder: Cultural Symbols and Historical Contexts(animal, country, metaphor, East Asia, English), testid: 2. See logs for details.
2025-07-28 13:43:16 - Processing folder: Cultural Symbols and Historical Contexts(animal, country, metaphor, East Asia, English), testid: 3
Folder: Cultural Symbols and Historical Contexts(animal, country, metaphor, East Asia, English)
TestID: 3
{
    "response": "### Image 1\n**Image 1**: A traditional Japanese katana sword with a black scabbard and intricate handle design, set against a dark background.\n\n### Image 2\n**Image 2**: A colorful map of Japan during the Sengoku period, showing various daimyo territories and routes, with illustrations of samurai and ships.\n\n### Image 3\n**Image 3**: A close-up of a panda bear resting its head on a rock, with a natural, blurred background.\n\n### Image 4\n**Image 4**: A traditional Japanese katana sword with a black scabbard and intricate handle design, set against a dark background.\n\n### Relation\n**Relation**: Historical and Cultural\n\n### Explanation\nBoth Image 1 and Image 4 feature a traditional Japanese katana sword, emphasizing the cultural and historical significance of the weapon. Similarly, Image 2 and Image 3 both depict elements of Japanese history and culture. Image 2 shows the Sengoku period with its detailed map and illustrations, while Image 3 captures the serene and natural beauty of a panda, which is an iconic symbol of wildlife and conservation efforts. The connection between these pairs highlights the rich tapestry of Japanese heritage, from its martial history to its natural wonders."
}

2025-07-28 13:43:51 - Successfully processed folder: Cultural Symbols and Historical Contexts(animal, country, metaphor, East Asia, English), testid: 3
2025-07-28 13:43:51 - Processing folder: Cultural Icons and National Significance two(animal, country, metaphor, East Asia, English), testid: 0
Folder: Cultural Icons and National Significance two(animal, country, metaphor, East Asia, English)
TestID: 0
{
    "response": "### Image 1\n**Image Concept**: A warrior in ornate armor, wielding a staff, set against a dark, smoky background. The character appears to be in a dynamic pose, suggesting action or combat.\n\n### Image 2\n**Image Concept**: A group of people with bicycles standing in front of a large Chinese flag. The scene includes a soldier saluting the flag, with a backdrop of a significant Chinese landmark, likely the Forbidden City.\n\n### Image 3\n**Image Concept**: A character with spiky, golden hair, wearing a blue and orange outfit, set against a simple, light background. The character has a determined expression and a muscular build.\n\n### Image 4\n**Image Concept**: A character with spiky, golden hair, wearing a blue and orange outfit, set against a simple, light background. The character has a determined expression and a muscular build.\n\n### Relation\n**Keyword**: Super Saiyan\n\n### Explanation\nBoth Image 3 and Image 4 feature a character with spiky, golden hair, wearing a blue and orange outfit, and set against a simple, light background. The character in both images has a determined expression and a muscular build, indicating a shared theme of power and intensity. The term \"Super Saiyan\" is used to describe the transformation of the character in both images, highlighting the connection between them."
}

2025-07-28 13:44:28 - Successfully processed folder: Cultural Icons and National Significance two(animal, country, metaphor, East Asia, English), testid: 0
2025-07-28 13:44:28 - Processing folder: Cultural Icons and National Significance two(animal, country, metaphor, East Asia, English), testid: 1
Folder: Cultural Icons and National Significance two(animal, country, metaphor, East Asia, English)
TestID: 1
{
    "response": "Image 1: [a group of people standing in front of a large red flag with a yellow star, with a soldier saluting in the background]\nImage 2: [a warrior in ornate armor, wielding a staff, against a dark, smoky backdrop]\nImage 3: [a towering structure illuminated at night, with intricate lighting patterns]\n\nImage 4: [a group of people standing in front of a large red flag with a yellow star, with a soldier saluting in the background]\nRelation: [similarity]\nExplanation: Both Image 1 and Image 4 depict a group of people standing in front of a large red flag with a yellow star, with a soldier saluting in the background. The main difference is that Image 1 is a cartoon illustration, while Image 4 is a photograph. The shared elements of the red flag, yellow star, and saluting soldier create a thematic connection between the two images."
}

2025-07-28 13:44:54 - Successfully processed folder: Cultural Icons and National Significance two(animal, country, metaphor, East Asia, English), testid: 1
2025-07-28 13:44:54 - Processing folder: Cultural Icons and National Significance two(animal, country, metaphor, East Asia, English), testid: 2
Folder: Cultural Icons and National Significance two(animal, country, metaphor, East Asia, English)
TestID: 2
{
    "response": "Image 1: [a character with spiky golden hair, wearing an orange and blue outfit, with a determined expression]\nImage 2: [a tall, illuminated tower with a lattice structure, lit up at night]\nImage 3: [a warrior in ornate armor, wielding a staff, with a flowing red cape]\nImage 4: [a warrior in ornate armor, wielding a staff, with a flowing red cape]\n\nRelation: Contrast\n\nExplanation: Both Image 1 and Image 3 feature characters with spiky hair and determined expressions, suggesting a theme of strength and resolve. Image 2, on the other hand, contrasts with its depiction of a towering structure at night, emphasizing architectural grandeur and the passage of time. The connection between Image 1 and Image 2 lies in their focus on powerful, iconic figures, while Image 3 introduces a different kind of strength and heroism, marked by the warrior's dynamic pose and the dramatic setting."
}

2025-07-28 13:45:21 - Successfully processed folder: Cultural Icons and National Significance two(animal, country, metaphor, East Asia, English), testid: 2
2025-07-28 13:45:21 - Processing folder: Cultural Icons and National Significance two(animal, country, metaphor, East Asia, English), testid: 3
Folder: Cultural Icons and National Significance two(animal, country, metaphor, East Asia, English)
TestID: 3
{
    "response": "Image 1: [Tokyo Tower at night]\nImage 2: [Super Saiyan character]\nImage 3: [People with bicycles in front of a flag]\nImage 4: [A group of people with bicycles in front of a flag]\n\nRelation: Cultural landmarks and iconic symbols\nExplanation: Both Image 1 and Image 3 feature iconic landmarks or symbols that are significant to their respective cultures. Tokyo Tower is a famous landmark in Japan, while the flag and the group of people with bicycles could represent a national or cultural event. Image 2, while not a landmark, represents a cultural phenomenon through the character from Dragon Ball, which is a significant part of Japanese pop culture. The connection between the images is the representation of cultural identity and landmarks that are recognized and celebrated within their communities."
}

2025-07-28 13:45:44 - Successfully processed folder: Cultural Icons and National Significance two(animal, country, metaphor, East Asia, English), testid: 3
2025-07-28 13:45:44 - Processing folder: Cultural Icons and Endangered Species two(people, animal, metaphor, East Asia, English), testid: 0
Folder: Cultural Icons and Endangered Species two(people, animal, metaphor, East Asia, English)
TestID: 0
{
    "response": "**Image 1**: A woman blowing a bubble with gum, wearing sunglasses and a flower crown.\n**Image 2**: A snow leopard lying in the snow, looking directly at the camera.\n**Image 3**: A man in a black suit holding a bouquet of flowers.\n\n**Image 1** and **Image 2** both feature individuals in a relaxed pose, with **Image 1** showing a playful and casual demeanor, while **Image 2** captures a serene and majestic moment with the snow leopard. The common theme is the juxtaposition of human-like behavior in animals, creating a sense of connection and harmony.\n\n**Image 3** and **Image 2** both feature individuals in formal attire, with **Image 3** showing a man in a suit holding flowers, and **Image 2** showcasing a snow leopard in a natural setting. The connection is the formal and composed nature of both subjects, despite the different contexts.\n\n**Image 4**: A woman in a white dress holding a bouquet of flowers, standing in a garden.\n\n**Relation**: Formal and composed\n**Explanation**: Both **Image 3** and **Image 4** feature individuals in formal attire, with **Image 3** showing a man in a suit and **Image 4** depicting a woman in a white dress. The connection is the formal and composed nature of both subjects, despite the different contexts."
}

2025-07-28 13:46:21 - Successfully processed folder: Cultural Icons and Endangered Species two(people, animal, metaphor, East Asia, English), testid: 0
2025-07-28 13:46:21 - Processing folder: Cultural Icons and Endangered Species two(people, animal, metaphor, East Asia, English), testid: 1
Folder: Cultural Icons and Endangered Species two(people, animal, metaphor, East Asia, English)
TestID: 1
{
    "response": "Image 1: [a snow leopard resting in the snow]\nImage 2: [a woman blowing a bubble with a flower headband]\nImage 3: [two cranes interacting in a snowy landscape]\nImage 4: [a woman wearing a flower headband and blowing a bubble]\nRelation: wildlife\nExplanation: Both Image 1 and Image 3 depict animals in their natural habitat, showcasing the beauty and behavior of wildlife. Image 2 and Image 4 both feature a woman with a flower headband, highlighting a human element that connects the two pairs."
}

2025-07-28 13:46:38 - Successfully processed folder: Cultural Icons and Endangered Species two(people, animal, metaphor, East Asia, English), testid: 1
2025-07-28 13:46:38 - Processing folder: Cultural Icons and Endangered Species two(people, animal, metaphor, East Asia, English), testid: 2
Folder: Cultural Icons and Endangered Species two(people, animal, metaphor, East Asia, English)
TestID: 2
{
    "response": "**Image 1**: [a man in a black suit holding a bouquet of flowers]\n**Image 2**: [two cranes in a snowy landscape]\n**Image 3**: [a woman in a white dress blowing a bubble with gum]\n**Image 4**: [a woman in a white dress blowing a bubble with gum]\n\n**Relation**: contrast\n\n**Explanation**: Both Image 1 and Image 2 feature a single subject, while Image 3 features a single subject as well. The contrast lies in the subjects' activities and settings: Image 1 and Image 2 depict formal and natural scenes, respectively, whereas Image 3 shows a playful and casual moment."
}

2025-07-28 13:46:56 - Successfully processed folder: Cultural Icons and Endangered Species two(people, animal, metaphor, East Asia, English), testid: 2
2025-07-28 13:46:56 - Processing folder: Cultural Icons and Endangered Species two(people, animal, metaphor, East Asia, English), testid: 3
Folder: Cultural Icons and Endangered Species two(people, animal, metaphor, East Asia, English)
TestID: 3
{
    "response": "**Image 1**: [two cranes interacting in a snowy landscape]\n**Image 2**: [a man holding a bouquet of flowers]\n**Image 3**: [a snow leopard lying in the snow]\n**Image 4**: [a person holding a bouquet of flowers]\n\n**Relation**: Nature and wildlife\n\n**Explanation**: Both Image 1 and Image 3 depict animals in their natural habitats, showcasing interactions and serene moments in the wild. Similarly, Image 2 and Image 4 both feature humans holding bouquets, suggesting a theme of human interaction with nature and the appreciation of natural beauty."
}

2025-07-28 13:47:13 - Successfully processed folder: Cultural Icons and Endangered Species two(people, animal, metaphor, East Asia, English), testid: 3
2025-07-28 13:47:13 - Processing folder: Cultural Icons and National Significance three(animal, country, metaphor, East Asia, English), testid: 0
2025-07-28 13:47:14 - Error in generate_response: CUDA out of memory. Tried to allocate 1.70 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.31 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.40 GiB memory in use. Of the allocated memory 32.63 GiB is allocated by PyTorch, and 1.32 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 13:47:14 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.70 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.31 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.40 GiB memory in use. Of the allocated memory 32.63 GiB is allocated by PyTorch, and 1.32 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Icons and National Significance three(animal, country, metaphor, East Asia, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 13:47:14 - Error occurred for folder: Cultural Icons and National Significance three(animal, country, metaphor, East Asia, English), testid: 0. See logs for details.
2025-07-28 13:47:14 - Processing folder: Cultural Icons and National Significance three(animal, country, metaphor, East Asia, English), testid: 1
Folder: Cultural Icons and National Significance three(animal, country, metaphor, East Asia, English)
TestID: 1
{
    "response": "**Image 1** depicts a group of people standing in front of a large, iconic building with a portrait of a significant figure, suggesting a historical or political context. **Image 2** shows a dynamic battle scene with a central warrior figure wielding a glowing weapon, surrounded by mythical creatures and a dark, stormy sky, indicating a fantasy or epic theme. **Image 3** presents a detailed, wireframe model of a tall tower, focusing on architectural design and structure.\n\n**Image 4** is a wireframe model of a futuristic tower, similar to **Image 3**, but with a more modern and sleek design, emphasizing technological advancement and innovation.\n\n**Relation**: Architectural Evolution\n\n**Explanation**: Both **Image 3** and **Image 4** showcase wireframe models of towers, highlighting the progression from traditional architectural designs to modern, technologically advanced structures. The connection lies in the focus on the structural and design elements of towers, illustrating the evolution of architectural aesthetics and engineering over time."
}

2025-07-28 13:47:42 - Successfully processed folder: Cultural Icons and National Significance three(animal, country, metaphor, East Asia, English), testid: 1
2025-07-28 13:47:42 - Processing folder: Cultural Icons and National Significance three(animal, country, metaphor, East Asia, English), testid: 2
2025-07-28 13:47:43 - Error in generate_response: CUDA out of memory. Tried to allocate 2.02 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.31 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.40 GiB memory in use. Of the allocated memory 32.98 GiB is allocated by PyTorch, and 990.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 13:47:43 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.02 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.31 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.40 GiB memory in use. Of the allocated memory 32.98 GiB is allocated by PyTorch, and 990.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Icons and National Significance three(animal, country, metaphor, East Asia, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 13:47:43 - Error occurred for folder: Cultural Icons and National Significance three(animal, country, metaphor, East Asia, English), testid: 2. See logs for details.
2025-07-28 13:47:43 - Processing folder: Cultural Icons and National Significance three(animal, country, metaphor, East Asia, English), testid: 3
Folder: Cultural Icons and National Significance three(animal, country, metaphor, East Asia, English)
TestID: 3
{
    "response": "### Image 1\n**Image Concept**: A detailed 3D model of a tall, intricate tower with a complex structure, likely a communication or observation tower.\n\n### Image 2\n**Image Concept**: An animated character with spiky, golden hair, dressed in an orange martial arts uniform, surrounded by a dynamic, electrified aura, suggesting a moment of intense power or transformation.\n\n### Image 3\n**Image Concept**: A historical or cultural painting depicting a group of people standing in front of a large, traditional building with red walls and a portrait hanging above the entrance. The scene includes various individuals, some carrying bags, and a bustling atmosphere.\n\n### Image 4\n**Image Concept**: A detailed 3D model of a traditional Chinese building with intricate architectural details, likely a historical or cultural structure, set against a clear sky.\n\n### Relation\n**Historical and Cultural Connection**\n\n### Explanation\nBoth Image 1 and Image 4 feature detailed 3D models of structures, with Image 1 showcasing a modern, possibly technological tower and Image 4 depicting a traditional Chinese building. The connection between them lies in their representation of architectural complexity and historical significance. Image 3, while different in style and content, also emphasizes cultural heritage with its depiction of a historical scene. The relationship between Image 1 and Image 2 is less direct, as Image 2 focuses on an animated character in a moment of power, whereas Image 3 and Image 4 both highlight cultural and historical themes."
}

2025-07-28 13:48:22 - Successfully processed folder: Cultural Icons and National Significance three(animal, country, metaphor, East Asia, English), testid: 3
2025-07-28 13:48:22 - Processing folder: Cultural Symbols and Animals(animal, country, metaphor, East Asia, English), testid: 0
Folder: Cultural Symbols and Animals(animal, country, metaphor, East Asia, English)
TestID: 0
{
    "response": "### Image 1\n**Image Concept**: Historical map of the Tang Dynasty and surrounding regions.\n\n### Image 2\n**Image Concept**: A panda bear in a natural setting.\n\n### Image 3\n**Image Concept**: A colorful, cartoonish map of Japan.\n\n### Image 4\n**Image Concept**: A cartoonish map of the United States.\n\n### Relation\n**Keyword/Phrase**: Geographical maps\n\n### Explanation\nBoth Image 1 and Image 3 are maps, with Image 1 depicting historical regions during the Tang Dynasty and Image 3 showing a stylized map of Japan. Image 4, which is a cartoonish map of the United States, mirrors the relationship between Image 1 and Image 3 by also being a map but representing a different geographical area. The common theme is the representation of geographical regions, albeit in different styles and contexts."
}

2025-07-28 13:48:45 - Successfully processed folder: Cultural Symbols and Animals(animal, country, metaphor, East Asia, English), testid: 0
2025-07-28 13:48:45 - Processing folder: Cultural Symbols and Animals(animal, country, metaphor, East Asia, English), testid: 1
Folder: Cultural Symbols and Animals(animal, country, metaphor, East Asia, English)
TestID: 1
{
    "response": "Image 1: A panda bear standing on grass.\nImage 2: A historical map showing the Tang Dynasty and surrounding regions.\nImage 3: A bird in flight with a distinctive red head and curved beak.\n\nImage 4: A map of the Tang Dynasty and surrounding regions.\n\nRelation: Historical context\n\nExplanation: Both Image 1 and Image 2 are related through the theme of historical context. Image 1 features a panda bear, which is a modern-day animal, while Image 2 is a historical map depicting the Tang Dynasty. The connection between these images is the historical aspect, as both images provide insights into different time periods and geographical regions."
}

2025-07-28 13:49:04 - Successfully processed folder: Cultural Symbols and Animals(animal, country, metaphor, East Asia, English), testid: 1
2025-07-28 13:49:04 - Processing folder: Cultural Symbols and Animals(animal, country, metaphor, East Asia, English), testid: 2
Folder: Cultural Symbols and Animals(animal, country, metaphor, East Asia, English)
TestID: 2
{
    "response": "Image 1: [colorful map of Japan with various symbols and icons]\nImage 2: [bird in flight with outstretched wings]\nImage 3: [map showing historical territories in Asia]\n\nImage 4: [map of Japan with various symbols and icons]\nRelation: Historical Context\nExplanation: Both Image 1 and Image 4 are maps of Japan, but Image 3 provides a historical context that could be relevant to understanding the symbols and icons in Image 1. The historical map could help explain the significance of the symbols and icons in the modern map, suggesting a connection between past and present.\n\nImage 1: [colorful map of Japan with various symbols and icons]\nImage 2: [bird in flight with outstretched wings]\nImage 3: [map showing historical territories in Asia]\n\nImage 4: [map of Japan with various symbols and icons]\nRelation: Cultural Symbols\nExplanation: Both Image 1 and Image 4 feature maps of Japan with various symbols and icons. Image 2, showing a bird in flight, could symbolize freedom or movement, which might relate to the cultural symbols in Image 1. The bird could represent the dynamic and diverse nature of the symbols in the map, suggesting a connection between nature and cultural identity.\n\nImage 1: [colorful map of Japan with various symbols and icons]\nImage 2: [bird in flight with outstretched wings]\nImage 3: [map showing historical territories in Asia]\n\nImage 4: [map of Japan with various symbols and icons]\nRelation: Geographical Representation\nExplanation: Both Image 1 and Image 4 are maps of Japan with various symbols and icons. Image 3 provides a geographical context for the symbols and icons in Image 1, suggesting that the symbols might represent different regions or cultural aspects of Japan. The geographical representation in Image 3 helps to understand the significance of the symbols in the modern map, indicating a connection between geography and cultural identity.\n\nImage 1: [colorful map of Japan with various symbols and icons]\nImage 2: [bird in flight with outstretched wings]\nImage 3: [map showing historical territories in Asia]\n\nImage 4: [map of Japan with various symbols and icons]\nRelation: Cultural Diversity\nExplanation: Both Image 1 and Image 4 are maps of Japan with various symbols and icons, indicating cultural diversity. Image 2, showing a bird in flight, could symbolize"
}

2025-07-28 13:50:10 - Successfully processed folder: Cultural Symbols and Animals(animal, country, metaphor, East Asia, English), testid: 2
2025-07-28 13:50:10 - Processing folder: Cultural Symbols and Animals(animal, country, metaphor, East Asia, English), testid: 3
Folder: Cultural Symbols and Animals(animal, country, metaphor, East Asia, English)
TestID: 3
{
    "response": "**Image 1**: [A bird in flight with a long, curved beak and distinctive red facial markings, set against a blurred green background.]\n\n**Image 2**: [A colorful, stylized map of Japan with various regions marked by different patterns and symbols.]\n\n**Image 3**: [A panda bear standing on grass with a natural background.]\n\n**Image 4**: [A colorful, stylized map of Japan with various regions marked by different patterns and symbols.]\n\n**Relation**: Similarity\n\n**Explanation**: Both Image 2 and Image 4 depict a stylized map of Japan with vibrant colors and unique patterns representing different regions. The common elements of the map's design and the use of bright colors to distinguish various areas create a thematic link between the two images."
}

2025-07-28 13:50:30 - Successfully processed folder: Cultural Symbols and Animals(animal, country, metaphor, East Asia, English), testid: 3
2025-07-28 13:50:30 - Processing folder: Cultural Symbols and Animals three(animal, country, metaphor, East Asia, English), testid: 0
Folder: Cultural Symbols and Animals three(animal, country, metaphor, East Asia, English)
TestID: 0
{
    "response": "### Image 1\n**Image Concept**: Historical Map of Ancient China\n- The map depicts the territorial divisions of ancient China, highlighting various states and regions with distinct colors. The central focus is on the state of Qin, which is marked in red and occupies a significant portion of the map. Surrounding states such as Zhao, Yan, and Qi are also visible, each represented by different colors. The map provides a visual representation of the geopolitical landscape during a historical period, likely the Warring States period.\n\n### Image 2\n**Image Concept**: Cute Panda Character\n- The image features a cartoonish panda with a sad expression. The panda has large, expressive eyes and a small, downturned mouth, giving it a melancholic appearance. The character is sitting down, with its arms resting on its knees. The panda's fur is predominantly white with black patches around the eyes, ears, and limbs, typical of a panda's coloring. The background is plain, ensuring the focus remains on the panda.\n\n### Image 3\n**Image Concept**: Map of Japan\n- The image shows a map of Japan, with the country's regions outlined and labeled in Japanese characters. The map is colored in shades of pink against a blue background, with the main islands of Honshu, Shikoku, and Kyushu clearly visible. The map includes various prefectures, each marked with its name. The text at the bottom of the image is in Japanese, indicating that the map is likely a historical or regional map of Japan.\n\n### Image 4\n**Image Concept**: Historical Map of Japan\n- The image depicts a map of Japan, similar to Image 3, but with a different color scheme and additional details. The map is colored in shades of pink and purple, with the main islands of Honshu, Shikoku, and Kyushu clearly visible. The map includes various prefectures, each marked with its name in Japanese characters. The text at the bottom of the image is in Japanese, indicating that the map is likely a historical or regional map of Japan.\n\n### Relation\n**Keyword**: Historical Maps\n\n### Explanation\n- Both Image 1 and Image 3 are historical maps, focusing on different regions of Asia. Image 1 depicts the territorial divisions of ancient China, while Image 3 shows the regions of Japan. Both maps provide a visual representation of historical geopolitical landscapes, with distinct color schemes and labels to differentiate between regions"
}

2025-07-28 13:51:31 - Successfully processed folder: Cultural Symbols and Animals three(animal, country, metaphor, East Asia, English), testid: 0
2025-07-28 13:51:31 - Processing folder: Cultural Symbols and Animals three(animal, country, metaphor, East Asia, English), testid: 1
Folder: Cultural Symbols and Animals three(animal, country, metaphor, East Asia, English)
TestID: 1
{
    "response": "### Image 1\n**Image Concept**: A cute, cartoon panda with a sad expression.\n\n### Image 2\n**Image Concept**: A historical map depicting the Warring States period in China, with various states marked in different colors.\n\n### Image 3\n**Image Concept**: A white bird with a long, curved beak standing by a water body.\n\n### Image 4\n**Image Concept**: A cartoon panda with a happy expression.\n\n### Relation\n**Connection**: Thematic shift from sadness to happiness.\n\n### Explanation\n- **Image 1** and **Image 2** are connected by the theme of sadness. Image 1 features a sad panda, while Image 2 depicts a historical period marked by conflict and division, symbolized by the Warring States period.\n- **Image 3** and **Image 4** are connected by the theme of happiness. Image 3 shows a bird in a serene environment, while Image 4 features a happy panda, contrasting the previous sad imagery."
}

2025-07-28 13:51:57 - Successfully processed folder: Cultural Symbols and Animals three(animal, country, metaphor, East Asia, English), testid: 1
2025-07-28 13:51:57 - Processing folder: Cultural Symbols and Animals three(animal, country, metaphor, East Asia, English), testid: 2
Folder: Cultural Symbols and Animals three(animal, country, metaphor, East Asia, English)
TestID: 2
{
    "response": "### Image 1\n**Image Concept**: A map of Japan divided into historical provinces, labeled in Chinese characters.\n\n### Image 2\n**Image Concept**: A white bird with a red face and long, curved beak standing on a nest by a body of water.\n\n### Image 3\n**Image Concept**: A historical map of ancient China, showing the territories of various states during the Warring States period, labeled in Chinese characters.\n\n### Image 4\n**Image Concept**: A map of Japan divided into historical provinces, labeled in Japanese characters.\n\n### Relation\n**Relation**: Historical Context\n\n### Explanation\nBoth Image 1 and Image 3 depict maps of Japan and ancient China, respectively, with regions labeled in their native languages. The maps highlight historical divisions and territories, suggesting a thematic connection to historical geography and cultural heritage."
}

2025-07-28 13:52:21 - Successfully processed folder: Cultural Symbols and Animals three(animal, country, metaphor, East Asia, English), testid: 2
2025-07-28 13:52:21 - Processing folder: Cultural Symbols and Animals three(animal, country, metaphor, East Asia, English), testid: 3
Folder: Cultural Symbols and Animals three(animal, country, metaphor, East Asia, English)
TestID: 3
{
    "response": "### Image 1\n**Image Concept**: A white bird with a long, curved beak standing on a rocky shore near water.\n\n### Image 2\n**Image Concept**: A map of Japan with various regions labeled in Japanese characters.\n\n### Image 3\n**Image Concept**: A cute, animated panda with a sad expression.\n\n### Image 4\n**Image Concept**: A cute, animated panda with a happy expression.\n\n### Relation\n**Keyword**: Sadness\n\n### Explanation\nBoth Image 1 and Image 3 depict a sense of sadness. Image 1 shows a bird with a long, curved beak standing on a rocky shore, which can evoke a feeling of solitude or melancholy. Similarly, Image 3 features a cute, animated panda with a sad expression, directly conveying sadness. The connection between these images is the theme of sadness, which is visually represented through the expressions and settings of the subjects in each image."
}

2025-07-28 13:52:47 - Successfully processed folder: Cultural Symbols and Animals three(animal, country, metaphor, East Asia, English), testid: 3
2025-07-28 13:52:47 - Processing folder: Cultural Symbols and Animals four(animal, country, metaphor, East Asia, English), testid: 0
2025-07-28 13:52:47 - Error in generate_response: CUDA out of memory. Tried to allocate 2.20 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.31 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.40 GiB memory in use. Of the allocated memory 33.18 GiB is allocated by PyTorch, and 787.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 13:52:47 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.20 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.31 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.40 GiB memory in use. Of the allocated memory 33.18 GiB is allocated by PyTorch, and 787.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Symbols and Animals four(animal, country, metaphor, East Asia, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 13:52:47 - Error occurred for folder: Cultural Symbols and Animals four(animal, country, metaphor, East Asia, English), testid: 0. See logs for details.
2025-07-28 13:52:47 - Processing folder: Cultural Symbols and Animals four(animal, country, metaphor, East Asia, English), testid: 1
2025-07-28 13:52:47 - Error in generate_response: CUDA out of memory. Tried to allocate 2.20 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.31 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.40 GiB memory in use. Of the allocated memory 33.18 GiB is allocated by PyTorch, and 787.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 13:52:47 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.20 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.31 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.40 GiB memory in use. Of the allocated memory 33.18 GiB is allocated by PyTorch, and 787.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Symbols and Animals four(animal, country, metaphor, East Asia, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 13:52:47 - Error occurred for folder: Cultural Symbols and Animals four(animal, country, metaphor, East Asia, English), testid: 1. See logs for details.
2025-07-28 13:52:47 - Processing folder: Cultural Symbols and Animals four(animal, country, metaphor, East Asia, English), testid: 2
Folder: Cultural Symbols and Animals four(animal, country, metaphor, East Asia, English)
TestID: 2
{
    "response": "### Image 1\n**Image Concept**: A detailed historical map of Japan, showcasing various regions, cities, and geographical features. The map includes annotations in Japanese and is color-coded to distinguish different areas. There are also illustrations of traditional Japanese architecture at the bottom.\n\n### Image 2\n**Image Concept**: A close-up photograph of two crowned cranes facing each other, with their distinctive golden crests prominently displayed. The background is blurred, emphasizing the birds' detailed features and interactions.\n\n### Image 3\n**Image Concept**: A historical map of China, highlighting different provinces and regions with distinct colors. The map includes Chinese text and is marked with a red outline indicating a specific area of interest.\n\n### Image 4\n**Image Concept**: A detailed historical map of Japan, similar to Image 1, showcasing various regions, cities, and geographical features. The map includes annotations in Japanese and is color-coded to distinguish different areas. There are also illustrations of traditional Japanese architecture at the bottom.\n\n### Relation\n**Keyword**: Historical Maps\n\n### Explanation\nBoth Image 1 and Image 3 are historical maps that provide detailed geographical and political information about Japan and China, respectively. They both include annotations in their respective languages and feature illustrations of traditional architecture. The maps serve as visual representations of historical territories and cultural elements, linking them through their focus on historical and geographical themes."
}

2025-07-28 13:53:23 - Successfully processed folder: Cultural Symbols and Animals four(animal, country, metaphor, East Asia, English), testid: 2
2025-07-28 13:53:23 - Processing folder: Cultural Symbols and Animals four(animal, country, metaphor, East Asia, English), testid: 3
Folder: Cultural Symbols and Animals four(animal, country, metaphor, East Asia, English)
TestID: 3
{
    "response": "Image 1: [image concept]\nImage 2: [image concept]\nImage 3: [image concept]\nImage 4: [image concept that you create]\nRelation: [a keyword, phrase, or sentence describing the connection]\nExplanation: [1-5 sentences detailing the reasoning and its application to both pairs]"
}

2025-07-28 13:53:33 - Successfully processed folder: Cultural Symbols and Animals four(animal, country, metaphor, East Asia, English), testid: 3
2025-07-28 13:53:33 - Processing folder: Cultural Symbols and Animals five(animal, country, metaphor, East Asia, English), testid: 0
2025-07-28 13:53:34 - Error in generate_response: CUDA out of memory. Tried to allocate 3.87 GiB. GPU 0 has a total capacity of 47.40 GiB of which 3.86 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 31.85 GiB memory in use. Of the allocated memory 31.16 GiB is allocated by PyTorch, and 231.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 13:53:34 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.87 GiB. GPU 0 has a total capacity of 47.40 GiB of which 3.86 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 31.85 GiB memory in use. Of the allocated memory 31.16 GiB is allocated by PyTorch, and 231.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Symbols and Animals five(animal, country, metaphor, East Asia, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 13:53:34 - Error occurred for folder: Cultural Symbols and Animals five(animal, country, metaphor, East Asia, English), testid: 0. See logs for details.
2025-07-28 13:53:34 - Processing folder: Cultural Symbols and Animals five(animal, country, metaphor, East Asia, English), testid: 1
2025-07-28 13:53:35 - Error in generate_response: CUDA out of memory. Tried to allocate 4.78 GiB. GPU 0 has a total capacity of 47.40 GiB of which 3.86 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 31.85 GiB memory in use. Of the allocated memory 31.24 GiB is allocated by PyTorch, and 149.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 13:53:35 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.78 GiB. GPU 0 has a total capacity of 47.40 GiB of which 3.86 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 31.85 GiB memory in use. Of the allocated memory 31.24 GiB is allocated by PyTorch, and 149.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Symbols and Animals five(animal, country, metaphor, East Asia, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 13:53:35 - Error occurred for folder: Cultural Symbols and Animals five(animal, country, metaphor, East Asia, English), testid: 1. See logs for details.
2025-07-28 13:53:35 - Processing folder: Cultural Symbols and Animals five(animal, country, metaphor, East Asia, English), testid: 2
2025-07-28 13:53:35 - Error in generate_response: CUDA out of memory. Tried to allocate 2.17 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.02 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.69 GiB memory in use. Of the allocated memory 33.15 GiB is allocated by PyTorch, and 86.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 13:53:35 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.17 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.02 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.69 GiB memory in use. Of the allocated memory 33.15 GiB is allocated by PyTorch, and 86.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Symbols and Animals five(animal, country, metaphor, East Asia, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 13:53:35 - Error occurred for folder: Cultural Symbols and Animals five(animal, country, metaphor, East Asia, English), testid: 2. See logs for details.
2025-07-28 13:53:35 - Processing folder: Cultural Symbols and Animals five(animal, country, metaphor, East Asia, English), testid: 3
2025-07-28 13:53:35 - Error in generate_response: CUDA out of memory. Tried to allocate 3.78 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.02 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.69 GiB memory in use. Of the allocated memory 31.16 GiB is allocated by PyTorch, and 2.08 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 13:53:35 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.78 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.02 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.69 GiB memory in use. Of the allocated memory 31.16 GiB is allocated by PyTorch, and 2.08 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Symbols and Animals five(animal, country, metaphor, East Asia, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 13:53:35 - Error occurred for folder: Cultural Symbols and Animals five(animal, country, metaphor, East Asia, English), testid: 3. See logs for details.
2025-07-28 13:53:35 - Processing folder: Cultural Symbols and Animals six(animal, country, metaphor, East Asia, English), testid: 0
Folder: Cultural Symbols and Animals six(animal, country, metaphor, East Asia, English)
TestID: 0
{
    "response": "**Image 1**: A historical map depicting territorial divisions during the year 212 AD, highlighting regions controlled by different factions such as Cao Cao, Liu Bei, and Sun Quan.\n\n**Image 2**: A photograph of two pandas hugging each other, showcasing a moment of affection between the animals.\n\n**Image 3**: A topographical map of Japan, focusing on regions like the Nara Basin and the island of Shikoku, with geographical features and labels in Japanese.\n\n**Image 4**: A topographical map of Japan, focusing on regions like the Nara Basin and the island of Shikoku, with geographical features and labels in Japanese.\n\n**Relation**: Geographical\n\n**Explanation**: Both Image 3 and Image 4 are topographical maps of Japan, focusing on similar regions and featuring geographical features and labels in Japanese. The connection is based on the shared theme of geography and the specific focus on Japanese regions."
}

2025-07-28 13:54:00 - Successfully processed folder: Cultural Symbols and Animals six(animal, country, metaphor, East Asia, English), testid: 0
2025-07-28 13:54:00 - Processing folder: Cultural Symbols and Animals six(animal, country, metaphor, East Asia, English), testid: 1
Folder: Cultural Symbols and Animals six(animal, country, metaphor, East Asia, English)
TestID: 1
{
    "response": "### Image 1\n**Image Concept**: Two pandas embracing each other in a natural setting.\n\n### Image 2\n**Image Concept**: A historical map depicting territorial divisions during the year 212 AD, highlighting regions controlled by different factions.\n\n### Image 3\n**Image Concept**: A white bird with a distinctive red face and long, curved beak standing in shallow water.\n\n### Image 4\n**Image Concept**: A map illustrating the territorial divisions during the year 212 AD, similar to Image 2, but with a focus on a different region or aspect.\n\n### Relation\n**Keyword**: Historical Context\n\n### Explanation\nBoth Image 1 and Image 2 share a theme of territorial or spatial relationships. Image 1 shows pandas in an embrace, which can be seen as a form of social bonding, similar to how territories are bonded in Image 2. Image 3, featuring a bird in water, contrasts with the terrestrial focus of the previous images but still involves a natural setting. Image 4, mirroring Image 2, emphasizes the historical context and territorial divisions, linking it to the theme of spatial relationships established in Image 1 and Image 2."
}

2025-07-28 13:54:29 - Successfully processed folder: Cultural Symbols and Animals six(animal, country, metaphor, East Asia, English), testid: 1
2025-07-28 13:54:29 - Processing folder: Cultural Symbols and Animals six(animal, country, metaphor, East Asia, English), testid: 2
Folder: Cultural Symbols and Animals six(animal, country, metaphor, East Asia, English)
TestID: 2
{
    "response": "**Image 1**: A topographic map of Japan highlighting regions like  and .\n\n**Image 2**: A white bird with a red face and black beak standing in shallow water.\n\n**Image 3**: A historical map of China from 212 AD showing territories controlled by , , , and .\n\n**Image 4**: A map of Japan highlighting regions like  and .\n\n**Relation**: Geographical focus\n\n**Explanation**: Both Image 1 and Image 4 focus on the geographical regions of Japan, specifically highlighting areas like  and . This geographical theme connects the two images, emphasizing the importance of regional identification and mapping in both historical and contemporary contexts."
}

2025-07-28 13:54:51 - Successfully processed folder: Cultural Symbols and Animals six(animal, country, metaphor, East Asia, English), testid: 2
2025-07-28 13:54:51 - Processing folder: Cultural Symbols and Animals six(animal, country, metaphor, East Asia, English), testid: 3
Folder: Cultural Symbols and Animals six(animal, country, metaphor, East Asia, English)
TestID: 3
{
    "response": "### Image 1\n**Image Concept**: A white bird with a long, curved black beak and a red patch around its eye, standing in shallow water with rocks in the background.\n\n### Image 2\n**Image Concept**: A topographic map of Japan, highlighting regions such as \"\" (Izumo), \"\" (Shikoku Island), and \"\" (Nara Basin).\n\n### Image 3\n**Image Concept**: Two pandas, one embracing the other, in a natural setting with greenery and rocks.\n\n### Image 4\n**Image Concept**: A map of Japan, highlighting regions such as \"\" (Izumo), \"\" (Shikoku Island), and \"\" (Nara Basin).\n\n### Relation\n**Relation**: Geographic Focus\n\n### Explanation\nBoth Image 2 and Image 4 are maps of Japan, focusing on specific regions. Image 2 highlights the regions of Izumo, Shikoku Island, and the Nara Basin, while Image 4 similarly emphasizes these areas. The connection is established through the shared theme of geography and the specific regions marked on the maps."
}

2025-07-28 13:55:21 - Successfully processed folder: Cultural Symbols and Animals six(animal, country, metaphor, East Asia, English), testid: 3
2025-07-28 13:55:21 - Processing folder: Cultural Symbols and Animals seven(animal, country, metaphor, East Asia, English), testid: 0
Folder: Cultural Symbols and Animals seven(animal, country, metaphor, East Asia, English)
TestID: 0
{
    "response": "### Image 1\n**Image Concept**: Historical Map of China\n**Description**: The map shows the territorial divisions of China during the period of the Three Kingdoms, Jin, and Northern and Southern Dynasties. It highlights the regions controlled by the Eastern Jin, Western Jin, and various other states and tribes.\n\n### Image 2\n**Image Concept**: Animated Character\n**Description**: The image features an animated panda character in a martial arts pose, with a determined expression and a glowing blue energy in its hand. The setting appears to be a traditional Asian-style room with a view of mountains in the background.\n\n### Image 3\n**Image Concept**: Modern Map of Japan\n**Description**: The map shows the modern political divisions of Japan, with different regions color-coded and labeled. It includes information about the prefectures and major cities.\n\n### Image 4\n**Image Concept**: Historical Map of Japan\n**Description**: The map shows the territorial divisions of Japan during the period of the Sengoku Daimyo, highlighting the various daimyo (feudal lords) and their territories.\n\n### Relation\n**Keyword**: Historical Maps\n**Explanation**: Both Image 1 and Image 3 are historical maps, but they represent different time periods and geographical regions. Image 1 focuses on China during the Three Kingdoms period, while Image 3 focuses on modern Japan. Image 4 is also a historical map, but it represents Japan during the Sengoku period, which is a different era from both Image 1 and Image 3. The common theme is the use of maps to depict historical territorial divisions, providing a visual representation of political and geographical changes over time."
}

2025-07-28 13:56:06 - Successfully processed folder: Cultural Symbols and Animals seven(animal, country, metaphor, East Asia, English), testid: 0
2025-07-28 13:56:06 - Processing folder: Cultural Symbols and Animals seven(animal, country, metaphor, East Asia, English), testid: 1
2025-07-28 13:56:06 - Error in generate_response: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.03 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.68 GiB memory in use. Of the allocated memory 33.95 GiB is allocated by PyTorch, and 278.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 13:56:06 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.03 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.68 GiB memory in use. Of the allocated memory 33.95 GiB is allocated by PyTorch, and 278.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Symbols and Animals seven(animal, country, metaphor, East Asia, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 13:56:06 - Error occurred for folder: Cultural Symbols and Animals seven(animal, country, metaphor, East Asia, English), testid: 1. See logs for details.
2025-07-28 13:56:06 - Processing folder: Cultural Symbols and Animals seven(animal, country, metaphor, East Asia, English), testid: 2
2025-07-28 13:56:06 - Error in generate_response: CUDA out of memory. Tried to allocate 1.64 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.36 GiB memory in use. Of the allocated memory 32.56 GiB is allocated by PyTorch, and 1.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 13:56:06 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.64 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.36 GiB memory in use. Of the allocated memory 32.56 GiB is allocated by PyTorch, and 1.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Symbols and Animals seven(animal, country, metaphor, East Asia, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 13:56:06 - Error occurred for folder: Cultural Symbols and Animals seven(animal, country, metaphor, East Asia, English), testid: 2. See logs for details.
2025-07-28 13:56:06 - Processing folder: Cultural Symbols and Animals seven(animal, country, metaphor, East Asia, English), testid: 3
2025-07-28 13:56:07 - Error in generate_response: CUDA out of memory. Tried to allocate 1.61 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.36 GiB memory in use. Of the allocated memory 32.53 GiB is allocated by PyTorch, and 1.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 13:56:07 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.61 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.36 GiB memory in use. Of the allocated memory 32.53 GiB is allocated by PyTorch, and 1.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Symbols and Animals seven(animal, country, metaphor, East Asia, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 13:56:07 - Error occurred for folder: Cultural Symbols and Animals seven(animal, country, metaphor, East Asia, English), testid: 3. See logs for details.
2025-07-28 13:56:07 - Processing folder: Cultural Symbols and Animals eight(animal, country, metaphor, East Asia, English), testid: 0
Folder: Cultural Symbols and Animals eight(animal, country, metaphor, East Asia, English)
TestID: 0
{
    "response": "### Image 1\n**Image 1** is a historical map depicting the territorial divisions during the Sui Dynasty in 612 AD. The map is color-coded to show different regions and includes labels for major cities and geographical features. The central area is marked with the name \"\" (Sui), indicating the heartland of the Sui Dynasty. Surrounding regions are labeled with names such as \"\" (Eastern Turkic), \"\" (Western Turkic), and \"\" (Goguryeo), among others. The map also includes a legend explaining the symbols used for capitals, prefectures, and other significant locations.\n\n### Image 2\n**Image 2** is a vibrant and colorful illustration featuring anthropomorphic pandas in a fantastical setting. The pandas are depicted with expressive faces, wearing traditional Chinese attire, and are surrounded by lush, detailed scenery that includes pagodas, waterfalls, and mountains. The overall atmosphere is whimsical and lively, suggesting a scene from an animated film or storybook.\n\n### Image 3\n**Image 3** is a historical map showing the movements of the shogunate's pursuit forces during the Genk War in 1441. The map is labeled in Japanese and highlights various regions and key locations involved in the conflict. The central area is marked as \"\" (Harima Province), with arrows indicating the directions of the shogunate's forces. Surrounding regions such as \"\" (Inaba Province), \"\" (Mimasaka Province), and \"\" (Bizen Province) are also labeled. The map includes additional annotations for specific locations like \"\" (Shirahata Castle) and \"\" (Jry Castle).\n\n### Image 4\n**Image 4** is a vibrant and colorful illustration featuring anthropomorphic pandas in a fantastical setting. The pandas are depicted with expressive faces, wearing traditional Chinese attire, and are surrounded by lush, detailed scenery that includes pagodas, waterfalls, and mountains. The overall atmosphere is whimsical and lively, suggesting a scene from an animated film or storybook.\n\n### Relation\n**Relation**: Historical and Cultural Context\n\n### Explanation\nThe connection between **Image 1** and **Image 2** lies in their shared historical and cultural context. Both images depict elements of ancient Chinese history and culture. **Image 1"
}

2025-07-28 13:57:08 - Successfully processed folder: Cultural Symbols and Animals eight(animal, country, metaphor, East Asia, English), testid: 0
2025-07-28 13:57:08 - Processing folder: Cultural Symbols and Animals eight(animal, country, metaphor, East Asia, English), testid: 1
2025-07-28 13:57:09 - Error in generate_response: CUDA out of memory. Tried to allocate 1.68 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 32.60 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 13:57:09 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.68 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 32.60 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Symbols and Animals eight(animal, country, metaphor, East Asia, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 13:57:09 - Error occurred for folder: Cultural Symbols and Animals eight(animal, country, metaphor, East Asia, English), testid: 1. See logs for details.
2025-07-28 13:57:09 - Processing folder: Cultural Symbols and Animals eight(animal, country, metaphor, East Asia, English), testid: 2
2025-07-28 13:57:09 - Error in generate_response: CUDA out of memory. Tried to allocate 2.42 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 33.42 GiB is allocated by PyTorch, and 489.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 13:57:09 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.42 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 33.42 GiB is allocated by PyTorch, and 489.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Symbols and Animals eight(animal, country, metaphor, East Asia, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 13:57:09 - Error occurred for folder: Cultural Symbols and Animals eight(animal, country, metaphor, East Asia, English), testid: 2. See logs for details.
2025-07-28 13:57:09 - Processing folder: Cultural Symbols and Animals eight(animal, country, metaphor, East Asia, English), testid: 3
Folder: Cultural Symbols and Animals eight(animal, country, metaphor, East Asia, English)
TestID: 3
{
    "response": "### Image 1\n**Image Concept**: A bird in flight with its wings fully extended, showcasing vibrant plumage.\n\n### Image 2\n**Image Concept**: A historical map depicting the movements of the shogunate's pursuit forces during the Genpei War in 1441.\n\n### Image 3\n**Image Concept**: Animated pandas in a vibrant, colorful setting, likely from a movie or animated series.\n\n### Image 4\n**Image Concept**: A map of a fictional region with animated pandas, similar to Image 3, but with a focus on the movements and locations of the pandas within the region.\n\n### Relation\n**Keyword**: Animated Pandas\n\n### Explanation\nBoth Image 1 and Image 2 are connected by the theme of movement and direction. Image 1 shows a bird in flight, symbolizing freedom and direction, while Image 2 depicts the strategic movements of military forces during a historical conflict. Similarly, Image 3 and Image 4 both feature animated pandas, with Image 4 focusing on the pandas' movements within a fictional region, mirroring the directional and strategic elements found in Image 2."
}

2025-07-28 13:57:38 - Successfully processed folder: Cultural Symbols and Animals eight(animal, country, metaphor, East Asia, English), testid: 3
2025-07-28 13:57:38 - Processing folder: Cultural Symbols and Animals nine(animal, country, metaphor, East Asia, English), testid: 0
Folder: Cultural Symbols and Animals nine(animal, country, metaphor, East Asia, English)
TestID: 0
{
    "response": "### Image 1\n**Image Concept**: A historical map depicting the territorial divisions during the Five Dynasties and Ten Kingdoms period in China.\n\n### Image 2\n**Image Concept**: A photograph of two pandas walking on a snowy path in a natural setting.\n\n### Image 3\n**Image Concept**: A historical map illustrating the territorial divisions in Japan during the year 1561, highlighting various daimyo (feudal lords) and their domains.\n\n### Image 4\n**Image Concept**: A map of Japan during the year 1561, similar to Image 3, but with a focus on the territories controlled by the daimyo of the Sengoku period.\n\n### Relation\n**Keyword**: Historical Territories\n\n### Explanation\nBoth Image 1 and Image 3 depict historical maps of Japan and China, respectively, showing the territorial divisions during specific periods. Image 1 focuses on the Five Dynasties and Ten Kingdoms period in China, while Image 3 highlights the daimyo territories in Japan during the Sengoku period. Image 4 is designed to mirror this relationship by presenting a map of Japan in 1561, similar to Image 3, but with a focus on the territories controlled by the daimyo of the Sengoku period. This creates a parallel between the historical territorial divisions in both countries, emphasizing the theme of historical territories."
}

2025-07-28 13:58:15 - Successfully processed folder: Cultural Symbols and Animals nine(animal, country, metaphor, East Asia, English), testid: 0
2025-07-28 13:58:15 - Processing folder: Cultural Symbols and Animals nine(animal, country, metaphor, East Asia, English), testid: 1
Folder: Cultural Symbols and Animals nine(animal, country, metaphor, East Asia, English)
TestID: 1
{
    "response": "### Image 1\n**Image Concept**: Two pandas in a natural setting, navigating a snowy path.\n\n### Image 2\n**Image Concept**: A historical map depicting the \"Five Dynasties and Ten Kingdoms\" period in China.\n\n### Image 3\n**Image Concept**: Birds perched on a fruit-laden tree, with some in flight.\n\n### Image 4\n**Image Concept**: A group of pandas in a natural setting, interacting with a fruit-laden tree.\n\n### Relation\n**Connection**: Nature and wildlife\n\n### Explanation\nBoth Image 1 and Image 4 depict pandas in natural settings, emphasizing wildlife and nature. Similarly, Image 3 shows birds interacting with a fruit-laden tree, also highlighting nature. The connection between these images is the theme of nature and wildlife, with pandas and birds being the focal points in their respective scenes."
}

2025-07-28 13:58:36 - Successfully processed folder: Cultural Symbols and Animals nine(animal, country, metaphor, East Asia, English), testid: 1
2025-07-28 13:58:36 - Processing folder: Cultural Symbols and Animals nine(animal, country, metaphor, East Asia, English), testid: 2
Folder: Cultural Symbols and Animals nine(animal, country, metaphor, East Asia, English)
TestID: 2
{
    "response": "1. **Image 1**: A historical map of Japan from 1561, showing various daimyo (feudal lords) and their territories, with labels in Japanese. The map is color-coded to distinguish different regions and includes a smaller inset map of Japan.\n   **Image 2**: A photograph of several birds, likely cranes, perched on a tree with orange fruits, possibly persimmons, in a natural setting with a blurred green background.\n   **Image 3**: A historical map of China during the Five Dynasties and Ten Kingdoms period, showing various states and their capitals, with labels in Chinese.\n\n2. **Analysis**:\n   - **Connection**: Both Image 1 and Image 3 are historical maps that depict territorial divisions and political divisions in Japan and China, respectively. They share a common theme of historical geography and political organization.\n   - **Shared Elements**: Both maps are detailed and color-coded to show different regions or states. They both provide a visual representation of historical territorial divisions, which is a key element in understanding the political landscape of their respective periods.\n\n3. **Image 4**:\n   - **Image 4 Concept**: A historical map of Japan during the Edo period, showing the various domains (han) and their territories, with labels in Japanese. The map is color-coded to distinguish different domains and includes a smaller inset map of Japan.\n   - **Relation**: The relationship between Image 1 and Image 4 mirrors that between Image 1 and Image 3. Both pairs involve historical maps of Japan, focusing on different periods and showing territorial divisions.\n   - **Explanation**: Just as Image 1 and Image 3 both depict historical maps of Japan with a focus on territorial divisions, Image 1 and Image 4 similarly highlight the historical geography of Japan, albeit during different time periods. Image 4 provides a broader perspective on the Edo period, which is a continuation of the historical narrative depicted in Image 1.\n\n4. **Final Analysis**:\n   - **Image 1**: [Historical map of Japan from 1561]\n   - **Image 2**: [Photograph of birds in a natural setting]\n   - **Image 3**: [Historical map of China during the Five Dynasties and Ten Kingdoms period]\n   - **Image 4**: [Historical map of Japan during the Edo period]\n   - **Relation**: Historical maps\n   - **Explanation**: Both"
}

2025-07-28 13:59:39 - Successfully processed folder: Cultural Symbols and Animals nine(animal, country, metaphor, East Asia, English), testid: 2
2025-07-28 13:59:39 - Processing folder: Cultural Symbols and Animals nine(animal, country, metaphor, East Asia, English), testid: 3
Folder: Cultural Symbols and Animals nine(animal, country, metaphor, East Asia, English)
TestID: 3
{
    "response": "### Image 1\n**Image Concept**: A group of birds in mid-flight, perched on a branch laden with fruit.\n\n### Image 2\n**Image Concept**: A historical map of Japan, detailing various daimyo (feudal lords) and their territories during the Sengoku period.\n\n### Image 3\n**Image Concept**: Two pandas walking on a snowy path, surrounded by natural terrain.\n\n### Image 4\n**Image Concept**: A group of pandas in mid-motion, possibly climbing or playing on a rocky terrain.\n\n### Relation\n**Keyword**: Natural Habitat\n\n### Explanation\nBoth Image 1 and Image 3 depict scenes of wildlife in their natural environments. Image 1 shows birds in flight, while Image 3 features pandas in a snowy landscape. Similarly, Image 4 illustrates pandas in a natural setting, emphasizing their habitat and behavior. The common theme is the depiction of animals in their natural surroundings, highlighting their interactions with the environment."
}

2025-07-28 14:00:06 - Successfully processed folder: Cultural Symbols and Animals nine(animal, country, metaphor, East Asia, English), testid: 3
2025-07-28 14:00:06 - Processing folder: Cultural Symbols and Animals ten(animal, country, metaphor, East Asia, English), testid: 0
Folder: Cultural Symbols and Animals ten(animal, country, metaphor, East Asia, English)
TestID: 0
{
    "response": "### Image 1\n**Image Concept**: A colorful map of ancient China, highlighting various regions and territories.\n\n### Image 2\n**Image Concept**: Two pandas hugging each other in a natural setting.\n\n### Image 3\n**Image Concept**: A map of Japan divided into various regions, each labeled with different names.\n\n### Image 4\n**Image Concept**: A map of Japan divided into various regions, each labeled with different names, similar to Image 3.\n\n### Relation\n**Keyword**: Historical Maps\n\n### Explanation\nBoth Image 1 and Image 3 depict maps of historical regions, with Image 1 focusing on ancient China and Image 3 on Japan. The maps are colorful and divided into distinct regions, each labeled with specific names. Image 4 mirrors this structure, showing a map of Japan divided into regions with labeled names, similar to the relationship between Image 1 and Image 3."
}

2025-07-28 14:00:29 - Successfully processed folder: Cultural Symbols and Animals ten(animal, country, metaphor, East Asia, English), testid: 0
2025-07-28 14:00:29 - Processing folder: Cultural Symbols and Animals ten(animal, country, metaphor, East Asia, English), testid: 1
Folder: Cultural Symbols and Animals ten(animal, country, metaphor, East Asia, English)
TestID: 1
{
    "response": "### Image 1\n**Image Concept**: Two pandas hugging each other affectionately.\n\n### Image 2\n**Image Concept**: A colorful map of ancient China, showing various regions and provinces.\n\n### Image 3\n**Image Concept**: A white bird with a red face and a long, curved beak standing on rocks by a body of water.\n\n### Image 4\n**Image Concept**: A white bird with a red face and a long, curved beak standing on rocks by a body of water.\n\n### Relation\n**Keyword**: Pandas\n\n### Explanation\nBoth Image 1 and Image 4 depict pandas in a similar pose, emphasizing their affectionate and gentle nature. Image 1 shows two pandas hugging, while Image 4 features a single bird standing on rocks by the water. The connection between these images is the depiction of animals in serene and natural settings, highlighting their peaceful and harmonious interactions with their environment."
}

2025-07-28 14:00:49 - Successfully processed folder: Cultural Symbols and Animals ten(animal, country, metaphor, East Asia, English), testid: 1
2025-07-28 14:00:49 - Processing folder: Cultural Symbols and Animals ten(animal, country, metaphor, East Asia, English), testid: 2
Folder: Cultural Symbols and Animals ten(animal, country, metaphor, East Asia, English)
TestID: 2
{
    "response": "### Image 1\n**Image 1** is a colorful map depicting various regions, each marked with distinct colors and labeled with names in a non-Latin script. The map appears to represent a geographical area with clear demarcations of different territories or districts.\n\n### Image 2\n**Image 2** features a white bird with a red patch on its head and a long, curved beak, standing on rocks by a body of water. The background is blurred, emphasizing the bird and its natural surroundings.\n\n### Image 3\n**Image 3** is another map, similar in style to Image 1, but it represents a different geographical area. This map is also color-coded with various regions labeled in a non-Latin script. The map includes a body of water labeled \"\" (South China Sea) and another body of water labeled \"\" (East China Sea).\n\n### Analysis of the Relationship Between Image 1 and Image 2\n**Relation**: Nature vs. Culture\n\n**Explanation**: \n- **Image 1** and **Image 2** both depict distinct elements of culture and nature. Image 1 represents cultural geography through its detailed map of regions, while Image 2 showcases nature through the depiction of a bird in its natural habitat. The contrast between the structured, human-made map and the organic, natural setting of the bird highlights the interplay between human civilization and the natural world.\n\n### Creating Image 4\n**Image 4** should mirror the relationship between Image 1 and Image 2. Therefore, it should depict a natural element that contrasts with a human-made structure.\n\n**Image 4**: A lush, green forest with a clear, flowing river running through it. The forest is dense with tall trees, and the river is surrounded by rocks and vegetation.\n\n**Relation**: Nature vs. Nature\n\n**Explanation**: \n- **Image 4** focuses on nature itself, similar to Image 2, but expands the scope to include a larger natural environment. The forest and river represent the untouched, organic aspects of nature, contrasting with the structured, human-made maps in Images 1 and 3. This pairing emphasizes the beauty and complexity of natural ecosystems, much like the bird in Image 2 highlights the elegance of individual wildlife."
}

2025-07-28 14:01:47 - Successfully processed folder: Cultural Symbols and Animals ten(animal, country, metaphor, East Asia, English), testid: 2
2025-07-28 14:01:47 - Processing folder: Cultural Symbols and Animals ten(animal, country, metaphor, East Asia, English), testid: 3
Folder: Cultural Symbols and Animals ten(animal, country, metaphor, East Asia, English)
TestID: 3
{
    "response": "### Image 1\n**Image Concept**: A white bird with a red face and long, curved beak standing on rocks by a body of water.\n\n### Image 2\n**Image Concept**: A colorful map of Japan divided into various regions, each labeled with different names.\n\n### Image 3\n**Image Concept**: Two pandas hugging each other in a natural setting with greenery and rocks.\n\n### Image 4\n**Image Concept**: A map of Japan divided into various regions, each labeled with different names.\n\n### Relation\n**Map of Japan**\n\n### Explanation\nBoth Image 2 and Image 4 depict a map of Japan divided into regions, each labeled with different names. The primary connection between these images is the geographical representation of Japan, highlighting its diverse regions. The visual elements in both images focus on the division and labeling of Japan's regions, making them closely related in terms of content and theme."
}

2025-07-28 14:02:12 - Successfully processed folder: Cultural Symbols and Animals ten(animal, country, metaphor, East Asia, English), testid: 3
2025-07-28 14:02:12 - Processing folder: Cultural Symbols and Animals eleven(animal, country, metaphor, East Asia, English), testid: 0
Folder: Cultural Symbols and Animals eleven(animal, country, metaphor, East Asia, English)
TestID: 0
{
    "response": "### Image 1\n**Image Concept**: Historical Map of the Yuan Dynasty\nThe image depicts a historical map of the Yuan Dynasty, highlighting its vast territorial extent. The map includes regions such as the Yuan Dynasty's capital, Dadu (present-day Beijing), and other significant areas like the Mongolian Plateau and the Han Chinese territories. The map is color-coded to distinguish different regions and includes labels in both Chinese and English, providing a clear visual representation of the dynasty's administrative divisions.\n\n### Image 2\n**Image Concept**: Panda Hugging a Tree\nThe image shows a panda cub hugging a tree trunk. The panda has distinctive black patches around its eyes, ears, and limbs, which are characteristic features of the species. The background appears to be a natural setting, possibly a zoo or a wildlife reserve, with some greenery visible. The panda's expression and posture convey a sense of comfort and curiosity.\n\n### Image 3\n**Image Concept**: Historical Map of Japan in 1868\nThe image is a historical map of Japan from the year 1868, during the Meiji Restoration. The map is color-coded to show different regions and includes labels in Japanese. It highlights the division of the country into various provinces and prefectures, with specific areas marked for their historical significance. The map also includes annotations in Japanese, providing context about the regions and their historical importance.\n\n### Image 4\n**Image Concept**: Panda Hugging a Tree (Revised)\nThe image shows a panda cub hugging a tree trunk, similar to Image 2. The panda has the same distinctive black patches around its eyes, ears, and limbs. The background is a natural setting, possibly a zoo or a wildlife reserve, with some greenery visible. The panda's expression and posture convey a sense of comfort and curiosity.\n\n### Relation\n**Keyword**: Historical Context\n\n### Explanation\nBoth Image 1 and Image 3 share a common theme of historical context. Image 1 depicts a historical map of the Yuan Dynasty, providing a visual representation of the dynasty's territorial extent and administrative divisions. Image 3 shows a historical map of Japan from the year 1868, highlighting the division of the country into various provinces and prefectures during the Meiji Restoration. Both images serve as visual aids to understand the historical and geographical context of their respective periods. The connection between the two pairs is the emphasis on historical maps, which provide valuable insights into the territorial and administrative"
}

2025-07-28 14:03:17 - Successfully processed folder: Cultural Symbols and Animals eleven(animal, country, metaphor, East Asia, English), testid: 0
2025-07-28 14:03:17 - Processing folder: Cultural Symbols and Animals eleven(animal, country, metaphor, East Asia, English), testid: 1
Folder: Cultural Symbols and Animals eleven(animal, country, metaphor, East Asia, English)
TestID: 1
{
    "response": "Image 1: [a panda bear hugging a tree]\nImage 2: [a map of China]\nImage 3: [a bird flying over water]\nImage 4: [a bird flying over water]\nRelation: natural\nExplanation: Both Image 1 and Image 3 depict animals interacting with their environment, with Image 1 showing a panda hugging a tree and Image 3 showing a bird flying over water."
}

2025-07-28 14:03:31 - Successfully processed folder: Cultural Symbols and Animals eleven(animal, country, metaphor, East Asia, English), testid: 1
2025-07-28 14:03:31 - Processing folder: Cultural Symbols and Animals eleven(animal, country, metaphor, East Asia, English), testid: 2
2025-07-28 14:03:31 - Error in generate_response: CUDA out of memory. Tried to allocate 2.03 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.02 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.68 GiB memory in use. Of the allocated memory 32.99 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:03:31 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.03 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.02 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.68 GiB memory in use. Of the allocated memory 32.99 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Symbols and Animals eleven(animal, country, metaphor, East Asia, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:03:31 - Error occurred for folder: Cultural Symbols and Animals eleven(animal, country, metaphor, East Asia, English), testid: 2. See logs for details.
2025-07-28 14:03:31 - Processing folder: Cultural Symbols and Animals eleven(animal, country, metaphor, East Asia, English), testid: 3
2025-07-28 14:03:31 - Error in generate_response: CUDA out of memory. Tried to allocate 1.80 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 32.74 GiB is allocated by PyTorch, and 1.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:03:31 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.80 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 32.74 GiB is allocated by PyTorch, and 1.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Symbols and Animals eleven(animal, country, metaphor, East Asia, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:03:31 - Error occurred for folder: Cultural Symbols and Animals eleven(animal, country, metaphor, East Asia, English), testid: 3. See logs for details.
2025-07-28 14:03:31 - Processing folder: Cultural Symbols and Animals twelve(animal, country, metaphor, East Asia, English), testid: 0
Folder: Cultural Symbols and Animals twelve(animal, country, metaphor, East Asia, English)
TestID: 0
{
    "response": "### Image 1\n**Image Concept**: Historical Map of Qing Dynasty in 1760\n\n**Description**: This is a detailed historical map of the Qing Dynasty in 1760. The map shows the territorial extent of the Qing Empire, including its borders with neighboring countries such as Russia and Japan. The map is color-coded to distinguish different regions and includes labels for major cities, rivers, and mountain ranges. The map also highlights the administrative divisions within the empire.\n\n### Image 2\n**Image Concept**: Giant Panda in a Natural Setting\n\n**Description**: This image features a giant panda lying on a wooden platform surrounded by green foliage. The panda appears relaxed and is looking directly at the camera. The panda's distinctive black and white fur pattern is clearly visible, and the setting suggests a natural or semi-natural habitat, possibly in a zoo or wildlife reserve.\n\n### Image 3\n**Image Concept**: Historical Map of Japan in the Sengoku Period\n\n**Description**: This is a historical map of Japan during the Sengoku Period, showing the various daimyo (feudal lords) and their territories. The map is color-coded to differentiate between the territories of different daimyo, with each region labeled in Japanese. The map also includes the names of major castles and cities, as well as the names of the daimyo who controlled each area.\n\n### Image 4\n**Image Concept**: Historical Map of the Roman Empire in 100 AD\n\n**Description**: This is a detailed historical map of the Roman Empire in 100 AD. The map shows the territorial extent of the Roman Empire, including its borders with neighboring tribes and regions. The map is color-coded to distinguish different regions and includes labels for major cities, rivers, and mountain ranges. The map also highlights the administrative divisions within the empire.\n\n### Relation\n**Keyword**: Historical Maps\n\n**Explanation**: Both Image 1 and Image 3 are historical maps that depict the territorial extent and administrative divisions of ancient empires. Image 1 shows the Qing Dynasty in 1760, while Image 3 shows Japan during the Sengoku Period. Both maps provide a visual representation of the political landscape of their respective time periods, highlighting the territories controlled by different rulers and the geographical features of the regions. The maps serve as valuable historical documents, offering insights into the political and social structures of the empires they represent."
}

2025-07-28 14:04:34 - Successfully processed folder: Cultural Symbols and Animals twelve(animal, country, metaphor, East Asia, English), testid: 0
2025-07-28 14:04:34 - Processing folder: Cultural Symbols and Animals twelve(animal, country, metaphor, East Asia, English), testid: 1
2025-07-28 14:04:34 - Error in generate_response: CUDA out of memory. Tried to allocate 2.78 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 33.82 GiB is allocated by PyTorch, and 81.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:04:34 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.78 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 33.82 GiB is allocated by PyTorch, and 81.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Symbols and Animals twelve(animal, country, metaphor, East Asia, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:04:34 - Error occurred for folder: Cultural Symbols and Animals twelve(animal, country, metaphor, East Asia, English), testid: 1. See logs for details.
2025-07-28 14:04:34 - Processing folder: Cultural Symbols and Animals twelve(animal, country, metaphor, East Asia, English), testid: 2
2025-07-28 14:04:34 - Error in generate_response: CUDA out of memory. Tried to allocate 3.43 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.13 GiB is allocated by PyTorch, and 2.77 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:04:34 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.43 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.13 GiB is allocated by PyTorch, and 2.77 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Symbols and Animals twelve(animal, country, metaphor, East Asia, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:04:34 - Error occurred for folder: Cultural Symbols and Animals twelve(animal, country, metaphor, East Asia, English), testid: 2. See logs for details.
2025-07-28 14:04:34 - Processing folder: Cultural Symbols and Animals twelve(animal, country, metaphor, East Asia, English), testid: 3
2025-07-28 14:04:34 - Error in generate_response: CUDA out of memory. Tried to allocate 2.06 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 33.02 GiB is allocated by PyTorch, and 896.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:04:34 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.06 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 33.02 GiB is allocated by PyTorch, and 896.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Symbols and Animals twelve(animal, country, metaphor, East Asia, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:04:34 - Error occurred for folder: Cultural Symbols and Animals twelve(animal, country, metaphor, East Asia, English), testid: 3. See logs for details.
2025-07-28 14:04:34 - Processing folder: Cultural Symbols and Animals thirteen(animal, country, metaphor, East Asia, English), testid: 0
2025-07-28 14:04:34 - Error in generate_response: CUDA out of memory. Tried to allocate 2.31 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 33.30 GiB is allocated by PyTorch, and 607.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:04:34 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.31 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 33.30 GiB is allocated by PyTorch, and 607.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Symbols and Animals thirteen(animal, country, metaphor, East Asia, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:04:34 - Error occurred for folder: Cultural Symbols and Animals thirteen(animal, country, metaphor, East Asia, English), testid: 0. See logs for details.
2025-07-28 14:04:34 - Processing folder: Cultural Symbols and Animals thirteen(animal, country, metaphor, East Asia, English), testid: 1
2025-07-28 14:04:35 - Error in generate_response: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 33.24 GiB is allocated by PyTorch, and 668.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:04:35 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 33.24 GiB is allocated by PyTorch, and 668.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Symbols and Animals thirteen(animal, country, metaphor, East Asia, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:04:35 - Error occurred for folder: Cultural Symbols and Animals thirteen(animal, country, metaphor, East Asia, English), testid: 1. See logs for details.
2025-07-28 14:04:35 - Processing folder: Cultural Symbols and Animals thirteen(animal, country, metaphor, East Asia, English), testid: 2
2025-07-28 14:04:35 - Error in generate_response: CUDA out of memory. Tried to allocate 2.95 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.08 GiB is allocated by PyTorch, and 2.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:04:35 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.95 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.08 GiB is allocated by PyTorch, and 2.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Symbols and Animals thirteen(animal, country, metaphor, East Asia, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:04:35 - Error occurred for folder: Cultural Symbols and Animals thirteen(animal, country, metaphor, East Asia, English), testid: 2. See logs for details.
2025-07-28 14:04:35 - Processing folder: Cultural Symbols and Animals thirteen(animal, country, metaphor, East Asia, English), testid: 3
2025-07-28 14:04:35 - Error in generate_response: CUDA out of memory. Tried to allocate 2.28 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 33.26 GiB is allocated by PyTorch, and 648.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:04:35 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.28 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 33.26 GiB is allocated by PyTorch, and 648.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Symbols and Animals thirteen(animal, country, metaphor, East Asia, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:04:35 - Error occurred for folder: Cultural Symbols and Animals thirteen(animal, country, metaphor, East Asia, English), testid: 3. See logs for details.
2025-07-28 14:04:35 - Processing folder: Cultural Symbols and Animals forteen(animal, country, metaphor, East Asia, English), testid: 0
2025-07-28 14:04:35 - Error in generate_response: CUDA out of memory. Tried to allocate 2.25 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 33.23 GiB is allocated by PyTorch, and 684.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:04:35 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.25 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 33.23 GiB is allocated by PyTorch, and 684.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Symbols and Animals forteen(animal, country, metaphor, East Asia, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:04:35 - Error occurred for folder: Cultural Symbols and Animals forteen(animal, country, metaphor, East Asia, English), testid: 0. See logs for details.
2025-07-28 14:04:35 - Processing folder: Cultural Symbols and Animals forteen(animal, country, metaphor, East Asia, English), testid: 1
2025-07-28 14:04:36 - Error in generate_response: CUDA out of memory. Tried to allocate 2.81 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.07 GiB is allocated by PyTorch, and 2.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:04:36 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.81 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.07 GiB is allocated by PyTorch, and 2.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Symbols and Animals forteen(animal, country, metaphor, East Asia, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:04:36 - Error occurred for folder: Cultural Symbols and Animals forteen(animal, country, metaphor, East Asia, English), testid: 1. See logs for details.
2025-07-28 14:04:36 - Processing folder: Cultural Symbols and Animals forteen(animal, country, metaphor, East Asia, English), testid: 2
2025-07-28 14:04:36 - Error in generate_response: CUDA out of memory. Tried to allocate 2.20 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 33.18 GiB is allocated by PyTorch, and 737.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:04:36 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.20 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 33.18 GiB is allocated by PyTorch, and 737.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Symbols and Animals forteen(animal, country, metaphor, East Asia, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:04:36 - Error occurred for folder: Cultural Symbols and Animals forteen(animal, country, metaphor, East Asia, English), testid: 2. See logs for details.
2025-07-28 14:04:36 - Processing folder: Cultural Symbols and Animals forteen(animal, country, metaphor, East Asia, English), testid: 3
2025-07-28 14:04:37 - Error in generate_response: CUDA out of memory. Tried to allocate 2.19 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 33.16 GiB is allocated by PyTorch, and 750.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:04:37 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.19 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 33.16 GiB is allocated by PyTorch, and 750.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Symbols and Animals forteen(animal, country, metaphor, East Asia, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:04:37 - Error occurred for folder: Cultural Symbols and Animals forteen(animal, country, metaphor, East Asia, English), testid: 3. See logs for details.
2025-07-28 14:04:37 - Processing folder: National Anthems and Their Associated Transit Systems(country, city, relation, East Asia, English), testid: 0
2025-07-28 14:04:38 - Error in generate_response: CUDA out of memory. Tried to allocate 2.49 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 33.50 GiB is allocated by PyTorch, and 411.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:04:38 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.49 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 33.50 GiB is allocated by PyTorch, and 411.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: National Anthems and Their Associated Transit Systems(country, city, relation, East Asia, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:04:38 - Error occurred for folder: National Anthems and Their Associated Transit Systems(country, city, relation, East Asia, English), testid: 0. See logs for details.
2025-07-28 14:04:38 - Processing folder: National Anthems and Their Associated Transit Systems(country, city, relation, East Asia, English), testid: 1
2025-07-28 14:04:39 - Error in generate_response: CUDA out of memory. Tried to allocate 2.34 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 33.33 GiB is allocated by PyTorch, and 581.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:04:39 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.34 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 33.33 GiB is allocated by PyTorch, and 581.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: National Anthems and Their Associated Transit Systems(country, city, relation, East Asia, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:04:39 - Error occurred for folder: National Anthems and Their Associated Transit Systems(country, city, relation, East Asia, English), testid: 1. See logs for details.
2025-07-28 14:04:39 - Processing folder: National Anthems and Their Associated Transit Systems(country, city, relation, East Asia, English), testid: 2
2025-07-28 14:04:39 - Error in generate_response: CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 33.56 GiB is allocated by PyTorch, and 341.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:04:39 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 33.56 GiB is allocated by PyTorch, and 341.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: National Anthems and Their Associated Transit Systems(country, city, relation, East Asia, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:04:39 - Error occurred for folder: National Anthems and Their Associated Transit Systems(country, city, relation, East Asia, English), testid: 2. See logs for details.
2025-07-28 14:04:39 - Processing folder: National Anthems and Their Associated Transit Systems(country, city, relation, East Asia, English), testid: 3
2025-07-28 14:04:40 - Error in generate_response: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.08 GiB is allocated by PyTorch, and 2.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:04:40 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.08 GiB is allocated by PyTorch, and 2.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: National Anthems and Their Associated Transit Systems(country, city, relation, East Asia, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:04:40 - Error occurred for folder: National Anthems and Their Associated Transit Systems(country, city, relation, East Asia, English), testid: 3. See logs for details.
2025-07-28 14:04:40 - Processing folder: Symbolic Connections in Chinese Culture(animal, city, relation, East Asia, English), testid: 0
Folder: Symbolic Connections in Chinese Culture(animal, city, relation, East Asia, English)
TestID: 0
{
    "response": "Image 1: [A bird with grey feathers and a striped chest stands on a branch]\nImage 2: [A large rock formation stands in a desert landscape with a sign in Chinese characters]\nImage 3: [A dense patch of green aquatic plants covers the surface of a body of water]\n\nImage 4: [A dense patch of green aquatic plants covers the surface of a body of water]\n\nRelation: Nature\n\nExplanation: Both Image 1 and Image 3 depict natural elements, with Image 1 featuring a bird in its natural habitat and Image 3 showing aquatic plants. Image 2, while also natural, introduces a man-made element with the rock formation and sign. The connection between Image 1 and Image 3 is stronger due to their shared focus on natural elements, whereas Image 2 introduces a contrasting human-made aspect."
}

2025-07-28 14:05:04 - Successfully processed folder: Symbolic Connections in Chinese Culture(animal, city, relation, East Asia, English), testid: 0
2025-07-28 14:05:04 - Processing folder: Symbolic Connections in Chinese Culture(animal, city, relation, East Asia, English), testid: 1
Folder: Symbolic Connections in Chinese Culture(animal, city, relation, East Asia, English)
TestID: 1
{
    "response": "**Image 1**: [ancient ruins in a desert landscape]\n**Image 2**: [bird perched on a branch]\n**Image 3**: [traditional Chinese garden with a pond and bridge]\n**Image 4**: [ancient ruins in a desert landscape]\n\n**Relation**: contrast\n\n**Explanation**: Both pairs of images contrast different elements: Image 1 contrasts the ancient ruins with the desert landscape, while Image 2 contrasts the bird with the branch. Similarly, Image 3 contrasts the serene garden with the pond, while Image 4 contrasts the ancient ruins with the desert landscape."
}

2025-07-28 14:05:22 - Successfully processed folder: Symbolic Connections in Chinese Culture(animal, city, relation, East Asia, English), testid: 1
2025-07-28 14:05:22 - Processing folder: Symbolic Connections in Chinese Culture(animal, city, relation, East Asia, English), testid: 2
Folder: Symbolic Connections in Chinese Culture(animal, city, relation, East Asia, English)
TestID: 2
{
    "response": "Image 1: [a dense patch of green aquatic plants covering a body of water]\nImage 2: [a traditional Chinese garden with a pond, bridge, and ornate buildings]\nImage 3: [a bird perched on a branch, displaying its plumage]\n\nImage 4: [a bird perched on a branch, displaying its plumage]\n\nRelation: Nature\nExplanation: Both Image 1 and Image 3 depict elements of nature, with Image 1 showing aquatic plants and Image 3 featuring a bird. Image 2, while showcasing a man-made structure, is set within a natural environment, thus maintaining the theme of nature."
}

2025-07-28 14:05:40 - Successfully processed folder: Symbolic Connections in Chinese Culture(animal, city, relation, East Asia, English), testid: 2
2025-07-28 14:05:40 - Processing folder: Symbolic Connections in Chinese Culture(animal, city, relation, East Asia, English), testid: 3
Folder: Symbolic Connections in Chinese Culture(animal, city, relation, East Asia, English)
TestID: 3
{
    "response": "Image 1: [A serene Chinese garden with traditional architecture, a bridge over a pond, and lush greenery]\nImage 2: [A dense patch of green aquatic plants covering a body of water]\nImage 3: [A desert landscape with a large rock formation and a sign with Chinese characters]\n\n**Image 4**: [A desert landscape with a large rock formation and a sign with English characters]\n\n**Relation**: Cultural Connection\n\n**Explanation**: Both Image 1 and Image 3 feature a desert landscape with a prominent rock formation, suggesting a connection to historical or cultural sites. Image 1, however, includes traditional Chinese architecture and a serene garden setting, while Image 3 includes a sign with Chinese characters. Image 4 mirrors this by placing a sign with English characters in a desert setting, thus maintaining the cultural and historical theme while introducing a new linguistic element."
}

2025-07-28 14:06:03 - Successfully processed folder: Symbolic Connections in Chinese Culture(animal, city, relation, East Asia, English), testid: 3
2025-07-28 14:06:03 - Processing folder: Symbolic Connections in Chinese Culture two(animal, city, relation, East Asia, English), testid: 0
Folder: Symbolic Connections in Chinese Culture two(animal, city, relation, East Asia, English)
TestID: 0
{
    "response": "Image 1: [a small bird with blue and brown feathers perched on a surface]\nImage 2: [a panoramic view of an ancient city with traditional architecture]\nImage 3: [a large bird with black and white feathers flying over water]\nImage 4: [a small bird with blue and brown feathers perched on a surface]\n\nRelation: bird\nExplanation: Both Image 1 and Image 4 feature a small bird with blue and brown feathers, suggesting a thematic connection through the depiction of avian subjects."
}

2025-07-28 14:06:18 - Successfully processed folder: Symbolic Connections in Chinese Culture two(animal, city, relation, East Asia, English), testid: 0
2025-07-28 14:06:18 - Processing folder: Symbolic Connections in Chinese Culture two(animal, city, relation, East Asia, English), testid: 1
2025-07-28 14:06:18 - Error in generate_response: CUDA out of memory. Tried to allocate 1.83 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 32.78 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:06:18 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.83 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 32.78 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Symbolic Connections in Chinese Culture two(animal, city, relation, East Asia, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:06:18 - Error occurred for folder: Symbolic Connections in Chinese Culture two(animal, city, relation, East Asia, English), testid: 1. See logs for details.
2025-07-28 14:06:18 - Processing folder: Symbolic Connections in Chinese Culture two(animal, city, relation, East Asia, English), testid: 2
Folder: Symbolic Connections in Chinese Culture two(animal, city, relation, East Asia, English)
TestID: 2
{
    "response": "**Image 1**: A Canada goose in mid-flight over water.\n**Image 2**: A traditional Chinese building complex with a bustling courtyard.\n**Image 3**: A small bird perched on a surface.\n\n**Image 4**: A small bird perched on a traditional Chinese building.\n\n**Relation**: Cultural and natural elements\n\n**Explanation**: Both Image 1 and Image 2 feature elements of nature and culture. Image 1 shows a Canada goose in flight, representing nature, while Image 2 depicts a traditional Chinese building, representing culture. Image 3 shows a small bird, similar to Image 1, and Image 4 places this bird on a traditional Chinese building, combining both elements."
}

2025-07-28 14:06:37 - Successfully processed folder: Symbolic Connections in Chinese Culture two(animal, city, relation, East Asia, English), testid: 2
2025-07-28 14:06:37 - Processing folder: Symbolic Connections in Chinese Culture two(animal, city, relation, East Asia, English), testid: 3
2025-07-28 14:06:37 - Error in generate_response: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 32.73 GiB is allocated by PyTorch, and 1.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:06:37 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 32.73 GiB is allocated by PyTorch, and 1.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Symbolic Connections in Chinese Culture two(animal, city, relation, East Asia, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:06:37 - Error occurred for folder: Symbolic Connections in Chinese Culture two(animal, city, relation, East Asia, English), testid: 3. See logs for details.
2025-07-28 14:06:37 - Processing folder: Symbolic Connections in Chinese Culture three(animal, city, relation, East Asia, English), testid: 0
2025-07-28 14:06:38 - Error in generate_response: CUDA out of memory. Tried to allocate 1.73 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 32.66 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:06:38 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.73 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 32.66 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Symbolic Connections in Chinese Culture three(animal, city, relation, East Asia, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:06:38 - Error occurred for folder: Symbolic Connections in Chinese Culture three(animal, city, relation, East Asia, English), testid: 0. See logs for details.
2025-07-28 14:06:38 - Processing folder: Symbolic Connections in Chinese Culture three(animal, city, relation, East Asia, English), testid: 1
2025-07-28 14:06:38 - Error in generate_response: CUDA out of memory. Tried to allocate 1.71 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 32.63 GiB is allocated by PyTorch, and 1.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:06:38 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.71 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 32.63 GiB is allocated by PyTorch, and 1.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Symbolic Connections in Chinese Culture three(animal, city, relation, East Asia, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:06:38 - Error occurred for folder: Symbolic Connections in Chinese Culture three(animal, city, relation, East Asia, English), testid: 1. See logs for details.
2025-07-28 14:06:38 - Processing folder: Symbolic Connections in Chinese Culture three(animal, city, relation, East Asia, English), testid: 2
2025-07-28 14:06:38 - Error in generate_response: CUDA out of memory. Tried to allocate 1.71 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 32.63 GiB is allocated by PyTorch, and 1.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:06:38 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.71 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 32.63 GiB is allocated by PyTorch, and 1.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Symbolic Connections in Chinese Culture three(animal, city, relation, East Asia, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:06:38 - Error occurred for folder: Symbolic Connections in Chinese Culture three(animal, city, relation, East Asia, English), testid: 2. See logs for details.
2025-07-28 14:06:38 - Processing folder: Symbolic Connections in Chinese Culture three(animal, city, relation, East Asia, English), testid: 3
2025-07-28 14:06:39 - Error in generate_response: CUDA out of memory. Tried to allocate 2.86 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.07 GiB is allocated by PyTorch, and 2.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:06:39 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.86 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.07 GiB is allocated by PyTorch, and 2.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Symbolic Connections in Chinese Culture three(animal, city, relation, East Asia, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:06:39 - Error occurred for folder: Symbolic Connections in Chinese Culture three(animal, city, relation, East Asia, English), testid: 3. See logs for details.
2025-07-28 14:06:39 - Processing folder: Symbolic Connections in Chinese Culture four(animal, city, relation, East Asia, English), testid: 0
Folder: Symbolic Connections in Chinese Culture four(animal, city, relation, East Asia, English)
TestID: 0
{
    "response": "Image 1: A colorful Mandarin duck swimming in water.\nImage 2: A scenic view of a river winding through a valley with mountains and a sunset.\nImage 3: A bird with its wings spread, perched on a branch.\n\n**Image 4**: A colorful parrot perched on a branch.\n**Relation**: Both images feature birds in natural settings.\n**Explanation**: Both Image 1 and Image 4 depict birds in their natural habitats, with Image 1 showing a Mandarin duck in water and Image 4 showing a parrot on a branch. The theme of birds in nature is consistent between the two pairs."
}

2025-07-28 14:06:56 - Successfully processed folder: Symbolic Connections in Chinese Culture four(animal, city, relation, East Asia, English), testid: 0
2025-07-28 14:06:56 - Processing folder: Symbolic Connections in Chinese Culture four(animal, city, relation, East Asia, English), testid: 1
2025-07-28 14:06:57 - Error in generate_response: CUDA out of memory. Tried to allocate 1.75 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 32.68 GiB is allocated by PyTorch, and 1.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:06:57 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.75 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 32.68 GiB is allocated by PyTorch, and 1.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Symbolic Connections in Chinese Culture four(animal, city, relation, East Asia, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:06:57 - Error occurred for folder: Symbolic Connections in Chinese Culture four(animal, city, relation, East Asia, English), testid: 1. See logs for details.
2025-07-28 14:06:57 - Processing folder: Symbolic Connections in Chinese Culture four(animal, city, relation, East Asia, English), testid: 2
Folder: Symbolic Connections in Chinese Culture four(animal, city, relation, East Asia, English)
TestID: 2
{
    "response": "Image 1: A bird with its wings spread wide, perched on a branch, appears to be calling out.\nImage 2: A traditional Chinese bridge illuminated at night, reflected in the water below, surrounded by modern buildings.\nImage 3: A colorful Mandarin duck swimming in water, with its vibrant plumage on display.\n\n**Image 4**: A colorful peacock with its tail feathers spread wide, standing on a grassy field.\n\n**Relation**: Nature and Wildlife\n\n**Explanation**: Both Image 1 and Image 3 depict animals in their natural habitats, showcasing their vibrant colors and behaviors. Similarly, Image 4 features a peacock, another bird known for its striking appearance, in a natural setting. The theme of nature and wildlife is consistent across all three images, highlighting the beauty and diversity of animal life."
}

2025-07-28 14:07:19 - Successfully processed folder: Symbolic Connections in Chinese Culture four(animal, city, relation, East Asia, English), testid: 2
2025-07-28 14:07:19 - Processing folder: Symbolic Connections in Chinese Culture four(animal, city, relation, East Asia, English), testid: 3
2025-07-28 14:07:20 - Error in generate_response: CUDA out of memory. Tried to allocate 1.88 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 32.83 GiB is allocated by PyTorch, and 1.07 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:07:20 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.88 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 32.83 GiB is allocated by PyTorch, and 1.07 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Symbolic Connections in Chinese Culture four(animal, city, relation, East Asia, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:07:20 - Error occurred for folder: Symbolic Connections in Chinese Culture four(animal, city, relation, East Asia, English), testid: 3. See logs for details.
2025-07-28 14:07:20 - Processing folder: Symbolic Connections in Chinese Culture five(animal, city, relation, East Asia, English), testid: 0
Folder: Symbolic Connections in Chinese Culture five(animal, city, relation, East Asia, English)
TestID: 0
{
    "response": "Image 1: A majestic phoenix with fiery wings and tail, symbolizing rebirth and renewal.\nImage 2: A brightly lit ancient Chinese building at night, showcasing traditional architecture.\nImage 3: A small owl perched on a branch, representing wisdom and quiet observation.\n- **Image 1**: [mythical creature]\n- **Image 2**: [ancient architecture]\n- **Image 3**: [wildlife]\n- **Image 4**: [mythical creature]\n- **Relation**: [mythical creatures]\n- **Explanation**: Both Image 1 and Image 4 feature mythical creatures, with Image 1 depicting a phoenix and Image 4 likely featuring another mythical being. The connection is established through the theme of mythology, where both images represent legendary and symbolic creatures from different cultural backgrounds."
}

2025-07-28 14:07:42 - Successfully processed folder: Symbolic Connections in Chinese Culture five(animal, city, relation, East Asia, English), testid: 0
2025-07-28 14:07:42 - Processing folder: Symbolic Connections in Chinese Culture five(animal, city, relation, East Asia, English), testid: 1
Folder: Symbolic Connections in Chinese Culture five(animal, city, relation, East Asia, English)
TestID: 1
{
    "response": "### Image 1\n**Image Concept**: A traditional Chinese pagoda illuminated at night, showcasing its architectural beauty and vibrant colors.\n\n### Image 2\n**Image Concept**: A majestic phoenix with fiery wings, symbolizing rebirth and power, set against a dramatic, fiery backdrop.\n\n### Image 3\n**Image Concept**: Traditional Chinese architecture by a serene water body, featuring pagodas and bridges, reflecting cultural heritage.\n\n### Image 4\n**Image Concept**: A serene Chinese garden with traditional pavilions and a tranquil pond, surrounded by lush greenery and pathways.\n\n### Relation\n**Keyword**: Cultural Heritage\n\n### Explanation\nBoth Image 1 and Image 2 share a theme of cultural heritage, with Image 1 depicting a traditional Chinese pagoda and Image 2 featuring a mythical phoenix, both representing historical and cultural significance. Similarly, Image 3 and Image 4 both emphasize traditional Chinese architecture and natural beauty, highlighting the cultural heritage and tranquility associated with such settings."
}

2025-07-28 14:08:08 - Successfully processed folder: Symbolic Connections in Chinese Culture five(animal, city, relation, East Asia, English), testid: 1
2025-07-28 14:08:08 - Processing folder: Symbolic Connections in Chinese Culture five(animal, city, relation, East Asia, English), testid: 2
Folder: Symbolic Connections in Chinese Culture five(animal, city, relation, East Asia, English)
TestID: 2
{
    "response": "Image 1: [a brown owl with white spots]\nImage 2: [a Chinese-style building]\nImage 3: [a phoenix]\nImage 4: [a phoenix]\nRelation: mythical\nExplanation: Both Image 3 and Image 4 depict mythical creatures. Image 3 shows a phoenix, a legendary bird often associated with fire and rebirth, while Image 4 also features a phoenix, reinforcing the theme of mythology. The connection between the two images is the presence of the phoenix, a symbol of immortality and transformation in various cultures."
}

2025-07-28 14:08:26 - Successfully processed folder: Symbolic Connections in Chinese Culture five(animal, city, relation, East Asia, English), testid: 2
2025-07-28 14:08:26 - Processing folder: Symbolic Connections in Chinese Culture five(animal, city, relation, East Asia, English), testid: 3
Folder: Symbolic Connections in Chinese Culture five(animal, city, relation, East Asia, English)
TestID: 3
{
    "response": "Image 1: [A serene Chinese palace complex with traditional architecture, surrounded by water and trees, reflecting a tranquil atmosphere.]\nImage 2: [A close-up of a brown owl perched on a branch, with detailed feathers and a focused gaze, set against a blurred green background.]\nImage 3: [A brightly lit Chinese pagoda at night, showcasing its intricate design and vibrant colors, with a bustling urban environment in the foreground.]\n\nImage 4: [A close-up of a brown owl perched on a branch, with detailed feathers and a focused gaze, set against a blurred green background.]\n\nRelation: Nature and Architecture\n\nExplanation: Both Image 1 and Image 3 depict architectural marvels, with Image 1 showing a traditional Chinese palace complex and Image 3 featuring a brightly lit Chinese pagoda. Image 2, on the other hand, captures a close-up of a brown owl perched on a branch, emphasizing the natural element. The connection between the pairs lies in the juxtaposition of human-made structures and the natural world, highlighting the harmony and contrast between architecture and nature."
}

2025-07-28 14:08:57 - Successfully processed folder: Symbolic Connections in Chinese Culture five(animal, city, relation, East Asia, English), testid: 3
2025-07-28 14:08:57 - Processing folder: Symbolic Connections in Chinese Culture six(animal, city, relation, East Asia, English), testid: 0
2025-07-28 14:08:58 - Error in generate_response: CUDA out of memory. Tried to allocate 2.86 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.07 GiB is allocated by PyTorch, and 2.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:08:58 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.86 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.07 GiB is allocated by PyTorch, and 2.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Symbolic Connections in Chinese Culture six(animal, city, relation, East Asia, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:08:58 - Error occurred for folder: Symbolic Connections in Chinese Culture six(animal, city, relation, East Asia, English), testid: 0. See logs for details.
2025-07-28 14:08:58 - Processing folder: Symbolic Connections in Chinese Culture six(animal, city, relation, East Asia, English), testid: 1
2025-07-28 14:08:58 - Error in generate_response: CUDA out of memory. Tried to allocate 2.86 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.07 GiB is allocated by PyTorch, and 2.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:08:58 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.86 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.07 GiB is allocated by PyTorch, and 2.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Symbolic Connections in Chinese Culture six(animal, city, relation, East Asia, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:08:58 - Error occurred for folder: Symbolic Connections in Chinese Culture six(animal, city, relation, East Asia, English), testid: 1. See logs for details.
2025-07-28 14:08:58 - Processing folder: Symbolic Connections in Chinese Culture six(animal, city, relation, East Asia, English), testid: 2
2025-07-28 14:08:58 - Error in generate_response: CUDA out of memory. Tried to allocate 2.86 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.07 GiB is allocated by PyTorch, and 2.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:08:58 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.86 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.07 GiB is allocated by PyTorch, and 2.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Symbolic Connections in Chinese Culture six(animal, city, relation, East Asia, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:08:58 - Error occurred for folder: Symbolic Connections in Chinese Culture six(animal, city, relation, East Asia, English), testid: 2. See logs for details.
2025-07-28 14:08:58 - Processing folder: Symbolic Connections in Chinese Culture six(animal, city, relation, East Asia, English), testid: 3
2025-07-28 14:08:58 - Error in generate_response: CUDA out of memory. Tried to allocate 2.89 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.07 GiB is allocated by PyTorch, and 2.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:08:58 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.89 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.07 GiB is allocated by PyTorch, and 2.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Symbolic Connections in Chinese Culture six(animal, city, relation, East Asia, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:08:58 - Error occurred for folder: Symbolic Connections in Chinese Culture six(animal, city, relation, East Asia, English), testid: 3. See logs for details.
2025-07-28 14:08:58 - Processing folder: Symbolic Connections in Chinese Culture seven(animal, city, relation, East Asia, English), testid: 0
2025-07-28 14:08:58 - Error in generate_response: CUDA out of memory. Tried to allocate 2.82 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.07 GiB is allocated by PyTorch, and 2.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:08:58 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.82 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.07 GiB is allocated by PyTorch, and 2.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Symbolic Connections in Chinese Culture seven(animal, city, relation, East Asia, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:08:58 - Error occurred for folder: Symbolic Connections in Chinese Culture seven(animal, city, relation, East Asia, English), testid: 0. See logs for details.
2025-07-28 14:08:58 - Processing folder: Symbolic Connections in Chinese Culture seven(animal, city, relation, East Asia, English), testid: 1
2025-07-28 14:08:58 - Error in generate_response: CUDA out of memory. Tried to allocate 2.86 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.07 GiB is allocated by PyTorch, and 2.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:08:58 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.86 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.07 GiB is allocated by PyTorch, and 2.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Symbolic Connections in Chinese Culture seven(animal, city, relation, East Asia, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:08:58 - Error occurred for folder: Symbolic Connections in Chinese Culture seven(animal, city, relation, East Asia, English), testid: 1. See logs for details.
2025-07-28 14:08:58 - Processing folder: Symbolic Connections in Chinese Culture seven(animal, city, relation, East Asia, English), testid: 2
2025-07-28 14:08:58 - Error in generate_response: CUDA out of memory. Tried to allocate 2.86 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.07 GiB is allocated by PyTorch, and 2.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:08:58 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.86 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.07 GiB is allocated by PyTorch, and 2.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Symbolic Connections in Chinese Culture seven(animal, city, relation, East Asia, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:08:58 - Error occurred for folder: Symbolic Connections in Chinese Culture seven(animal, city, relation, East Asia, English), testid: 2. See logs for details.
2025-07-28 14:08:58 - Processing folder: Symbolic Connections in Chinese Culture seven(animal, city, relation, East Asia, English), testid: 3
2025-07-28 14:08:59 - Error in generate_response: CUDA out of memory. Tried to allocate 2.82 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.07 GiB is allocated by PyTorch, and 2.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:08:59 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.82 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.07 GiB is allocated by PyTorch, and 2.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Symbolic Connections in Chinese Culture seven(animal, city, relation, East Asia, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:08:59 - Error occurred for folder: Symbolic Connections in Chinese Culture seven(animal, city, relation, East Asia, English), testid: 3. See logs for details.
2025-07-28 14:08:59 - Processing folder: Symbolic Connections in Chinese Culture eight(animal, city, relation, East Asia, English), testid: 0
2025-07-28 14:08:59 - Error in generate_response: CUDA out of memory. Tried to allocate 2.22 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 33.20 GiB is allocated by PyTorch, and 711.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:08:59 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.22 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 33.20 GiB is allocated by PyTorch, and 711.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Symbolic Connections in Chinese Culture eight(animal, city, relation, East Asia, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:08:59 - Error occurred for folder: Symbolic Connections in Chinese Culture eight(animal, city, relation, East Asia, English), testid: 0. See logs for details.
2025-07-28 14:08:59 - Processing folder: Symbolic Connections in Chinese Culture eight(animal, city, relation, East Asia, English), testid: 1
2025-07-28 14:08:59 - Error in generate_response: CUDA out of memory. Tried to allocate 2.18 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 33.16 GiB is allocated by PyTorch, and 753.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:08:59 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.18 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 33.16 GiB is allocated by PyTorch, and 753.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Symbolic Connections in Chinese Culture eight(animal, city, relation, East Asia, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:08:59 - Error occurred for folder: Symbolic Connections in Chinese Culture eight(animal, city, relation, East Asia, English), testid: 1. See logs for details.
2025-07-28 14:08:59 - Processing folder: Symbolic Connections in Chinese Culture eight(animal, city, relation, East Asia, English), testid: 2
2025-07-28 14:08:59 - Error in generate_response: CUDA out of memory. Tried to allocate 2.16 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 33.13 GiB is allocated by PyTorch, and 782.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:08:59 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.16 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 33.13 GiB is allocated by PyTorch, and 782.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Symbolic Connections in Chinese Culture eight(animal, city, relation, East Asia, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:08:59 - Error occurred for folder: Symbolic Connections in Chinese Culture eight(animal, city, relation, East Asia, English), testid: 2. See logs for details.
2025-07-28 14:08:59 - Processing folder: Symbolic Connections in Chinese Culture eight(animal, city, relation, East Asia, English), testid: 3
2025-07-28 14:08:59 - Error in generate_response: CUDA out of memory. Tried to allocate 2.88 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.07 GiB is allocated by PyTorch, and 2.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:08:59 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.88 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.07 GiB is allocated by PyTorch, and 2.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Symbolic Connections in Chinese Culture eight(animal, city, relation, East Asia, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:08:59 - Error occurred for folder: Symbolic Connections in Chinese Culture eight(animal, city, relation, East Asia, English), testid: 3. See logs for details.
2025-07-28 14:08:59 - Processing folder: Cultural Icons and National Significance four(people, country, metaphor, East Asia, English), testid: 0
2025-07-28 14:08:59 - Error in generate_response: CUDA out of memory. Tried to allocate 2.89 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.08 GiB is allocated by PyTorch, and 2.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:08:59 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.89 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.08 GiB is allocated by PyTorch, and 2.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Icons and National Significance four(people, country, metaphor, East Asia, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:08:59 - Error occurred for folder: Cultural Icons and National Significance four(people, country, metaphor, East Asia, English), testid: 0. See logs for details.
2025-07-28 14:08:59 - Processing folder: Cultural Icons and National Significance four(people, country, metaphor, East Asia, English), testid: 1
2025-07-28 14:08:59 - Error in generate_response: CUDA out of memory. Tried to allocate 2.91 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.08 GiB is allocated by PyTorch, and 2.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:08:59 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.91 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.08 GiB is allocated by PyTorch, and 2.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Icons and National Significance four(people, country, metaphor, East Asia, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:08:59 - Error occurred for folder: Cultural Icons and National Significance four(people, country, metaphor, East Asia, English), testid: 1. See logs for details.
2025-07-28 14:08:59 - Processing folder: Cultural Icons and National Significance four(people, country, metaphor, East Asia, English), testid: 2
2025-07-28 14:09:00 - Error in generate_response: CUDA out of memory. Tried to allocate 2.87 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.07 GiB is allocated by PyTorch, and 2.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:09:00 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.87 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.07 GiB is allocated by PyTorch, and 2.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Icons and National Significance four(people, country, metaphor, East Asia, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:09:00 - Error occurred for folder: Cultural Icons and National Significance four(people, country, metaphor, East Asia, English), testid: 2. See logs for details.
2025-07-28 14:09:00 - Processing folder: Cultural Icons and National Significance four(people, country, metaphor, East Asia, English), testid: 3
2025-07-28 14:09:00 - Error in generate_response: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.08 GiB is allocated by PyTorch, and 2.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:09:00 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.08 GiB is allocated by PyTorch, and 2.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Icons and National Significance four(people, country, metaphor, East Asia, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:09:00 - Error occurred for folder: Cultural Icons and National Significance four(people, country, metaphor, East Asia, English), testid: 3. See logs for details.
2025-07-28 14:09:00 - Processing folder: Cultural Icons and National Significance five(people, country, metaphor, East Asia, English), testid: 0
2025-07-28 14:09:00 - Error in generate_response: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 33.24 GiB is allocated by PyTorch, and 671.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:09:00 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 33.24 GiB is allocated by PyTorch, and 671.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Icons and National Significance five(people, country, metaphor, East Asia, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:09:00 - Error occurred for folder: Cultural Icons and National Significance five(people, country, metaphor, East Asia, English), testid: 0. See logs for details.
2025-07-28 14:09:00 - Processing folder: Cultural Icons and National Significance five(people, country, metaphor, East Asia, English), testid: 1
2025-07-28 14:09:00 - Error in generate_response: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.08 GiB is allocated by PyTorch, and 2.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:09:00 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.08 GiB is allocated by PyTorch, and 2.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Icons and National Significance five(people, country, metaphor, East Asia, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:09:00 - Error occurred for folder: Cultural Icons and National Significance five(people, country, metaphor, East Asia, English), testid: 1. See logs for details.
2025-07-28 14:09:00 - Processing folder: Cultural Icons and National Significance five(people, country, metaphor, East Asia, English), testid: 2
2025-07-28 14:09:00 - Error in generate_response: CUDA out of memory. Tried to allocate 2.29 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 33.28 GiB is allocated by PyTorch, and 632.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:09:00 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.29 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 33.28 GiB is allocated by PyTorch, and 632.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Icons and National Significance five(people, country, metaphor, East Asia, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:09:00 - Error occurred for folder: Cultural Icons and National Significance five(people, country, metaphor, East Asia, English), testid: 2. See logs for details.
2025-07-28 14:09:00 - Processing folder: Cultural Icons and National Significance five(people, country, metaphor, East Asia, English), testid: 3
2025-07-28 14:09:00 - Error in generate_response: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 33.24 GiB is allocated by PyTorch, and 671.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:09:00 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 33.24 GiB is allocated by PyTorch, and 671.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Icons and National Significance five(people, country, metaphor, East Asia, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:09:00 - Error occurred for folder: Cultural Icons and National Significance five(people, country, metaphor, East Asia, English), testid: 3. See logs for details.
2025-07-28 14:09:00 - Processing folder: Cultural Icons and National Significance six(people, country, metaphor, East Asia, English), testid: 0
2025-07-28 14:09:01 - Error in generate_response: CUDA out of memory. Tried to allocate 2.33 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 33.32 GiB is allocated by PyTorch, and 591.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:09:01 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.33 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 33.32 GiB is allocated by PyTorch, and 591.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Icons and National Significance six(people, country, metaphor, East Asia, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:09:01 - Error occurred for folder: Cultural Icons and National Significance six(people, country, metaphor, East Asia, English), testid: 0. See logs for details.
2025-07-28 14:09:01 - Processing folder: Cultural Icons and National Significance six(people, country, metaphor, East Asia, English), testid: 1
2025-07-28 14:09:01 - Error in generate_response: CUDA out of memory. Tried to allocate 2.34 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 33.33 GiB is allocated by PyTorch, and 577.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:09:01 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.34 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 33.33 GiB is allocated by PyTorch, and 577.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Icons and National Significance six(people, country, metaphor, East Asia, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:09:01 - Error occurred for folder: Cultural Icons and National Significance six(people, country, metaphor, East Asia, English), testid: 1. See logs for details.
2025-07-28 14:09:01 - Processing folder: Cultural Icons and National Significance six(people, country, metaphor, East Asia, English), testid: 2
2025-07-28 14:09:02 - Error in generate_response: CUDA out of memory. Tried to allocate 3.58 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.14 GiB is allocated by PyTorch, and 2.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:09:02 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.58 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.14 GiB is allocated by PyTorch, and 2.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Icons and National Significance six(people, country, metaphor, East Asia, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:09:02 - Error occurred for folder: Cultural Icons and National Significance six(people, country, metaphor, East Asia, English), testid: 2. See logs for details.
2025-07-28 14:09:02 - Processing folder: Cultural Icons and National Significance six(people, country, metaphor, East Asia, English), testid: 3
2025-07-28 14:09:03 - Error in generate_response: CUDA out of memory. Tried to allocate 1.77 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 32.70 GiB is allocated by PyTorch, and 1.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:09:03 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.77 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 32.70 GiB is allocated by PyTorch, and 1.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Icons and National Significance six(people, country, metaphor, East Asia, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:09:03 - Error occurred for folder: Cultural Icons and National Significance six(people, country, metaphor, East Asia, English), testid: 3. See logs for details.
2025-07-28 14:09:03 - Processing folder: Cultural Icons and National Significance seven(people, country, metaphor, East Asia, English), testid: 0
Folder: Cultural Icons and National Significance seven(people, country, metaphor, East Asia, English)
TestID: 0
{
    "response": "### Image 1\n**Image Concept**: A statue of an ancient Chinese philosopher, likely Confucius, depicted with traditional attire and a serene expression.\n\n### Image 2\n**Image Concept**: The Temple of Heaven, a significant historical and religious site in China, characterized by its distinctive triple-tiered roof and intricate architectural design.\n\n### Image 3\n**Image Concept**: A portrait of a historical figure in elaborate military attire, suggesting a person of high rank or importance, possibly from the 19th century.\n\n### Image 4\n**Image Concept**: A portrait of a historical figure in traditional Chinese attire, with a focus on the clothing and accessories that signify status and cultural heritage.\n\n### Relation\n**Theme**: Historical and Cultural Significance\n\n### Explanation\nBoth Image 1 and Image 2 share a theme of historical and cultural significance, focusing on important figures and landmarks from Chinese history. Image 1 depicts a statue of Confucius, a revered philosopher, while Image 2 showcases the Temple of Heaven, a significant religious and architectural site. Similarly, Image 3 and Image 4 both highlight historical figures, with Image 3 featuring a person in military attire and Image 4 presenting a figure in traditional Chinese clothing. The connection between these pairs lies in their emphasis on historical and cultural heritage, showcasing influential individuals and their contributions to Chinese history."
}

2025-07-28 14:09:38 - Successfully processed folder: Cultural Icons and National Significance seven(people, country, metaphor, East Asia, English), testid: 0
2025-07-28 14:09:38 - Processing folder: Cultural Icons and National Significance seven(people, country, metaphor, East Asia, English), testid: 1
Folder: Cultural Icons and National Significance seven(people, country, metaphor, East Asia, English)
TestID: 1
{
    "response": "Image 1: [a temple with a blue roof and golden top]\nImage 2: [a statue of a bearded man]\nImage 3: [a white building with a green roof]\nImage 4: [a white building with a blue roof and golden top]\n\nRelation: cultural landmarks\n\nExplanation: Both Image 1 and Image 3 depict significant cultural landmarks, with Image 1 showing a temple and Image 3 showing a traditional building. Image 2, while not a landmark, features a statue of a historical figure, which complements the cultural theme. The connection between the pairs is the emphasis on cultural heritage and historical significance."
}

2025-07-28 14:09:57 - Successfully processed folder: Cultural Icons and National Significance seven(people, country, metaphor, East Asia, English), testid: 1
2025-07-28 14:09:57 - Processing folder: Cultural Icons and National Significance seven(people, country, metaphor, East Asia, English), testid: 2
2025-07-28 14:09:58 - Error in generate_response: CUDA out of memory. Tried to allocate 1.47 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 32.38 GiB is allocated by PyTorch, and 1.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:09:58 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.47 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 32.38 GiB is allocated by PyTorch, and 1.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Icons and National Significance seven(people, country, metaphor, East Asia, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:09:58 - Error occurred for folder: Cultural Icons and National Significance seven(people, country, metaphor, East Asia, English), testid: 2. See logs for details.
2025-07-28 14:09:58 - Processing folder: Cultural Icons and National Significance seven(people, country, metaphor, East Asia, English), testid: 3
Folder: Cultural Icons and National Significance seven(people, country, metaphor, East Asia, English)
TestID: 3
{
    "response": "Image 1: [a traditional Japanese castle with white walls and a green roof, surrounded by trees and a stone wall, with ornate street lamps in the foreground]\nImage 2: [a portrait of a man in a military uniform with gold embellishments and a red sash, holding a sword]\nImage 3: [a large, circular Chinese temple with three tiers and a blue roof, surrounded by a white fence and a clear blue sky]\nImage 4: [a large, circular Chinese temple with three tiers and a blue roof, surrounded by a white fence and a clear blue sky]\n\nRelation: Cultural Heritage\n\nExplanation: Both Image 1 and Image 2 depict elements of Japanese and Chinese cultural heritage, respectively. Image 1 shows a traditional Japanese castle, a symbol of historical and architectural significance in Japan. Image 2 features a portrait of a man in a military uniform, which could represent a historical figure or a symbol of military heritage. Image 3 and Image 4 both showcase a large, circular Chinese temple, emphasizing the architectural and cultural importance of such structures in China. The connection between Image 1 and Image 2 is the focus on historical and cultural heritage, while Image 3 and Image 4 highlight the architectural beauty and cultural significance of Chinese temples."
}

2025-07-28 14:10:33 - Successfully processed folder: Cultural Icons and National Significance seven(people, country, metaphor, East Asia, English), testid: 3
2025-07-28 14:10:33 - Processing folder: Cultural Icons and National Significance eight(people, country, metaphor, East Asia, English), testid: 0
2025-07-28 14:10:33 - Error in generate_response: CUDA out of memory. Tried to allocate 3.77 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.16 GiB is allocated by PyTorch, and 2.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:10:33 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.77 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.16 GiB is allocated by PyTorch, and 2.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Icons and National Significance eight(people, country, metaphor, East Asia, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:10:33 - Error occurred for folder: Cultural Icons and National Significance eight(people, country, metaphor, East Asia, English), testid: 0. See logs for details.
2025-07-28 14:10:33 - Processing folder: Cultural Icons and National Significance eight(people, country, metaphor, East Asia, English), testid: 1
2025-07-28 14:10:33 - Error in generate_response: CUDA out of memory. Tried to allocate 2.85 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.07 GiB is allocated by PyTorch, and 2.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:10:33 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.85 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.07 GiB is allocated by PyTorch, and 2.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Icons and National Significance eight(people, country, metaphor, East Asia, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:10:33 - Error occurred for folder: Cultural Icons and National Significance eight(people, country, metaphor, East Asia, English), testid: 1. See logs for details.
2025-07-28 14:10:33 - Processing folder: Cultural Icons and National Significance eight(people, country, metaphor, East Asia, English), testid: 2
2025-07-28 14:10:33 - Error in generate_response: CUDA out of memory. Tried to allocate 3.77 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.16 GiB is allocated by PyTorch, and 2.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:10:33 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.77 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.16 GiB is allocated by PyTorch, and 2.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Icons and National Significance eight(people, country, metaphor, East Asia, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:10:33 - Error occurred for folder: Cultural Icons and National Significance eight(people, country, metaphor, East Asia, English), testid: 2. See logs for details.
2025-07-28 14:10:33 - Processing folder: Cultural Icons and National Significance eight(people, country, metaphor, East Asia, English), testid: 3
2025-07-28 14:10:34 - Error in generate_response: CUDA out of memory. Tried to allocate 3.82 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.16 GiB is allocated by PyTorch, and 2.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:10:34 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.82 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.16 GiB is allocated by PyTorch, and 2.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Icons and National Significance eight(people, country, metaphor, East Asia, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:10:34 - Error occurred for folder: Cultural Icons and National Significance eight(people, country, metaphor, East Asia, English), testid: 3. See logs for details.
2025-07-28 14:10:34 - Processing folder: National Anthems and Their Associated Transit Systems two(country, city, relation, East Asia, English), testid: 0
Folder: National Anthems and Their Associated Transit Systems two(country, city, relation, East Asia, English)
TestID: 0
{
    "response": "**Image 1**: This image is a colorful infographic in Korean, featuring a floral design and a South Korean flag. It appears to be a list or guide, possibly related to cultural or national themes, given the presence of the flag.\n\n**Image 2**: This image is a detailed map of the Seoul Metro system, showing various metro lines and stations in the Seoul metropolitan area. It is a complex diagram with numerous lines and labels.\n\n**Image 3**: This image is a sheet of music titled \"Aegukga,\" which is the national anthem of South Korea. It includes musical notation and lyrics in Korean.\n\n**Image 4**: This image is a colorful infographic in Korean, featuring a floral design and a South Korean flag. It appears to be a list or guide, possibly related to cultural or national themes, given the presence of the flag.\n\n**Relation**: Both images are related to South Korea.\n\n**Explanation**: Both Image 1 and Image 4 are infographics in Korean with a floral design and a South Korean flag, suggesting a thematic connection to South Korean culture or national pride. Image 2, while not directly related to the cultural theme, shares the South Korean flag, reinforcing the connection to South Korea."
}

2025-07-28 14:11:01 - Successfully processed folder: National Anthems and Their Associated Transit Systems two(country, city, relation, East Asia, English), testid: 0
2025-07-28 14:11:01 - Processing folder: National Anthems and Their Associated Transit Systems two(country, city, relation, East Asia, English), testid: 1
Folder: National Anthems and Their Associated Transit Systems two(country, city, relation, East Asia, English)
TestID: 1
{
    "response": "### Image 1\n**Image Concept**: A detailed map of the Seoul Metro system, showcasing various lines and stations.\n\n### Image 2\n**Image Concept**: A colorful infographic with Korean text, featuring a South Korean flag and floral decorations.\n\n### Image 3\n**Image Concept**: A simplified subway map highlighting specific lines and stations, with a legend indicating different routes.\n\n### Image 4\n**Image Concept**: A simplified subway map highlighting specific lines and stations, with a legend indicating different routes.\n\n### Relation\n**Keyword**: Subway Map\n\n### Explanation\nBoth Image 1 and Image 3 are subway maps, focusing on the layout and connectivity of metro lines. Image 1 provides a comprehensive view of the Seoul Metro system, while Image 3 offers a more focused view of specific lines and stations. Image 4 mirrors this relationship by presenting a simplified version of a subway map, emphasizing the same themes of connectivity and route identification."
}

2025-07-28 14:11:26 - Successfully processed folder: National Anthems and Their Associated Transit Systems two(country, city, relation, East Asia, English), testid: 1
2025-07-28 14:11:26 - Processing folder: National Anthems and Their Associated Transit Systems two(country, city, relation, East Asia, English), testid: 2
Folder: National Anthems and Their Associated Transit Systems two(country, city, relation, East Asia, English)
TestID: 2
{
    "response": "### Image 1\n**Image Concept**: Sheet music for the song \"Aegukka\" with lyrics in Korean.\n\n### Image 2\n**Image Concept**: A subway map showing routes and stations in Seoul, South Korea.\n\n### Image 3\n**Image Concept**: A page with Korean text, likely lyrics or a poem, accompanied by a South Korean flag and floral decorations.\n\n### Image 4\n**Image Concept**: A page with Korean text, likely lyrics or a poem, accompanied by a South Korean flag and floral decorations.\n\n### Relation\n**Keyword**: Cultural Connection\n\n### Explanation\nBoth Image 1 and Image 2 share a cultural connection through their representation of South Korea. Image 1 features the song \"Aegukka,\" which is a patriotic song in South Korea, while Image 2 shows a subway map of Seoul, highlighting the country's infrastructure. Image 3 also emphasizes South Korean culture with its text and flag. Image 4 mirrors this by presenting another set of Korean text, maintaining the cultural theme."
}

2025-07-28 14:11:55 - Successfully processed folder: National Anthems and Their Associated Transit Systems two(country, city, relation, East Asia, English), testid: 2
2025-07-28 14:11:55 - Processing folder: National Anthems and Their Associated Transit Systems two(country, city, relation, East Asia, English), testid: 3
Folder: National Anthems and Their Associated Transit Systems two(country, city, relation, East Asia, English)
TestID: 3
{
    "response": "### Image 1\n**Image Concept**: A subway map of the Seoul Metro system, highlighting the Sinjju and Seoul lines.\n\n### Image 2\n**Image Concept**: Sheet music for the song \"Aegukga,\" with musical notation and lyrics.\n\n### Image 3\n**Image Concept**: A detailed map of the Seoul Metro system, showing all lines and stations.\n\n### Image 4\n**Image Concept**: A detailed map of the Seoul Metro system, showing all lines and stations.\n\n### Relation\n**Keyword**: Metro System\n\n### Explanation\nBoth Image 1 and Image 3 depict the Seoul Metro system, focusing on different aspects. Image 1 highlights specific lines (Sinjju and Seoul) with a simplified representation, while Image 3 provides a comprehensive view of all lines and stations. Image 4 mirrors this relationship by presenting a detailed map of the entire Seoul Metro system, similar to Image 3, but without the specific focus on the Sinjju and Seoul lines as in Image 1."
}

2025-07-28 14:12:26 - Successfully processed folder: National Anthems and Their Associated Transit Systems two(country, city, relation, East Asia, English), testid: 3
2025-07-28 14:12:26 - Error opening image ./img/National Anthems and Their Associated Transit Systems three(country, city, relation, Non-English European, English)/Lyrics of 'God Save the Queen'.jpg: cannot identify image file "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/img/National Anthems and Their Associated Transit Systems three(country, city, relation, Non-English European, English)/Lyrics of 'God Save the Queen'.jpg"
2025-07-28 14:12:26 - Error opening image ./img/National Anthems and Their Associated Transit Systems three(country, city, relation, Non-English European, English)/A map of the London Underground.jpg: cannot identify image file '/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/img/National Anthems and Their Associated Transit Systems three(country, city, relation, Non-English European, English)/A map of the London Underground.jpg'
2025-07-28 14:12:26 - Four valid images are required for processing.
2025-07-28 14:12:26 - Processing folder: National Anthems and Their Associated Transit Systems four(country, city, relation, other, English), testid: 0
2025-07-28 14:12:27 - Error in generate_response: CUDA out of memory. Tried to allocate 2.86 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.07 GiB is allocated by PyTorch, and 2.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:12:27 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.86 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.07 GiB is allocated by PyTorch, and 2.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: National Anthems and Their Associated Transit Systems four(country, city, relation, other, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:12:27 - Error occurred for folder: National Anthems and Their Associated Transit Systems four(country, city, relation, other, English), testid: 0. See logs for details.
2025-07-28 14:12:27 - Processing folder: National Anthems and Their Associated Transit Systems four(country, city, relation, other, English), testid: 1
2025-07-28 14:12:27 - Error in generate_response: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.08 GiB is allocated by PyTorch, and 2.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:12:27 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.08 GiB is allocated by PyTorch, and 2.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: National Anthems and Their Associated Transit Systems four(country, city, relation, other, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:12:27 - Error occurred for folder: National Anthems and Their Associated Transit Systems four(country, city, relation, other, English), testid: 1. See logs for details.
2025-07-28 14:12:27 - Processing folder: National Anthems and Their Associated Transit Systems four(country, city, relation, other, English), testid: 2
2025-07-28 14:12:28 - Error in generate_response: CUDA out of memory. Tried to allocate 2.87 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.07 GiB is allocated by PyTorch, and 2.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:12:28 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.87 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.07 GiB is allocated by PyTorch, and 2.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: National Anthems and Their Associated Transit Systems four(country, city, relation, other, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:12:28 - Error occurred for folder: National Anthems and Their Associated Transit Systems four(country, city, relation, other, English), testid: 2. See logs for details.
2025-07-28 14:12:28 - Processing folder: National Anthems and Their Associated Transit Systems four(country, city, relation, other, English), testid: 3
2025-07-28 14:12:29 - Error in generate_response: CUDA out of memory. Tried to allocate 2.83 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.07 GiB is allocated by PyTorch, and 2.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:12:29 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.83 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.07 GiB is allocated by PyTorch, and 2.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: National Anthems and Their Associated Transit Systems four(country, city, relation, other, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:12:29 - Error occurred for folder: National Anthems and Their Associated Transit Systems four(country, city, relation, other, English), testid: 3. See logs for details.
2025-07-28 14:12:29 - Error opening image ./img/National Anthems and Their Associated Transit Systems five(country, city, relation, South Asia and South-East Asia, English)/Lyrics of 'Jana Gana Mana'.jpg: cannot identify image file "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/img/National Anthems and Their Associated Transit Systems five(country, city, relation, South Asia and South-East Asia, English)/Lyrics of 'Jana Gana Mana'.jpg"
2025-07-28 14:12:29 - Error opening image ./img/National Anthems and Their Associated Transit Systems five(country, city, relation, South Asia and South-East Asia, English)/A map of the Delhi Metro.jpg: cannot identify image file '/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/img/National Anthems and Their Associated Transit Systems five(country, city, relation, South Asia and South-East Asia, English)/A map of the Delhi Metro.jpg'
2025-07-28 14:12:29 - Error opening image ./img/National Anthems and Their Associated Transit Systems five(country, city, relation, South Asia and South-East Asia, English)/Lyrics of 'The Star-Spangled Banner'.jpg: cannot identify image file "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/img/National Anthems and Their Associated Transit Systems five(country, city, relation, South Asia and South-East Asia, English)/Lyrics of 'The Star-Spangled Banner'.jpg"
2025-07-28 14:12:29 - Error opening image ./img/National Anthems and Their Associated Transit Systems five(country, city, relation, South Asia and South-East Asia, English)/A map of the New York City subway.jpg: cannot identify image file '/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/img/National Anthems and Their Associated Transit Systems five(country, city, relation, South Asia and South-East Asia, English)/A map of the New York City subway.jpg'
2025-07-28 14:12:29 - Four valid images are required for processing.
2025-07-28 14:12:29 - Processing folder: National Anthems and Their Associated Transit Systems six(country, city, relation, East Asia, English), testid: 0
2025-07-28 14:12:30 - Error in generate_response: CUDA out of memory. Tried to allocate 3.51 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.13 GiB is allocated by PyTorch, and 2.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:12:30 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.51 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.13 GiB is allocated by PyTorch, and 2.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: National Anthems and Their Associated Transit Systems six(country, city, relation, East Asia, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:12:30 - Error occurred for folder: National Anthems and Their Associated Transit Systems six(country, city, relation, East Asia, English), testid: 0. See logs for details.
2025-07-28 14:12:30 - Processing folder: National Anthems and Their Associated Transit Systems six(country, city, relation, East Asia, English), testid: 1
2025-07-28 14:12:31 - Error in generate_response: CUDA out of memory. Tried to allocate 2.88 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.07 GiB is allocated by PyTorch, and 2.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:12:31 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.88 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.07 GiB is allocated by PyTorch, and 2.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: National Anthems and Their Associated Transit Systems six(country, city, relation, East Asia, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:12:31 - Error occurred for folder: National Anthems and Their Associated Transit Systems six(country, city, relation, East Asia, English), testid: 1. See logs for details.
2025-07-28 14:12:31 - Processing folder: National Anthems and Their Associated Transit Systems six(country, city, relation, East Asia, English), testid: 2
2025-07-28 14:12:31 - Error in generate_response: CUDA out of memory. Tried to allocate 4.16 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.19 GiB is allocated by PyTorch, and 2.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:12:31 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.16 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.19 GiB is allocated by PyTorch, and 2.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: National Anthems and Their Associated Transit Systems six(country, city, relation, East Asia, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:12:31 - Error occurred for folder: National Anthems and Their Associated Transit Systems six(country, city, relation, East Asia, English), testid: 2. See logs for details.
2025-07-28 14:12:31 - Processing folder: National Anthems and Their Associated Transit Systems six(country, city, relation, East Asia, English), testid: 3
2025-07-28 14:12:31 - Error in generate_response: CUDA out of memory. Tried to allocate 1.45 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 32.35 GiB is allocated by PyTorch, and 1.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:12:31 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.45 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 32.35 GiB is allocated by PyTorch, and 1.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: National Anthems and Their Associated Transit Systems six(country, city, relation, East Asia, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:12:31 - Error occurred for folder: National Anthems and Their Associated Transit Systems six(country, city, relation, East Asia, English), testid: 3. See logs for details.
2025-07-28 14:12:31 - Processing folder: Symbolic Representation two(country, city, relation, USAEnglish, English), testid: 0
2025-07-28 14:12:31 - Error in generate_response: CUDA out of memory. Tried to allocate 1.64 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 32.56 GiB is allocated by PyTorch, and 1.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:12:31 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.64 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 32.56 GiB is allocated by PyTorch, and 1.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Symbolic Representation two(country, city, relation, USAEnglish, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:12:31 - Error occurred for folder: Symbolic Representation two(country, city, relation, USAEnglish, English), testid: 0. See logs for details.
2025-07-28 14:12:31 - Processing folder: Symbolic Representation two(country, city, relation, USAEnglish, English), testid: 1
2025-07-28 14:12:32 - Error in generate_response: CUDA out of memory. Tried to allocate 3.01 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.09 GiB is allocated by PyTorch, and 2.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:12:32 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.01 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.09 GiB is allocated by PyTorch, and 2.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Symbolic Representation two(country, city, relation, USAEnglish, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:12:32 - Error occurred for folder: Symbolic Representation two(country, city, relation, USAEnglish, English), testid: 1. See logs for details.
2025-07-28 14:12:32 - Processing folder: Symbolic Representation two(country, city, relation, USAEnglish, English), testid: 2
2025-07-28 14:12:32 - Error in generate_response: CUDA out of memory. Tried to allocate 3.19 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.10 GiB is allocated by PyTorch, and 2.79 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:12:32 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.19 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.10 GiB is allocated by PyTorch, and 2.79 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Symbolic Representation two(country, city, relation, USAEnglish, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:12:32 - Error occurred for folder: Symbolic Representation two(country, city, relation, USAEnglish, English), testid: 2. See logs for details.
2025-07-28 14:12:32 - Processing folder: Symbolic Representation two(country, city, relation, USAEnglish, English), testid: 3
2025-07-28 14:12:32 - Error in generate_response: CUDA out of memory. Tried to allocate 4.41 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.21 GiB is allocated by PyTorch, and 2.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:12:32 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.41 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.21 GiB is allocated by PyTorch, and 2.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Symbolic Representation two(country, city, relation, USAEnglish, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:12:32 - Error occurred for folder: Symbolic Representation two(country, city, relation, USAEnglish, English), testid: 3. See logs for details.
2025-07-28 14:12:32 - Processing folder: Iconic Monuments and Transit Systems in Chinese Cities two(animal, city, relation, East Asia, English), testid: 0
2025-07-28 14:12:32 - Error in generate_response: CUDA out of memory. Tried to allocate 2.45 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 33.45 GiB is allocated by PyTorch, and 455.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:12:32 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.45 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 33.45 GiB is allocated by PyTorch, and 455.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Iconic Monuments and Transit Systems in Chinese Cities two(animal, city, relation, East Asia, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:12:32 - Error occurred for folder: Iconic Monuments and Transit Systems in Chinese Cities two(animal, city, relation, East Asia, English), testid: 0. See logs for details.
2025-07-28 14:12:32 - Processing folder: Iconic Monuments and Transit Systems in Chinese Cities two(animal, city, relation, East Asia, English), testid: 1
Folder: Iconic Monuments and Transit Systems in Chinese Cities two(animal, city, relation, East Asia, English)
TestID: 1
{
    "response": "Image 1: A train is traveling on a curved track surrounded by lush greenery, with a cityscape visible in the background.\nImage 2: A statue of a goat with multiple smaller goats at its base, set against a backdrop of trees and a clear sky.\nImage 3: A high-speed train is moving on an elevated track, with a flat landscape and distant buildings in the background.\n\n**Image 4**: A statue of a goat with multiple smaller goats at its base, set against a backdrop of trees and a clear sky.\n\n**Relation**: Statue\n\n**Explanation**: Both Image 1 and Image 4 feature a central figure (a train in Image 1 and a statue in Image 4) that is the focal point of the image. The trains in Image 1 and Image 3 are both in motion, symbolizing movement and progress, while the statue in Image 4 represents a static, enduring symbol. The greenery in Image 1 and the trees in Image 2 both contribute to a natural setting, while the clear sky in Image 2 and the flat landscape in Image 3 provide a serene backdrop. The curved tracks in Image 1 and the elevated track in Image 3 both represent transportation infrastructure, connecting different elements of the environment."
}

2025-07-28 14:13:06 - Successfully processed folder: Iconic Monuments and Transit Systems in Chinese Cities two(animal, city, relation, East Asia, English), testid: 1
2025-07-28 14:13:06 - Processing folder: Iconic Monuments and Transit Systems in Chinese Cities two(animal, city, relation, East Asia, English), testid: 2
Folder: Iconic Monuments and Transit Systems in Chinese Cities two(animal, city, relation, East Asia, English)
TestID: 2
{
    "response": "Image 1: [cityscape at dusk with illuminated skyscrapers reflecting on water]\nImage 2: [high-speed train on elevated tracks]\nImage 3: [statue of a goat with smaller goats]\nImage 4: [statue of a goat with smaller goats]\n\nRelation: Urban Development\nExplanation: Both Image 1 and Image 2 depict elements of modern urban development, with Image 1 showcasing a cityscape at dusk and Image 2 featuring a high-speed train, symbolizing advanced transportation infrastructure. Image 3, while different in theme, also represents development through its intricate sculpture, which could be seen as a metaphor for human achievement and progress."
}

2025-07-28 14:13:25 - Successfully processed folder: Iconic Monuments and Transit Systems in Chinese Cities two(animal, city, relation, East Asia, English), testid: 2
2025-07-28 14:13:25 - Processing folder: Iconic Monuments and Transit Systems in Chinese Cities two(animal, city, relation, East Asia, English), testid: 3
2025-07-28 14:13:26 - Error in generate_response: CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 32.61 GiB is allocated by PyTorch, and 1.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:13:26 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 32.61 GiB is allocated by PyTorch, and 1.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Iconic Monuments and Transit Systems in Chinese Cities two(animal, city, relation, East Asia, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:13:26 - Error occurred for folder: Iconic Monuments and Transit Systems in Chinese Cities two(animal, city, relation, East Asia, English), testid: 3. See logs for details.
2025-07-28 14:13:26 - Processing folder: Landmarks and Their Associated Transit Systems(country, city, relation, Non-English European, English), testid: 0
2025-07-28 14:13:26 - Error in generate_response: CUDA out of memory. Tried to allocate 4.67 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.24 GiB is allocated by PyTorch, and 2.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:13:26 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.67 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.24 GiB is allocated by PyTorch, and 2.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Landmarks and Their Associated Transit Systems(country, city, relation, Non-English European, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:13:26 - Error occurred for folder: Landmarks and Their Associated Transit Systems(country, city, relation, Non-English European, English), testid: 0. See logs for details.
2025-07-28 14:13:26 - Processing folder: Landmarks and Their Associated Transit Systems(country, city, relation, Non-English European, English), testid: 1
2025-07-28 14:13:26 - Error in generate_response: CUDA out of memory. Tried to allocate 4.65 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.23 GiB is allocated by PyTorch, and 2.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:13:26 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.65 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.23 GiB is allocated by PyTorch, and 2.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Landmarks and Their Associated Transit Systems(country, city, relation, Non-English European, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:13:26 - Error occurred for folder: Landmarks and Their Associated Transit Systems(country, city, relation, Non-English European, English), testid: 1. See logs for details.
2025-07-28 14:13:26 - Processing folder: Landmarks and Their Associated Transit Systems(country, city, relation, Non-English European, English), testid: 2
2025-07-28 14:13:26 - Error in generate_response: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.08 GiB is allocated by PyTorch, and 2.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:13:26 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.08 GiB is allocated by PyTorch, and 2.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Landmarks and Their Associated Transit Systems(country, city, relation, Non-English European, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:13:26 - Error occurred for folder: Landmarks and Their Associated Transit Systems(country, city, relation, Non-English European, English), testid: 2. See logs for details.
2025-07-28 14:13:26 - Processing folder: Landmarks and Their Associated Transit Systems(country, city, relation, Non-English European, English), testid: 3
2025-07-28 14:13:27 - Error in generate_response: CUDA out of memory. Tried to allocate 4.62 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.23 GiB is allocated by PyTorch, and 2.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:13:27 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.62 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.23 GiB is allocated by PyTorch, and 2.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Landmarks and Their Associated Transit Systems(country, city, relation, Non-English European, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:13:27 - Error occurred for folder: Landmarks and Their Associated Transit Systems(country, city, relation, Non-English European, English), testid: 3. See logs for details.
2025-07-28 14:13:27 - Processing folder: Landmarks and Their Associated Transit Systems two(country, city, relation, East Asia, English), testid: 0
2025-07-28 14:13:27 - Error in generate_response: CUDA out of memory. Tried to allocate 2.82 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.07 GiB is allocated by PyTorch, and 2.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:13:27 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.82 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.07 GiB is allocated by PyTorch, and 2.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Landmarks and Their Associated Transit Systems two(country, city, relation, East Asia, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:13:27 - Error occurred for folder: Landmarks and Their Associated Transit Systems two(country, city, relation, East Asia, English), testid: 0. See logs for details.
2025-07-28 14:13:27 - Processing folder: Landmarks and Their Associated Transit Systems two(country, city, relation, East Asia, English), testid: 1
2025-07-28 14:13:27 - Error in generate_response: CUDA out of memory. Tried to allocate 2.82 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.07 GiB is allocated by PyTorch, and 2.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:13:27 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.82 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.07 GiB is allocated by PyTorch, and 2.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Landmarks and Their Associated Transit Systems two(country, city, relation, East Asia, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:13:27 - Error occurred for folder: Landmarks and Their Associated Transit Systems two(country, city, relation, East Asia, English), testid: 1. See logs for details.
2025-07-28 14:13:27 - Processing folder: Landmarks and Their Associated Transit Systems two(country, city, relation, East Asia, English), testid: 2
2025-07-28 14:13:27 - Error in generate_response: CUDA out of memory. Tried to allocate 2.89 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.07 GiB is allocated by PyTorch, and 2.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:13:27 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.89 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.07 GiB is allocated by PyTorch, and 2.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Landmarks and Their Associated Transit Systems two(country, city, relation, East Asia, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:13:27 - Error occurred for folder: Landmarks and Their Associated Transit Systems two(country, city, relation, East Asia, English), testid: 2. See logs for details.
2025-07-28 14:13:27 - Processing folder: Landmarks and Their Associated Transit Systems two(country, city, relation, East Asia, English), testid: 3
2025-07-28 14:13:27 - Error in generate_response: CUDA out of memory. Tried to allocate 2.82 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.07 GiB is allocated by PyTorch, and 2.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:13:27 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.82 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.07 GiB is allocated by PyTorch, and 2.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Landmarks and Their Associated Transit Systems two(country, city, relation, East Asia, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:13:27 - Error occurred for folder: Landmarks and Their Associated Transit Systems two(country, city, relation, East Asia, English), testid: 3. See logs for details.
2025-07-28 14:13:27 - Processing folder: Landmarks and Their Associated Transit Systems three(country, city, relation, Latin American, English), testid: 0
Folder: Landmarks and Their Associated Transit Systems three(country, city, relation, Latin American, English)
TestID: 0
{
    "response": "**Image 1**: [ancient ruins in a mountainous landscape]\n**Image 2**: [public transportation map]\n**Image 3**: [monument in an urban setting]\n**Image 4**: [monument in a mountainous landscape]\n\n**Relation**: contrast\n\n**Explanation**: Both Image 1 and Image 4 feature monuments set in mountainous landscapes, highlighting the grandeur and historical significance of these structures. Image 1 showcases ancient ruins, while Image 4 presents a modern monument, emphasizing the enduring presence of human-made landmarks in natural settings."
}

2025-07-28 14:13:43 - Successfully processed folder: Landmarks and Their Associated Transit Systems three(country, city, relation, Latin American, English), testid: 0
2025-07-28 14:13:43 - Processing folder: Landmarks and Their Associated Transit Systems three(country, city, relation, Latin American, English), testid: 1
Folder: Landmarks and Their Associated Transit Systems three(country, city, relation, Latin American, English)
TestID: 1
{
    "response": "### Image 1\n**Image Concept**: A detailed map of the Lima Metro system, showcasing various lines, stations, and connections.\n\n### Image 2\n**Image Concept**: A breathtaking view of Machu Picchu, an ancient Incan city nestled in the Andes Mountains.\n\n### Image 3\n**Image Concept**: A detailed map of the Buenos Aires Subte (Subway) system, highlighting different lines, stations, and connections.\n\n### Image 4\n**Image Concept**: A detailed map of the Lima Metro system, showcasing various lines, stations, and connections.\n\n### Relation\n**Keyword**: Urban Transportation\n\n### Explanation\nBoth Image 1 and Image 3 are maps of urban subway systems, providing detailed information about the routes, stations, and connections within the respective cities. Image 1 focuses on the Lima Metro, while Image 3 focuses on the Buenos Aires Subte. The Lima Metro map is designed to help users navigate the city's public transportation network, similar to how the Buenos Aires Subte map assists in navigating Buenos Aires. Both maps are essential tools for commuters and tourists alike, offering a clear visual representation of the metro systems in their respective cities."
}

2025-07-28 14:14:15 - Successfully processed folder: Landmarks and Their Associated Transit Systems three(country, city, relation, Latin American, English), testid: 1
2025-07-28 14:14:15 - Processing folder: Landmarks and Their Associated Transit Systems three(country, city, relation, Latin American, English), testid: 2
2025-07-28 14:14:16 - Error in generate_response: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 32.70 GiB is allocated by PyTorch, and 1.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:14:16 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 32.70 GiB is allocated by PyTorch, and 1.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Landmarks and Their Associated Transit Systems three(country, city, relation, Latin American, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:14:16 - Error occurred for folder: Landmarks and Their Associated Transit Systems three(country, city, relation, Latin American, English), testid: 2. See logs for details.
2025-07-28 14:14:16 - Processing folder: Landmarks and Their Associated Transit Systems three(country, city, relation, Latin American, English), testid: 3
2025-07-28 14:14:17 - Error in generate_response: CUDA out of memory. Tried to allocate 2.18 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 33.16 GiB is allocated by PyTorch, and 756.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:14:17 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.18 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 33.16 GiB is allocated by PyTorch, and 756.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Landmarks and Their Associated Transit Systems three(country, city, relation, Latin American, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:14:17 - Error occurred for folder: Landmarks and Their Associated Transit Systems three(country, city, relation, Latin American, English), testid: 3. See logs for details.
2025-07-28 14:14:17 - Processing folder: Landmarks and Their Associated Transit System four(country, city, relation, Arabic-Islamic, English), testid: 0
2025-07-28 14:14:18 - Error in generate_response: CUDA out of memory. Tried to allocate 1.50 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 32.40 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:14:18 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.50 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 32.40 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Landmarks and Their Associated Transit System four(country, city, relation, Arabic-Islamic, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:14:18 - Error occurred for folder: Landmarks and Their Associated Transit System four(country, city, relation, Arabic-Islamic, English), testid: 0. See logs for details.
2025-07-28 14:14:18 - Processing folder: Landmarks and Their Associated Transit System four(country, city, relation, Arabic-Islamic, English), testid: 1
2025-07-28 14:14:19 - Error in generate_response: CUDA out of memory. Tried to allocate 2.51 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 33.52 GiB is allocated by PyTorch, and 383.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:14:19 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.51 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 33.52 GiB is allocated by PyTorch, and 383.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Landmarks and Their Associated Transit System four(country, city, relation, Arabic-Islamic, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:14:19 - Error occurred for folder: Landmarks and Their Associated Transit System four(country, city, relation, Arabic-Islamic, English), testid: 1. See logs for details.
2025-07-28 14:14:19 - Processing folder: Landmarks and Their Associated Transit System four(country, city, relation, Arabic-Islamic, English), testid: 2
2025-07-28 14:14:19 - Error in generate_response: CUDA out of memory. Tried to allocate 1.50 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 32.41 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:14:19 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.50 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 32.41 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Landmarks and Their Associated Transit System four(country, city, relation, Arabic-Islamic, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:14:19 - Error occurred for folder: Landmarks and Their Associated Transit System four(country, city, relation, Arabic-Islamic, English), testid: 2. See logs for details.
2025-07-28 14:14:19 - Processing folder: Landmarks and Their Associated Transit System four(country, city, relation, Arabic-Islamic, English), testid: 3
2025-07-28 14:14:20 - Error in generate_response: CUDA out of memory. Tried to allocate 1.74 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 32.67 GiB is allocated by PyTorch, and 1.22 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:14:20 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.74 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 32.67 GiB is allocated by PyTorch, and 1.22 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Landmarks and Their Associated Transit System four(country, city, relation, Arabic-Islamic, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:14:20 - Error occurred for folder: Landmarks and Their Associated Transit System four(country, city, relation, Arabic-Islamic, English), testid: 3. See logs for details.
2025-07-28 14:14:20 - Processing folder: Cultural Elements of Cameroon football(animal, country, relation, other, English), testid: 0
Folder: Cultural Elements of Cameroon football(animal, country, relation, other, English)
TestID: 0
{
    "response": "**Image 1**: A majestic lion resting in a grassy field.\n**Image 2**: A satellite image of Cameroon.\n**Image 3**: A young elephant walking in a grassy field.\n\n**Image 1** and **Image 2** both depict natural elements, with **Image 1** featuring a lion in its habitat and **Image 2** showing the geographical landscape of Cameroon. The connection between them is the theme of nature and wildlife.\n\n**Image 3** also features a natural element, a young elephant in a grassy field, similar to **Image 1**. The relationship between **Image 3** and **Image 2** is that both images highlight the natural environment, with **Image 3** focusing on wildlife and **Image 2** on geography.\n\n**Image 4**: A young giraffe standing in a savannah.\n\n**Relation**: Natural environment\n\n**Explanation**: Both **Image 3** and **Image 4** showcase elements of the natural world, with **Image 3** featuring a young elephant in a grassy field and **Image 4** depicting a young giraffe in a savannah. The connection between them is the theme of wildlife and their respective habitats."
}

2025-07-28 14:14:52 - Successfully processed folder: Cultural Elements of Cameroon football(animal, country, relation, other, English), testid: 0
2025-07-28 14:14:52 - Processing folder: Cultural Elements of Cameroon football(animal, country, relation, other, English), testid: 1
Folder: Cultural Elements of Cameroon football(animal, country, relation, other, English)
TestID: 1
{
    "response": "### Image 1\n**Image Concept**: A satellite image of a country, specifically Cameroon, depicted in a greenish hue.\n\n### Image 2\n**Image Concept**: A majestic lion resting in a grassy field, showcasing its powerful mane and calm demeanor.\n\n### Image 3\n**Image Concept**: A detailed topographic map of Cameroon, highlighting various regions and geographical features.\n\n### Image 4\n**Image Concept**: A detailed topographic map of a country, highlighting various regions and geographical features.\n\n### Relation\n**Keyword**: Geographic Representation\n\n### Explanation\nBoth Image 1 and Image 3 are geographic representations of Cameroon, with Image 1 showing a satellite image and Image 3 showing a topographic map. Image 2, while not directly related to Cameroon, features a lion, which is a significant animal in the African continent, where Cameroon is located. The connection between Image 1 and Image 3 is their focus on the geographical and topographical aspects of Cameroon, while Image 2 adds an element of wildlife, emphasizing the rich biodiversity of the region."
}

2025-07-28 14:15:22 - Successfully processed folder: Cultural Elements of Cameroon football(animal, country, relation, other, English), testid: 1
2025-07-28 14:15:22 - Processing folder: Cultural Elements of Cameroon football(animal, country, relation, other, English), testid: 2
Folder: Cultural Elements of Cameroon football(animal, country, relation, other, English)
TestID: 2
{
    "response": "**Image 1**: A young elephant walking on grass.\n**Image 2**: A map of Ivory Coast.\n**Image 3**: A lion resting on grass.\n\n**Image 4**: A young elephant walking on grass.\n**Relation**: Wildlife\n**Explanation**: Both Image 1 and Image 4 feature a young elephant walking on grass, highlighting the theme of wildlife in natural settings."
}

2025-07-28 14:15:34 - Successfully processed folder: Cultural Elements of Cameroon football(animal, country, relation, other, English), testid: 2
2025-07-28 14:15:34 - Processing folder: Cultural Elements of Cameroon football(animal, country, relation, other, English), testid: 3
Folder: Cultural Elements of Cameroon football(animal, country, relation, other, English)
TestID: 3
{
    "response": "**Image 1**: A detailed topographic map of Cte d'Ivoire, highlighting geographical features and administrative divisions.\n\n**Image 2**: A young elephant walking in a grassy field, showcasing its natural habitat.\n\n**Image 3**: A satellite image of Cte d'Ivoire, emphasizing its geographical outline and terrain.\n\n**Image 4**: A satellite image of a country shaped like a rhinoceros, highlighting its geographical outline and terrain.\n\n**Relation**: Geographical Representation\n\n**Explanation**: Both Image 1 and Image 3 are satellite images of Cte d'Ivoire, focusing on its geographical features and administrative divisions. Similarly, Image 4 is a satellite image of a country shaped like a rhinoceros, emphasizing its geographical outline and terrain. The connection lies in the use of satellite imagery to represent a country's geography, with a creative twist in Image 4 by shaping the country like a rhinoceros."
}

2025-07-28 14:16:02 - Successfully processed folder: Cultural Elements of Cameroon football(animal, country, relation, other, English), testid: 3
2025-07-28 14:16:02 - Processing folder: Cultural Elements ofCameroon football(animal, country, relation, other, English), testid: 0
2025-07-28 14:16:03 - Error in generate_response: CUDA out of memory. Tried to allocate 3.35 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.12 GiB is allocated by PyTorch, and 2.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:16:03 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.35 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.12 GiB is allocated by PyTorch, and 2.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Elements ofCameroon football(animal, country, relation, other, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:16:03 - Error occurred for folder: Cultural Elements ofCameroon football(animal, country, relation, other, English), testid: 0. See logs for details.
2025-07-28 14:16:03 - Processing folder: Cultural Elements ofCameroon football(animal, country, relation, other, English), testid: 1
2025-07-28 14:16:03 - Error in generate_response: CUDA out of memory. Tried to allocate 2.24 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 33.22 GiB is allocated by PyTorch, and 694.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:16:03 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.24 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 33.22 GiB is allocated by PyTorch, and 694.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Elements ofCameroon football(animal, country, relation, other, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:16:03 - Error occurred for folder: Cultural Elements ofCameroon football(animal, country, relation, other, English), testid: 1. See logs for details.
2025-07-28 14:16:03 - Processing folder: Cultural Elements ofCameroon football(animal, country, relation, other, English), testid: 2
2025-07-28 14:16:03 - Error in generate_response: CUDA out of memory. Tried to allocate 2.28 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 33.26 GiB is allocated by PyTorch, and 651.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:16:03 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.28 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 33.26 GiB is allocated by PyTorch, and 651.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Elements ofCameroon football(animal, country, relation, other, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:16:03 - Error occurred for folder: Cultural Elements ofCameroon football(animal, country, relation, other, English), testid: 2. See logs for details.
2025-07-28 14:16:03 - Processing folder: Cultural Elements ofCameroon football(animal, country, relation, other, English), testid: 3
2025-07-28 14:16:03 - Error in generate_response: CUDA out of memory. Tried to allocate 1.83 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 32.77 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:16:03 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.83 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 32.77 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Elements ofCameroon football(animal, country, relation, other, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:16:03 - Error occurred for folder: Cultural Elements ofCameroon football(animal, country, relation, other, English), testid: 3. See logs for details.
2025-07-28 14:16:03 - Processing folder: Cultural Elements of Argentina football(animal, country, relation, Latin American, English), testid: 0
2025-07-28 14:16:03 - Error in generate_response: CUDA out of memory. Tried to allocate 5.29 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.29 GiB is allocated by PyTorch, and 2.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:16:03 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 5.29 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.29 GiB is allocated by PyTorch, and 2.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Elements of Argentina football(animal, country, relation, Latin American, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:16:03 - Error occurred for folder: Cultural Elements of Argentina football(animal, country, relation, Latin American, English), testid: 0. See logs for details.
2025-07-28 14:16:03 - Processing folder: Cultural Elements of Argentina football(animal, country, relation, Latin American, English), testid: 1
2025-07-28 14:16:04 - Error in generate_response: CUDA out of memory. Tried to allocate 3.51 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.13 GiB is allocated by PyTorch, and 2.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:16:04 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.51 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.13 GiB is allocated by PyTorch, and 2.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Elements of Argentina football(animal, country, relation, Latin American, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:16:04 - Error occurred for folder: Cultural Elements of Argentina football(animal, country, relation, Latin American, English), testid: 1. See logs for details.
2025-07-28 14:16:04 - Processing folder: Cultural Elements of Argentina football(animal, country, relation, Latin American, English), testid: 2
2025-07-28 14:16:04 - Error in generate_response: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.18 GiB is allocated by PyTorch, and 2.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:16:04 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.18 GiB is allocated by PyTorch, and 2.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Elements of Argentina football(animal, country, relation, Latin American, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:16:04 - Error occurred for folder: Cultural Elements of Argentina football(animal, country, relation, Latin American, English), testid: 2. See logs for details.
2025-07-28 14:16:04 - Processing folder: Cultural Elements of Argentina football(animal, country, relation, Latin American, English), testid: 3
2025-07-28 14:16:04 - Error in generate_response: CUDA out of memory. Tried to allocate 2.41 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 33.41 GiB is allocated by PyTorch, and 493.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:16:04 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.41 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 33.41 GiB is allocated by PyTorch, and 493.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Elements of Argentina football(animal, country, relation, Latin American, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:16:04 - Error occurred for folder: Cultural Elements of Argentina football(animal, country, relation, Latin American, English), testid: 3. See logs for details.
2025-07-28 14:16:04 - Processing folder: Cultural Elements of Latin footballmap(animal, country, relation, Latin American, English), testid: 0
Folder: Cultural Elements of Latin footballmap(animal, country, relation, Latin American, English)
TestID: 0
{
    "response": "### Image 1\n**Image Concept**: The image features a stylized eagle with outstretched wings, prominently displayed above the word \"PAMPA.\" The eagle is depicted in a bold, dark blue color against a light yellow background, conveying a sense of strength and freedom.\n\n### Image 2\n**Image Concept**: The image showcases the flag of Argentina, characterized by three horizontal stripes: light blue on the top and bottom, and white in the middle. A golden sun with a face is centered in the white stripe, symbolizing the Inca sun god Inti.\n\n### Image 3\n**Image Concept**: The image depicts a maned wolf walking on a grassy terrain. The animal has a reddish-brown coat with black legs and a distinctive black mane around its neck, giving it a unique appearance.\n\n### Image 4\n**Image Concept**: The image features a stylized maned wolf with outstretched legs, prominently displayed above the word \"PAMPA.\" The maned wolf is depicted in a bold, dark blue color against a light yellow background, conveying a sense of strength and freedom.\n\n### Relation\n**Relation**: Symbolic Representation\n\n### Explanation\nBoth Image 1 and Image 4 feature a stylized representation of a maned wolf with outstretched wings, set against a light yellow background. The word \"PAMPA\" is prominently displayed below each image, suggesting a thematic connection. The maned wolf, known for its distinctive appearance and habitat in the Pampas region of South America, serves as a central element in both images, linking them through a shared cultural and geographical context. The use of bold, dark blue color for the maned wolf in both images reinforces the sense of strength and freedom, while the light yellow background provides a consistent visual theme. This connection highlights the symbolic representation of the maned wolf as a powerful and emblematic creature within the Pampas region."
}

2025-07-28 14:16:53 - Successfully processed folder: Cultural Elements of Latin footballmap(animal, country, relation, Latin American, English), testid: 0
2025-07-28 14:16:53 - Processing folder: Cultural Elements of Latin footballmap(animal, country, relation, Latin American, English), testid: 1
Folder: Cultural Elements of Latin footballmap(animal, country, relation, Latin American, English)
TestID: 1
{
    "response": "**Image 1**: The flag of Argentina, featuring a light blue and white horizontal bicolor with a yellow sun emblem in the center.\n\n**Image 2**: A logo with a stylized eagle with outstretched wings, accompanied by the text \"PAMPA\" below it.\n\n**Image 3**: The flag of Paraguay, characterized by three horizontal stripes of red, white, and blue, with a national emblem in the center of the white stripe.\n\n**Image 4**: A flag with a light blue and white horizontal bicolor, featuring a yellow sun emblem in the center.\n\n**Relation**: National Symbols\n\n**Explanation**: Both Image 1 and Image 4 depict flags with light blue and white horizontal stripes and a yellow sun emblem in the center, suggesting a connection to national symbols. Image 2, while not a flag, features a stylized eagle emblem, which is a common motif in national symbols. The shared elements of national symbols and emblems link Image 1 and Image 4, while Image 2 complements this theme with its own emblematic design."
}

2025-07-28 14:17:23 - Successfully processed folder: Cultural Elements of Latin footballmap(animal, country, relation, Latin American, English), testid: 1
2025-07-28 14:17:23 - Processing folder: Cultural Elements of Latin footballmap(animal, country, relation, Latin American, English), testid: 2
2025-07-28 14:17:23 - Error in generate_response: CUDA out of memory. Tried to allocate 1.89 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 32.84 GiB is allocated by PyTorch, and 1.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:17:23 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.89 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 32.84 GiB is allocated by PyTorch, and 1.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Elements of Latin footballmap(animal, country, relation, Latin American, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:17:23 - Error occurred for folder: Cultural Elements of Latin footballmap(animal, country, relation, Latin American, English), testid: 2. See logs for details.
2025-07-28 14:17:23 - Processing folder: Cultural Elements of Latin footballmap(animal, country, relation, Latin American, English), testid: 3
2025-07-28 14:17:24 - Error in generate_response: CUDA out of memory. Tried to allocate 1.61 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 32.53 GiB is allocated by PyTorch, and 1.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:17:24 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.61 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 32.53 GiB is allocated by PyTorch, and 1.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Elements of Latin footballmap(animal, country, relation, Latin American, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:17:24 - Error occurred for folder: Cultural Elements of Latin footballmap(animal, country, relation, Latin American, English), testid: 3. See logs for details.
2025-07-28 14:17:24 - Processing folder: Cultural Elements of Latin football(animal, country, relation, Latin American, English), testid: 0
2025-07-28 14:17:25 - Error in generate_response: CUDA out of memory. Tried to allocate 2.59 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 33.61 GiB is allocated by PyTorch, and 296.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:17:25 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.59 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 33.61 GiB is allocated by PyTorch, and 296.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Elements of Latin football(animal, country, relation, Latin American, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:17:25 - Error occurred for folder: Cultural Elements of Latin football(animal, country, relation, Latin American, English), testid: 0. See logs for details.
2025-07-28 14:17:25 - Processing folder: Cultural Elements of Latin football(animal, country, relation, Latin American, English), testid: 1
2025-07-28 14:17:26 - Error in generate_response: CUDA out of memory. Tried to allocate 2.87 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.07 GiB is allocated by PyTorch, and 2.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:17:26 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.87 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.07 GiB is allocated by PyTorch, and 2.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Elements of Latin football(animal, country, relation, Latin American, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:17:26 - Error occurred for folder: Cultural Elements of Latin football(animal, country, relation, Latin American, English), testid: 1. See logs for details.
2025-07-28 14:17:26 - Processing folder: Cultural Elements of Latin football(animal, country, relation, Latin American, English), testid: 2
2025-07-28 14:17:26 - Error in generate_response: CUDA out of memory. Tried to allocate 2.28 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 33.27 GiB is allocated by PyTorch, and 645.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:17:26 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.28 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 33.27 GiB is allocated by PyTorch, and 645.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Elements of Latin football(animal, country, relation, Latin American, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:17:26 - Error occurred for folder: Cultural Elements of Latin football(animal, country, relation, Latin American, English), testid: 2. See logs for details.
2025-07-28 14:17:26 - Processing folder: Cultural Elements of Latin football(animal, country, relation, Latin American, English), testid: 3
Folder: Cultural Elements of Latin football(animal, country, relation, Latin American, English)
TestID: 3
{
    "response": "### Image 1\n**Image Concept**: A topographical map of a region, likely depicting elevation changes and terrain features.\n\n### Image 2\n**Image Concept**: A close-up photograph of a dog lying on the ground, possibly in a park or garden setting.\n\n### Image 3\n**Image Concept**: A topographical map of a different region, showing elevation changes and terrain features.\n\n### Image 4\n**Image Concept**: A topographical map of a region, likely depicting elevation changes and terrain features.\n\n### Relation\n**Relation**: Topographical maps\n\n### Explanation\nBoth Image 1 and Image 3 are topographical maps, which means they both depict the physical features of a region, including elevation changes and terrain. Similarly, Image 4 is also a topographical map, indicating it shares the same thematic focus as Image 1 and Image 3. The connection between these images is their shared focus on geographical and topographical information."
}

2025-07-28 14:17:55 - Successfully processed folder: Cultural Elements of Latin football(animal, country, relation, Latin American, English), testid: 3
2025-07-28 14:17:55 - Processing folder: Cultural Elements of city football(animal, city, relation, Non-English European, English), testid: 0
2025-07-28 14:17:55 - Error in generate_response: CUDA out of memory. Tried to allocate 2.82 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.07 GiB is allocated by PyTorch, and 2.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:17:55 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.82 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.07 GiB is allocated by PyTorch, and 2.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Elements of city football(animal, city, relation, Non-English European, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:17:55 - Error occurred for folder: Cultural Elements of city football(animal, city, relation, Non-English European, English), testid: 0. See logs for details.
2025-07-28 14:17:55 - Processing folder: Cultural Elements of city football(animal, city, relation, Non-English European, English), testid: 1
2025-07-28 14:17:55 - Error in generate_response: CUDA out of memory. Tried to allocate 1.89 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 32.83 GiB is allocated by PyTorch, and 1.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:17:55 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.89 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 32.83 GiB is allocated by PyTorch, and 1.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Elements of city football(animal, city, relation, Non-English European, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:17:55 - Error occurred for folder: Cultural Elements of city football(animal, city, relation, Non-English European, English), testid: 1. See logs for details.
2025-07-28 14:17:55 - Processing folder: Cultural Elements of city football(animal, city, relation, Non-English European, English), testid: 2
2025-07-28 14:17:55 - Error in generate_response: CUDA out of memory. Tried to allocate 1.87 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 32.81 GiB is allocated by PyTorch, and 1.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:17:55 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.87 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 32.81 GiB is allocated by PyTorch, and 1.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Elements of city football(animal, city, relation, Non-English European, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:17:55 - Error occurred for folder: Cultural Elements of city football(animal, city, relation, Non-English European, English), testid: 2. See logs for details.
2025-07-28 14:17:55 - Processing folder: Cultural Elements of city football(animal, city, relation, Non-English European, English), testid: 3
2025-07-28 14:17:55 - Error in generate_response: CUDA out of memory. Tried to allocate 1.86 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 32.81 GiB is allocated by PyTorch, and 1.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:17:55 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.86 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 32.81 GiB is allocated by PyTorch, and 1.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Elements of city football(animal, city, relation, Non-English European, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:17:55 - Error occurred for folder: Cultural Elements of city football(animal, city, relation, Non-English European, English), testid: 3. See logs for details.
2025-07-28 14:17:55 - Processing folder: Cultural Elements of city football2(animal, city, relation, Non-English European, English), testid: 0
2025-07-28 14:17:55 - Error in generate_response: CUDA out of memory. Tried to allocate 4.50 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.22 GiB is allocated by PyTorch, and 2.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:17:55 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.50 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.22 GiB is allocated by PyTorch, and 2.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Elements of city football2(animal, city, relation, Non-English European, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:17:55 - Error occurred for folder: Cultural Elements of city football2(animal, city, relation, Non-English European, English), testid: 0. See logs for details.
2025-07-28 14:17:55 - Processing folder: Cultural Elements of city football2(animal, city, relation, Non-English European, English), testid: 1
2025-07-28 14:17:55 - Error in generate_response: CUDA out of memory. Tried to allocate 3.47 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.13 GiB is allocated by PyTorch, and 2.77 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:17:55 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.47 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.13 GiB is allocated by PyTorch, and 2.77 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Elements of city football2(animal, city, relation, Non-English European, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:17:55 - Error occurred for folder: Cultural Elements of city football2(animal, city, relation, Non-English European, English), testid: 1. See logs for details.
2025-07-28 14:17:55 - Processing folder: Cultural Elements of city football2(animal, city, relation, Non-English European, English), testid: 2
2025-07-28 14:17:56 - Error in generate_response: CUDA out of memory. Tried to allocate 4.50 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.22 GiB is allocated by PyTorch, and 2.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:17:56 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.50 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.22 GiB is allocated by PyTorch, and 2.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Elements of city football2(animal, city, relation, Non-English European, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:17:56 - Error occurred for folder: Cultural Elements of city football2(animal, city, relation, Non-English European, English), testid: 2. See logs for details.
2025-07-28 14:17:56 - Processing folder: Cultural Elements of city football2(animal, city, relation, Non-English European, English), testid: 3
2025-07-28 14:17:56 - Error in generate_response: CUDA out of memory. Tried to allocate 3.79 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.16 GiB is allocated by PyTorch, and 2.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:17:56 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.79 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.16 GiB is allocated by PyTorch, and 2.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Elements of city football2(animal, city, relation, Non-English European, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:17:56 - Error occurred for folder: Cultural Elements of city football2(animal, city, relation, Non-English European, English), testid: 3. See logs for details.
2025-07-28 14:17:56 - Processing folder: Culture and Sports(animal, country, relation, East Asia, English), testid: 0
Folder: Culture and Sports(animal, country, relation, East Asia, English)
TestID: 0
{
    "response": "**Image 1**: [A male athlete playing table tennis, wearing a black and yellow uniform with a focused expression, preparing to hit a ball with a paddle.]\n\n**Image 2**: [A giant panda sitting in a grassy area, surrounded by bamboo, with a calm and curious expression.]\n\n**Image 3**: [A white soccer ball with red and black patterns, featuring a Nike logo and Premier League emblem, placed on a light background with small black specks around it.]\n\n**Image 4**: [A soccer player in a black and yellow uniform, focused on a soccer ball, preparing to kick it with a determined expression.]\n\n**Relation**: Sports\n\n**Explanation**: Both Image 1 and Image 4 depict athletes engaged in sports activities. Image 1 shows a table tennis player in action, while Image 4 features a soccer player about to kick a ball. Both images emphasize the athletes' focus and readiness, highlighting the competitive nature of their respective sports. Similarly, Image 2 and Image 3 also share a sports theme, with Image 2 showing a panda in a natural setting and Image 3 displaying a soccer ball. The connection between Image 1 and Image 2, as well as Image 3 and Image 4, is the shared element of sports, showcasing different aspects of athleticism and competition."
}

2025-07-28 14:18:33 - Successfully processed folder: Culture and Sports(animal, country, relation, East Asia, English), testid: 0
2025-07-28 14:18:33 - Processing folder: Culture and Sports(animal, country, relation, East Asia, English), testid: 1
Folder: Culture and Sports(animal, country, relation, East Asia, English)
TestID: 1
{
    "response": "1. **Image 1**: A panda is sitting in a grassy area, surrounded by tall grass and bamboo, appearing to be in a natural habitat.\n2. **Image 2**: A man is playing table tennis, focused on hitting a ball with a paddle, wearing a sports uniform.\n3. **Image 3**: The logo of the Premier League, featuring a lion standing on a soccer ball with a crown, symbolizing strength and royalty.\n\n**Image 1** and **Image 2** both depict animals in their respective environments: a panda in nature and a man in a sports setting. Both images focus on the subjects' engagement with their surroundings, whether it's the panda in its habitat or the man in a competitive sports environment.\n\n**Image 1** and **Image 3** share a theme of strength and dominance. The panda, though not typically associated with strength, is depicted in a powerful stance, while the Premier League logo uses a lion to symbolize power and leadership in sports.\n\n**Image 2** and **Image 3** both involve sports. The table tennis player is engaged in a competitive sport, similar to the Premier League, which is a major football league. Both images highlight the intensity and focus required in their respective sports.\n\n**Image 4**: A soccer player is kicking a ball in a stadium, wearing a team uniform, with the crowd in the background.\n\n**Relation**: Sports and Competition\n\n**Explanation**: Both Image 2 and Image 4 depict individuals engaged in sports, highlighting the competitive nature of the activities. The table tennis player and the soccer player are both focused and determined, showcasing the intensity and skill involved in their sports."
}

2025-07-28 14:19:18 - Successfully processed folder: Culture and Sports(animal, country, relation, East Asia, English), testid: 1
2025-07-28 14:19:18 - Processing folder: Culture and Sports(animal, country, relation, East Asia, English), testid: 2
Folder: Culture and Sports(animal, country, relation, East Asia, English)
TestID: 2
{
    "response": "**Image 1**: A soccer ball with a distinctive design featuring red and black patterns on a white background, accompanied by a Nike logo.\n\n**Image 2**: The Premier League logo, which includes a lion standing on a soccer ball, with the text \"Premier League\" below.\n\n**Image 3**: A person playing table tennis, wearing a black sports outfit with a paddle in hand, focused on hitting a ball.\n\n**Image 4**: A logo featuring a stylized lion standing on a soccer ball, with the text \"Premier League\" below it.\n\n**Relation**: Sports\n\n**Explanation**: Both Image 1 and Image 2 feature soccer-related elements, with Image 1 showing a soccer ball and Image 2 displaying the Premier League logo. Similarly, Image 3 and Image 4 both depict sports themes, with Image 3 showing a table tennis player and Image 4 featuring a lion on a soccer ball, which is reminiscent of the Premier League logo. The connection is established through the shared theme of sports, specifically soccer and table tennis."
}

2025-07-28 14:19:47 - Successfully processed folder: Culture and Sports(animal, country, relation, East Asia, English), testid: 2
2025-07-28 14:19:47 - Processing folder: Culture and Sports(animal, country, relation, East Asia, English), testid: 3
Folder: Culture and Sports(animal, country, relation, East Asia, English)
TestID: 3
{
    "response": "### Image 1\n**Image Concept**: The image features the logo of the Premier League, a professional football league in England. The logo includes a stylized lion standing on a football, with the words \"PREMIER LEAGUE\" written below.\n\n### Image 2\n**Image Concept**: The image shows a close-up of a football, specifically designed for the Premier League. The ball has a distinctive pattern with the Premier League logo and the Nike swoosh.\n\n### Image 3\n**Image Concept**: The image depicts a giant panda sitting in a natural environment, surrounded by tall grass and bamboo.\n\n### Image 4\n**Image Concept**: The image features a close-up of a panda bear sitting in a natural setting, similar to Image 3. The panda is surrounded by tall grass and bamboo, creating a serene and natural atmosphere.\n\n### Relation\n**Relation**: Similarity\n\n### Explanation\nBoth Image 1 and Image 2 share a connection through the theme of football, specifically the Premier League. Image 1 features the official logo of the Premier League, while Image 2 showcases a football used in the league. Similarly, Image 3 and Image 4 both depict pandas in natural settings, emphasizing the serene and natural environment. The connection between Image 1 and Image 2 is the football theme, while the connection between Image 3 and Image 4 is the natural setting and the presence of pandas."
}

2025-07-28 14:20:27 - Successfully processed folder: Culture and Sports(animal, country, relation, East Asia, English), testid: 3
2025-07-28 14:20:27 - Processing folder: Culture and Sports two(animal, country, relation, East Asia, English), testid: 0
Folder: Culture and Sports two(animal, country, relation, East Asia, English)
TestID: 0
{
    "response": "**Image 1**: [A male athlete in a black sports shirt with a dragon design, holding a paddle, celebrating in a stadium.]  \n**Image 2**: [A panda bear with a calm expression, resting on a tree branch.]  \n**Image 3**: [A male athlete in a blue and white sports jacket, holding a gold medal.]  \n\n**Image 1** and **Image 2** both feature individuals in celebratory poses. The athlete in Image 1 is celebrating with a paddle, while the panda in Image 2 appears relaxed and content. Both images capture moments of triumph or peace, respectively, in their respective contexts.\n\n**Image 3** and **Image 2** both feature individuals in a state of achievement or calmness. The athlete in Image 3 is holding a gold medal, symbolizing victory, while the panda in Image 2 is at ease, showcasing a sense of tranquility. Both images highlight moments of success or serenity.\n\n**Image 4**: [A panda bear in a natural setting, appearing relaxed and content, similar to Image 2.]\n\n**Relation**: Similarity in Expressions\n\n**Explanation**: Both Image 2 and Image 4 feature a panda bear in a natural setting, both appearing relaxed and content. This similarity in expressions and settings mirrors the connection between Image 1 and Image 3, where both athletes are in celebratory or victorious poses."
}

2025-07-28 14:21:03 - Successfully processed folder: Culture and Sports two(animal, country, relation, East Asia, English), testid: 0
2025-07-28 14:21:03 - Processing folder: Culture and Sports two(animal, country, relation, East Asia, English), testid: 1
2025-07-28 14:21:03 - Error in generate_response: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 32.90 GiB is allocated by PyTorch, and 1021.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:21:03 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 32.90 GiB is allocated by PyTorch, and 1021.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Culture and Sports two(animal, country, relation, East Asia, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:21:03 - Error occurred for folder: Culture and Sports two(animal, country, relation, East Asia, English), testid: 1. See logs for details.
2025-07-28 14:21:03 - Processing folder: Culture and Sports two(animal, country, relation, East Asia, English), testid: 2
2025-07-28 14:21:04 - Error in generate_response: CUDA out of memory. Tried to allocate 2.09 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 33.05 GiB is allocated by PyTorch, and 862.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:21:04 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.09 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 33.05 GiB is allocated by PyTorch, and 862.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Culture and Sports two(animal, country, relation, East Asia, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:21:04 - Error occurred for folder: Culture and Sports two(animal, country, relation, East Asia, English), testid: 2. See logs for details.
2025-07-28 14:21:04 - Processing folder: Culture and Sports two(animal, country, relation, East Asia, English), testid: 3
2025-07-28 14:21:04 - Error in generate_response: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 32.95 GiB is allocated by PyTorch, and 968.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:21:04 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 32.95 GiB is allocated by PyTorch, and 968.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Culture and Sports two(animal, country, relation, East Asia, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:21:04 - Error occurred for folder: Culture and Sports two(animal, country, relation, East Asia, English), testid: 3. See logs for details.
2025-07-28 14:21:04 - Processing folder: Symbols(country, animal, relation, Latin American, English), testid: 0
2025-07-28 14:21:04 - Error in generate_response: CUDA out of memory. Tried to allocate 2.51 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 33.52 GiB is allocated by PyTorch, and 383.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:21:04 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.51 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 33.52 GiB is allocated by PyTorch, and 383.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Symbols(country, animal, relation, Latin American, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:21:04 - Error occurred for folder: Symbols(country, animal, relation, Latin American, English), testid: 0. See logs for details.
2025-07-28 14:21:04 - Processing folder: Symbols(country, animal, relation, Latin American, English), testid: 1
2025-07-28 14:21:04 - Error in generate_response: CUDA out of memory. Tried to allocate 2.49 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 33.50 GiB is allocated by PyTorch, and 404.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:21:04 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.49 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 33.50 GiB is allocated by PyTorch, and 404.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Symbols(country, animal, relation, Latin American, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:21:04 - Error occurred for folder: Symbols(country, animal, relation, Latin American, English), testid: 1. See logs for details.
2025-07-28 14:21:04 - Processing folder: Symbols(country, animal, relation, Latin American, English), testid: 2
2025-07-28 14:21:04 - Error in generate_response: CUDA out of memory. Tried to allocate 1.83 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 32.78 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:21:04 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.83 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 32.78 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Symbols(country, animal, relation, Latin American, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:21:04 - Error occurred for folder: Symbols(country, animal, relation, Latin American, English), testid: 2. See logs for details.
2025-07-28 14:21:04 - Processing folder: Symbols(country, animal, relation, Latin American, English), testid: 3
2025-07-28 14:21:04 - Error in generate_response: CUDA out of memory. Tried to allocate 3.84 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.16 GiB is allocated by PyTorch, and 2.73 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:21:04 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.84 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.16 GiB is allocated by PyTorch, and 2.73 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Symbols(country, animal, relation, Latin American, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:21:04 - Error occurred for folder: Symbols(country, animal, relation, Latin American, English), testid: 3. See logs for details.
2025-07-28 14:21:04 - Processing folder: Famous Symbols(city, animal, relation, USAEnglish, English), testid: 0
2025-07-28 14:21:05 - Error in generate_response: CUDA out of memory. Tried to allocate 1.80 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 32.74 GiB is allocated by PyTorch, and 1.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:21:05 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.80 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 32.74 GiB is allocated by PyTorch, and 1.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Famous Symbols(city, animal, relation, USAEnglish, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:21:05 - Error occurred for folder: Famous Symbols(city, animal, relation, USAEnglish, English), testid: 0. See logs for details.
2025-07-28 14:21:05 - Processing folder: Famous Symbols(city, animal, relation, USAEnglish, English), testid: 1
2025-07-28 14:21:05 - Error in generate_response: CUDA out of memory. Tried to allocate 1.85 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 32.79 GiB is allocated by PyTorch, and 1.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:21:05 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.85 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 32.79 GiB is allocated by PyTorch, and 1.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Famous Symbols(city, animal, relation, USAEnglish, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:21:05 - Error occurred for folder: Famous Symbols(city, animal, relation, USAEnglish, English), testid: 1. See logs for details.
2025-07-28 14:21:05 - Processing folder: Famous Symbols(city, animal, relation, USAEnglish, English), testid: 2
2025-07-28 14:21:05 - Error in generate_response: CUDA out of memory. Tried to allocate 1.85 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 32.79 GiB is allocated by PyTorch, and 1.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:21:05 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.85 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 32.79 GiB is allocated by PyTorch, and 1.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Famous Symbols(city, animal, relation, USAEnglish, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:21:05 - Error occurred for folder: Famous Symbols(city, animal, relation, USAEnglish, English), testid: 2. See logs for details.
2025-07-28 14:21:05 - Processing folder: Famous Symbols(city, animal, relation, USAEnglish, English), testid: 3
2025-07-28 14:21:05 - Error in generate_response: CUDA out of memory. Tried to allocate 2.91 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.08 GiB is allocated by PyTorch, and 2.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:21:05 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.91 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.08 GiB is allocated by PyTorch, and 2.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Famous Symbols(city, animal, relation, USAEnglish, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:21:05 - Error occurred for folder: Famous Symbols(city, animal, relation, USAEnglish, English), testid: 3. See logs for details.
2025-07-28 14:21:05 - Processing folder: Famous Symbols of cat(city, animal, relation, USAEnglish, English), testid: 0
Folder: Famous Symbols of cat(city, animal, relation, USAEnglish, English)
TestID: 0
{
    "response": "Image 1: [a close-up of a spider with detailed eyes and hair]\nImage 2: [a cityscape with a prominent skyscraper during sunset]\nImage 3: [a kitten in a grassy field]\n\n**Image 4**: [a close-up of a kitten with detailed fur and eyes]\n\n**Relation**: macro photography\n\n**Explanation**: Both Image 1 and Image 4 are close-up shots that emphasize the intricate details of their subjects, showcasing the textures and features with high clarity. Similarly, Image 2, while not a close-up, captures the grandeur of the cityscape with a focus on the illuminated skyscraper, highlighting its architectural details against the backdrop of the sunset. The common theme of detailed observation is evident in all three images, whether it's the minute details of the spider and kitten or the majestic view of the cityscape."
}

2025-07-28 14:21:26 - Successfully processed folder: Famous Symbols of cat(city, animal, relation, USAEnglish, English), testid: 0
2025-07-28 14:21:26 - Processing folder: Famous Symbols of cat(city, animal, relation, USAEnglish, English), testid: 1
Folder: Famous Symbols of cat(city, animal, relation, USAEnglish, English)
TestID: 1
{
    "response": "Image 1: [a cityscape featuring the Empire State Building illuminated at dusk]\nImage 2: [a close-up of a spider with detailed eyes and hair]\nImage 3: [a large suspension bridge with a clear sky and surrounding greenery]\n\nImage 4: [a close-up of a bird's eye with detailed feathers and beak]\n- Relation: Macro\n- Explanation: Both Image 1 and Image 2 are macro images, focusing on the intricate details of a large structure (Empire State Building) and a small creature (spider), respectively. Similarly, Image 4 is a macro image of a bird's eye, highlighting the fine details of the bird's features. The connection between Image 1 and Image 2 is their shared focus on detailed close-ups, which is mirrored in the relationship between Image 4 and Image 3 through the macro perspective on the bird's eye."
}

2025-07-28 14:21:51 - Successfully processed folder: Famous Symbols of cat(city, animal, relation, USAEnglish, English), testid: 1
2025-07-28 14:21:51 - Processing folder: Famous Symbols of cat(city, animal, relation, USAEnglish, English), testid: 2
Folder: Famous Symbols of cat(city, animal, relation, USAEnglish, English)
TestID: 2
{
    "response": "Image 1: [a cute kitten exploring a grassy field]\nImage 2: [a large suspension bridge with a clear sky]\nImage 3: [a close-up of a spider with detailed eyes and hair]\nImage 4: [a close-up of a curious puppy exploring a grassy field]\n\nRelation: Nature's Curiosity\nExplanation: Both Image 1 and Image 4 feature young animals exploring their natural environments, highlighting the theme of curiosity in nature."
}

2025-07-28 14:22:05 - Successfully processed folder: Famous Symbols of cat(city, animal, relation, USAEnglish, English), testid: 2
2025-07-28 14:22:05 - Processing folder: Famous Symbols of cat(city, animal, relation, USAEnglish, English), testid: 3
Folder: Famous Symbols of cat(city, animal, relation, USAEnglish, English)
TestID: 3
{
    "response": "**Image 1**: [A large suspension bridge with tall towers and cables, set against a backdrop of a cityscape and a clear sky]\n**Image 2**: [A small kitten with striped fur, standing on green grass and looking curiously at the camera]\n**Image 3**: [A cityscape at sunset with the Empire State Building prominently lit up, surrounded by other skyscrapers]\n\n**Image 4**: [A small puppy with fluffy fur, standing on a grassy field and looking curiously at the camera]\n\n**Relation**: Urban and Natural Contrast\n\n**Explanation**: Both pairs of images contrast urban and natural elements. Image 1 juxtaposes a large, man-made suspension bridge with a natural cityscape and sky, while Image 2 contrasts the small, natural kitten with the green grass. Similarly, Image 3 contrasts the urban skyline with the natural beauty of a sunset. Image 4 mirrors this contrast by placing a small, natural puppy against a grassy field, emphasizing the juxtaposition of urban and natural elements."
}

2025-07-28 14:22:31 - Successfully processed folder: Famous Symbols of cat(city, animal, relation, USAEnglish, English), testid: 3
2025-07-28 14:22:31 - Processing folder: Cultural Elements of football(animal, country, relation, Non-English European, English), testid: 0
2025-07-28 14:22:32 - Error in generate_response: CUDA out of memory. Tried to allocate 3.86 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.16 GiB is allocated by PyTorch, and 2.73 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:22:32 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.86 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.16 GiB is allocated by PyTorch, and 2.73 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Elements of football(animal, country, relation, Non-English European, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:22:32 - Error occurred for folder: Cultural Elements of football(animal, country, relation, Non-English European, English), testid: 0. See logs for details.
2025-07-28 14:22:32 - Processing folder: Cultural Elements of football(animal, country, relation, Non-English European, English), testid: 1
2025-07-28 14:22:32 - Error in generate_response: CUDA out of memory. Tried to allocate 2.24 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 33.22 GiB is allocated by PyTorch, and 691.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:22:32 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.24 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 33.22 GiB is allocated by PyTorch, and 691.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Elements of football(animal, country, relation, Non-English European, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:22:32 - Error occurred for folder: Cultural Elements of football(animal, country, relation, Non-English European, English), testid: 1. See logs for details.
2025-07-28 14:22:32 - Processing folder: Cultural Elements of football(animal, country, relation, Non-English European, English), testid: 2
2025-07-28 14:22:33 - Error in generate_response: CUDA out of memory. Tried to allocate 4.87 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.25 GiB is allocated by PyTorch, and 2.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:22:33 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.87 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.25 GiB is allocated by PyTorch, and 2.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Elements of football(animal, country, relation, Non-English European, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:22:33 - Error occurred for folder: Cultural Elements of football(animal, country, relation, Non-English European, English), testid: 2. See logs for details.
2025-07-28 14:22:33 - Processing folder: Cultural Elements of football(animal, country, relation, Non-English European, English), testid: 3
2025-07-28 14:22:34 - Error in generate_response: CUDA out of memory. Tried to allocate 3.94 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.17 GiB is allocated by PyTorch, and 2.73 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:22:34 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.94 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.17 GiB is allocated by PyTorch, and 2.73 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Elements of football(animal, country, relation, Non-English European, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:22:34 - Error occurred for folder: Cultural Elements of football(animal, country, relation, Non-English European, English), testid: 3. See logs for details.
2025-07-28 14:22:34 - Processing folder: Cultural Elements of Spanish football(animal, country, relation, Non-English European, English), testid: 0
Folder: Cultural Elements of Spanish football(animal, country, relation, Non-English European, English)
TestID: 0
{
    "response": "### Image 1\n**Image Concept**: Bullfighting\n\n**Description**: The image depicts a bullfighting scene where a matador, dressed in traditional attire, is engaging with a bull. The matador is holding a pink cape, and the bull is charging towards it, kicking up dust in the process. The setting appears to be a bullfighting arena with red barriers in the background.\n\n### Image 2\n**Image Concept**: Geographical Map\n\n**Description**: The image shows a topographical map of Spain. The map highlights the country's terrain with varying shades of green and brown, indicating different elevations. The map includes the surrounding seas and some nearby islands.\n\n### Image 3\n**Image Concept**: Wildlife\n\n**Description**: The image features a lion lying on the ground in a natural setting. The lion has a majestic mane and is resting on dry grass. The background is blurred, suggesting a focus on the lion itself.\n\n### Image 4\n**Image Concept**: Wildlife\n\n**Description**: The image shows a lion lying on the ground in a natural setting. The lion has a majestic mane and is resting on dry grass. The background is blurred, suggesting a focus on the lion itself.\n\n### Relation\n**Relation**: Geographic Connection\n\n### Explanation\nBoth Image 1 and Image 2 are connected through the theme of Spain. Image 1 depicts a traditional Spanish activity, bullfighting, which is deeply rooted in the country's culture. Image 2 is a geographical representation of Spain, highlighting its topography. The connection between these images lies in their shared geographical context, as bullfighting is a cultural practice that takes place within the geographical boundaries of Spain. The topographical map in Image 2 provides a visual representation of the country where such cultural activities occur, thus linking the two images through their geographical and cultural significance."
}

2025-07-28 14:23:20 - Successfully processed folder: Cultural Elements of Spanish football(animal, country, relation, Non-English European, English), testid: 0
2025-07-28 14:23:20 - Processing folder: Cultural Elements of Spanish football(animal, country, relation, Non-English European, English), testid: 1
Folder: Cultural Elements of Spanish football(animal, country, relation, Non-English European, English)
TestID: 1
{
    "response": "### Image 1\n**Image Concept**: Topographic map of Spain\n- This image is a topographic map of Spain, showcasing the country's varied terrain. The map uses color gradients to represent elevation, with higher elevations in brown and lower elevations in green. The map is detailed, showing mountain ranges, plains, and coastal areas.\n\n### Image 2\n**Image Concept**: Bullfighting scene\n- This image captures a moment in a bullfighting event. A matador, dressed in traditional attire, is engaging with a bull using a pink cape. The bull is in mid-charge, and the scene is set in a bullfighting arena with red walls and sand-covered ground.\n\n### Image 3\n**Image Concept**: 3D topographic map of the United Kingdom\n- This image is a 3D topographic map of the United Kingdom, highlighting the country's varied terrain. The map uses shades of green to represent elevation, with darker greens indicating higher elevations and lighter greens indicating lower elevations. The map is detailed, showing mountain ranges, plains, and coastal areas.\n\n### Image 4\n**Image Concept**: 3D topographic map of the United Kingdom\n- This image is a 3D topographic map of the United Kingdom, similar to Image 3. It uses shades of green to represent elevation, with darker greens indicating higher elevations and lighter greens indicating lower elevations. The map is detailed, showing mountain ranges, plains, and coastal areas.\n\n### Relation\n**Relation**: Geographical representation\n- Both Image 3 and Image 4 are 3D topographic maps of the United Kingdom, focusing on the country's varied terrain. They both use color gradients to represent elevation, with darker greens indicating higher elevations and lighter greens indicating lower elevations. The maps are detailed, showing mountain ranges, plains, and coastal areas.\n\n### Explanation\n- Both Image 3 and Image 4 are 3D topographic maps of the United Kingdom, providing a visual representation of the country's terrain. They use similar color gradients to represent elevation, with darker greens indicating higher elevations and lighter greens indicating lower elevations. The maps are detailed, showing mountain ranges, plains, and coastal areas. The main difference is that Image 3 is a 2D topographic map, while Image 4 is a 3D topographic map, offering a more immersive and realistic view of the terrain."
}

2025-07-28 14:24:24 - Successfully processed folder: Cultural Elements of Spanish football(animal, country, relation, Non-English European, English), testid: 1
2025-07-28 14:24:24 - Processing folder: Cultural Elements of Spanish football(animal, country, relation, Non-English European, English), testid: 2
Folder: Cultural Elements of Spanish football(animal, country, relation, Non-English European, English)
TestID: 2
{
    "response": "Image 1: [A majestic lion resting on a grassy field]\nImage 2: [A 3D topographical map of the United Kingdom]\nImage 3: [A matador in traditional attire engaging with a bull in a bullfighting ring]\n\n**Image 4**: [A majestic lion resting on a grassy field]\n\n**Relation**: Geographic Diversity\n\n**Explanation**: Both Image 1 and Image 4 feature a lion in a natural setting, emphasizing the theme of wildlife and nature. Image 2, while depicting a topographical map, also represents the diversity of geographical landscapes, similar to how Image 1 showcases the natural habitat of the lion. The connection lies in the representation of diverse natural environments, whether through wildlife or geographical features."
}

2025-07-28 14:24:44 - Successfully processed folder: Cultural Elements of Spanish football(animal, country, relation, Non-English European, English), testid: 2
2025-07-28 14:24:44 - Processing folder: Cultural Elements of Spanish football(animal, country, relation, Non-English European, English), testid: 3
Folder: Cultural Elements of Spanish football(animal, country, relation, Non-English European, English)
TestID: 3
{
    "response": "**Image 1**: A 3D topographic map of the United Kingdom, showcasing its varied terrain with green and brown hues indicating different elevations.\n\n**Image 2**: A majestic lion resting on a grassy plain, with a serene and powerful presence.\n\n**Image 3**: A 3D topographic map of Spain, highlighting its diverse landscape with orange and green shades representing different elevations.\n\n**Image 4**: A 3D topographic map of Italy, featuring its varied terrain with green and brown hues indicating different elevations.\n\n**Relation**: Geographical Diversity\n\n**Explanation**: Both Image 1 and Image 3 depict 3D topographic maps of different countries, showcasing their unique geographical features and diverse landscapes. Similarly, Image 4, which is a 3D topographic map of Italy, mirrors this theme by highlighting Italy's varied terrain with green and brown hues indicating different elevations. The connection between these images lies in their focus on geographical diversity and the representation of topographical details."
}

2025-07-28 14:25:10 - Successfully processed folder: Cultural Elements of Spanish football(animal, country, relation, Non-English European, English), testid: 3
2025-07-28 14:25:10 - Processing folder: Cultural Elements of Korean football(animal, country, relation, East Asia, English), testid: 0
Folder: Cultural Elements of Korean football(animal, country, relation, East Asia, English)
TestID: 0
{
    "response": "**Image 1**: A cartoon tiger holding a yin-yang symbol.\n**Image 2**: A topographic map of South Korea.\n**Image 3**: A close-up of a lion's face.\n\n**Image 4**: A cartoon lion holding a yin-yang symbol.\n\n**Relation**: Animalistic\n\n**Explanation**: Both Image 1 and Image 4 feature a cartoon animal holding a yin-yang symbol, creating a thematic link between the two images. The yin-yang symbol represents balance and duality, which is a common theme in both images. The cartoon style is consistent between Image 1 and Image 4, further emphasizing their connection."
}

2025-07-28 14:25:30 - Successfully processed folder: Cultural Elements of Korean football(animal, country, relation, East Asia, English), testid: 0
2025-07-28 14:25:30 - Processing folder: Cultural Elements of Korean football(animal, country, relation, East Asia, English), testid: 1
Folder: Cultural Elements of Korean football(animal, country, relation, East Asia, English)
TestID: 1
{
    "response": "**Image 1**: A topographic map of South Korea showing elevation changes with a color gradient. \n**Image 2**: A stylized illustration of a tiger holding a yin-yang symbol. \n**Image 3**: A 3D topographic map of England with a blue background.\n\n**Image 4**: A 3D topographic map of Japan with a blue background.\n\n**Relation**: Geographical Focus\n\n**Explanation**: Both Image 1 and Image 3 are topographic maps of specific countries, South Korea and England, respectively. Image 4, which is a topographic map of Japan, shares the same geographical focus as Image 1 and Image 3, emphasizing the topographical features of a country."
}

2025-07-28 14:25:52 - Successfully processed folder: Cultural Elements of Korean football(animal, country, relation, East Asia, English), testid: 1
2025-07-28 14:25:52 - Processing folder: Cultural Elements of Korean football(animal, country, relation, East Asia, English), testid: 2
2025-07-28 14:25:52 - Error in generate_response: CUDA out of memory. Tried to allocate 2.13 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.01 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.69 GiB memory in use. Of the allocated memory 33.11 GiB is allocated by PyTorch, and 1.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:25:52 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.13 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.01 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.69 GiB memory in use. Of the allocated memory 33.11 GiB is allocated by PyTorch, and 1.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Elements of Korean football(animal, country, relation, East Asia, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:25:52 - Error occurred for folder: Cultural Elements of Korean football(animal, country, relation, East Asia, English), testid: 2. See logs for details.
2025-07-28 14:25:52 - Processing folder: Cultural Elements of Korean football(animal, country, relation, East Asia, English), testid: 3
2025-07-28 14:25:52 - Error in generate_response: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.01 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.69 GiB memory in use. Of the allocated memory 32.90 GiB is allocated by PyTorch, and 1.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:25:52 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.01 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.69 GiB memory in use. Of the allocated memory 32.90 GiB is allocated by PyTorch, and 1.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Elements of Korean football(animal, country, relation, East Asia, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:25:52 - Error occurred for folder: Cultural Elements of Korean football(animal, country, relation, East Asia, English), testid: 3. See logs for details.
2025-07-28 14:25:52 - Processing folder: Symbols of horse(city, animal, relation, Non-English European, English), testid: 0
2025-07-28 14:25:52 - Error in generate_response: CUDA out of memory. Tried to allocate 1.96 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.01 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.69 GiB memory in use. Of the allocated memory 32.92 GiB is allocated by PyTorch, and 1.32 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:25:52 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.96 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.01 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.69 GiB memory in use. Of the allocated memory 32.92 GiB is allocated by PyTorch, and 1.32 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Symbols of horse(city, animal, relation, Non-English European, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:25:52 - Error occurred for folder: Symbols of horse(city, animal, relation, Non-English European, English), testid: 0. See logs for details.
2025-07-28 14:25:52 - Processing folder: Symbols of horse(city, animal, relation, Non-English European, English), testid: 1
2025-07-28 14:25:52 - Error in generate_response: CUDA out of memory. Tried to allocate 1.96 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.01 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.69 GiB memory in use. Of the allocated memory 32.91 GiB is allocated by PyTorch, and 1.32 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:25:52 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.96 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.01 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.69 GiB memory in use. Of the allocated memory 32.91 GiB is allocated by PyTorch, and 1.32 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Symbols of horse(city, animal, relation, Non-English European, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:25:52 - Error occurred for folder: Symbols of horse(city, animal, relation, Non-English European, English), testid: 1. See logs for details.
2025-07-28 14:25:52 - Processing folder: Symbols of horse(city, animal, relation, Non-English European, English), testid: 2
2025-07-28 14:25:53 - Error in generate_response: CUDA out of memory. Tried to allocate 2.80 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.01 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.69 GiB memory in use. Of the allocated memory 33.84 GiB is allocated by PyTorch, and 409.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:25:53 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.80 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.01 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.69 GiB memory in use. Of the allocated memory 33.84 GiB is allocated by PyTorch, and 409.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Symbols of horse(city, animal, relation, Non-English European, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:25:53 - Error occurred for folder: Symbols of horse(city, animal, relation, Non-English European, English), testid: 2. See logs for details.
2025-07-28 14:25:53 - Processing folder: Symbols of horse(city, animal, relation, Non-English European, English), testid: 3
2025-07-28 14:25:53 - Error in generate_response: CUDA out of memory. Tried to allocate 1.94 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.01 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.69 GiB memory in use. Of the allocated memory 32.89 GiB is allocated by PyTorch, and 1.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:25:53 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.94 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.01 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.69 GiB memory in use. Of the allocated memory 32.89 GiB is allocated by PyTorch, and 1.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Symbols of horse(city, animal, relation, Non-English European, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:25:53 - Error occurred for folder: Symbols of horse(city, animal, relation, Non-English European, English), testid: 3. See logs for details.
2025-07-28 14:25:53 - Processing folder: Symbols ofhorse(city, animal, relation, Non-English European, English), testid: 0
Folder: Symbols ofhorse(city, animal, relation, Non-English European, English)
TestID: 0
{
    "response": "**Image 1**: A bronze statue of a horse-drawn carriage with two figures, set against a backdrop of modern buildings.\n\n**Image 2**: A 3D map of France, colored in blue, white, and red, representing the French flag.\n\n**Image 3**: A large elephant walking in a grassy field with a clear blue sky.\n\n**Image 4**: A 3D map of France, colored in blue, white, and red, representing the French flag.\n\n**Relation**: Geographic\n\n**Explanation**: Both Image 2 and Image 4 depict a 3D map of France, colored in blue, white, and red, representing the French flag. The connection is clear as both images focus on the geographical representation of France, with the second image being a specific depiction of the country's topography and the fourth image being a stylized version of the same."
}

2025-07-28 14:26:17 - Successfully processed folder: Symbols ofhorse(city, animal, relation, Non-English European, English), testid: 0
2025-07-28 14:26:17 - Processing folder: Symbols ofhorse(city, animal, relation, Non-English European, English), testid: 1
2025-07-28 14:26:18 - Error in generate_response: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.01 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.69 GiB memory in use. Of the allocated memory 33.00 GiB is allocated by PyTorch, and 1.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:26:18 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.01 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.69 GiB memory in use. Of the allocated memory 33.00 GiB is allocated by PyTorch, and 1.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Symbols ofhorse(city, animal, relation, Non-English European, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:26:18 - Error occurred for folder: Symbols ofhorse(city, animal, relation, Non-English European, English), testid: 1. See logs for details.
2025-07-28 14:26:18 - Processing folder: Symbols ofhorse(city, animal, relation, Non-English European, English), testid: 2
2025-07-28 14:26:18 - Error in generate_response: CUDA out of memory. Tried to allocate 1.81 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 32.75 GiB is allocated by PyTorch, and 1.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:26:18 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.81 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 32.75 GiB is allocated by PyTorch, and 1.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Symbols ofhorse(city, animal, relation, Non-English European, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:26:18 - Error occurred for folder: Symbols ofhorse(city, animal, relation, Non-English European, English), testid: 2. See logs for details.
2025-07-28 14:26:18 - Processing folder: Symbols ofhorse(city, animal, relation, Non-English European, English), testid: 3
Folder: Symbols ofhorse(city, animal, relation, Non-English European, English)
TestID: 3
{
    "response": "Image 1: [a 3D map of Thailand in green and brown colors]\nImage 2: [a brown elephant walking on grass]\nImage 3: [a 3D map of France in blue, white, and red colors]\nImage 4: [a 3D map of Italy in green and brown colors]\n\nRelation: geographical maps\n\nExplanation: Both Image 1 and Image 3 are 3D maps of different countries, Thailand and France, respectively. They share the theme of geography and topography, with each map highlighting the physical features of the respective country. Image 2, while not a map, features an elephant, which is an animal native to certain regions of the world, including parts of Africa and Asia, where Thailand and France are located. The connection between the images is the geographical context, as they all relate to the physical landscapes and natural elements of different countries."
}

2025-07-28 14:26:46 - Successfully processed folder: Symbols ofhorse(city, animal, relation, Non-English European, English), testid: 3
2025-07-28 14:26:47 - Processing folder: Symbolsofhorse(city, animal, relation, Non-English European, English), testid: 0
2025-07-28 14:26:47 - Error in generate_response: CUDA out of memory. Tried to allocate 2.88 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.07 GiB is allocated by PyTorch, and 2.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:26:47 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.88 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.07 GiB is allocated by PyTorch, and 2.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Symbolsofhorse(city, animal, relation, Non-English European, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:26:47 - Error occurred for folder: Symbolsofhorse(city, animal, relation, Non-English European, English), testid: 0. See logs for details.
2025-07-28 14:26:47 - Processing folder: Symbolsofhorse(city, animal, relation, Non-English European, English), testid: 1
2025-07-28 14:26:47 - Error in generate_response: CUDA out of memory. Tried to allocate 2.88 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.07 GiB is allocated by PyTorch, and 2.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:26:47 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.88 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.07 GiB is allocated by PyTorch, and 2.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Symbolsofhorse(city, animal, relation, Non-English European, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:26:47 - Error occurred for folder: Symbolsofhorse(city, animal, relation, Non-English European, English), testid: 1. See logs for details.
2025-07-28 14:26:47 - Processing folder: Symbolsofhorse(city, animal, relation, Non-English European, English), testid: 2
2025-07-28 14:26:47 - Error in generate_response: CUDA out of memory. Tried to allocate 2.88 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.07 GiB is allocated by PyTorch, and 2.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:26:47 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.88 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.07 GiB is allocated by PyTorch, and 2.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Symbolsofhorse(city, animal, relation, Non-English European, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:26:47 - Error occurred for folder: Symbolsofhorse(city, animal, relation, Non-English European, English), testid: 2. See logs for details.
2025-07-28 14:26:47 - Processing folder: Symbolsofhorse(city, animal, relation, Non-English European, English), testid: 3
2025-07-28 14:26:48 - Error in generate_response: CUDA out of memory. Tried to allocate 2.97 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.08 GiB is allocated by PyTorch, and 2.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:26:48 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.97 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 31.08 GiB is allocated by PyTorch, and 2.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Symbolsofhorse(city, animal, relation, Non-English European, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:26:48 - Error occurred for folder: Symbolsofhorse(city, animal, relation, Non-English European, English), testid: 3. See logs for details.
2025-07-28 14:26:48 - Processing folder: Cultural Elements of Koreanfootball(animal, country, relation, East Asia, English), testid: 0
Folder: Cultural Elements of Koreanfootball(animal, country, relation, East Asia, English)
TestID: 0
{
    "response": "Image 1: [A yin-yang symbol featuring a tiger and a white tiger, with a snake and a dragon intertwined in the center, surrounded by autumn leaves and a moon in the background.]\nImage 2: [A topographical map of South Korea, showing the country's terrain and surrounding islands.]\nImage 3: [A kangaroo standing on a beach with clear blue water and a rocky coastline in the background.]\n\nImage 4: [A kangaroo standing on a beach with clear blue water and a rocky coastline in the background.]\n\nRelation: Continent\n\nExplanation: Both Image 1 and Image 2 depict natural elements and landscapes, with Image 1 focusing on a symbolic representation of balance and harmony, and Image 2 showing the geographical features of South Korea. Similarly, Image 3 and Image 4 both feature a kangaroo in a natural setting, emphasizing the animal's habitat. The connection between Image 1 and Image 2 is the theme of nature and geography, while the connection between Image 3 and Image 4 is the focus on wildlife and their environments."
}

2025-07-28 14:27:17 - Successfully processed folder: Cultural Elements of Koreanfootball(animal, country, relation, East Asia, English), testid: 0
2025-07-28 14:27:17 - Processing folder: Cultural Elements of Koreanfootball(animal, country, relation, East Asia, English), testid: 1
Folder: Cultural Elements of Koreanfootball(animal, country, relation, East Asia, English)
TestID: 1
{
    "response": "Image 1: A topographical map of the Korean Peninsula, showing varied terrain with mountainous regions and coastal areas.\nImage 2: A yin-yang symbol featuring a tiger and a white tiger, representing balance and duality.\nImage 3: A topographical map of Australia, highlighting its diverse terrain with deserts, mountains, and coastal regions.\n\n### Analysis:\nBoth Image 1 and Image 3 are topographical maps of different regions, showcasing the physical geography of the Korean Peninsula and Australia, respectively. They share the theme of geographical representation, focusing on the natural landscape and terrain of these areas.\n\n### Image 4:\n- **Image 4**: A yin-yang symbol featuring a kangaroo and an emu, representing balance and duality.\n\n### Relation:\n- **Relation**: Geographical Balance\n- **Explanation**: Just as Image 1 and Image 3 both depict topographical maps of different regions, Image 4 mirrors this by presenting a yin-yang symbol that combines elements of Australian fauna (kangaroo and emu) to symbolize balance and duality, similar to the geographical balance shown in the topographical maps."
}

2025-07-28 14:27:50 - Successfully processed folder: Cultural Elements of Koreanfootball(animal, country, relation, East Asia, English), testid: 1
2025-07-28 14:27:50 - Processing folder: Cultural Elements of Koreanfootball(animal, country, relation, East Asia, English), testid: 2
Folder: Cultural Elements of Koreanfootball(animal, country, relation, East Asia, English)
TestID: 2
{
    "response": "Image 1: [a kangaroo standing on a beach]\nImage 2: [a map of Australia]\nImage 3: [a yin-yang symbol with a tiger and a white tiger]\nImage 4: [a yin-yang symbol with a kangaroo and a wallaby]\n\nRelation: geographical\nExplanation: Both Image 1 and Image 2 depict elements related to Australia, with Image 1 showing a kangaroo on a beach and Image 2 displaying a map of Australia. Image 4 similarly connects to Image 1 by featuring a kangaroo in the yin-yang symbol, while Image 3 connects to Image 2 by incorporating a map of Australia in the yin-yang symbol. The common theme is the representation of Australian wildlife and geography in symbolic forms."
}

2025-07-28 14:28:12 - Successfully processed folder: Cultural Elements of Koreanfootball(animal, country, relation, East Asia, English), testid: 2
2025-07-28 14:28:12 - Processing folder: Cultural Elements of Koreanfootball(animal, country, relation, East Asia, English), testid: 3
Folder: Cultural Elements of Koreanfootball(animal, country, relation, East Asia, English)
TestID: 3
{
    "response": "**Image 1**: [a map of Australia]\n**Image 2**: [a kangaroo on a beach]\n**Image 3**: [a map of South Korea]\n**Image 4**: [a map of Japan]\n\n**Relation**: geographical focus\n\n**Explanation**: Both Image 1 and Image 3 focus on the geographical aspect of their respective countries, Australia and South Korea. Image 1 shows the topography and surrounding waters of Australia, while Image 3 presents the topographical features of South Korea. The creation of Image 4, a map of Japan, similarly emphasizes the geographical focus, mirroring the relationship between Image 1 and Image 3."
}

2025-07-28 14:28:32 - Successfully processed folder: Cultural Elements of Koreanfootball(animal, country, relation, East Asia, English), testid: 3
2025-07-28 14:28:32 - Processing folder: Cultural Elements of Australianfootball(animal, country, relation, other, English), testid: 0
2025-07-28 14:28:32 - Error in generate_response: CUDA out of memory. Tried to allocate 1.45 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 32.35 GiB is allocated by PyTorch, and 1.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:28:32 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.45 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 32.35 GiB is allocated by PyTorch, and 1.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Elements of Australianfootball(animal, country, relation, other, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:28:32 - Error occurred for folder: Cultural Elements of Australianfootball(animal, country, relation, other, English), testid: 0. See logs for details.
2025-07-28 14:28:32 - Processing folder: Cultural Elements of Australianfootball(animal, country, relation, other, English), testid: 1
Folder: Cultural Elements of Australianfootball(animal, country, relation, other, English)
TestID: 1
{
    "response": "### Image 1\n**Image Concept**: A detailed topographic map of Australia, highlighting geographical features such as rivers, mountains, and cities.\n\n### Image 2\n**Image Concept**: A kangaroo standing on a grassy hill, with a natural background of trees and foliage.\n\n### Image 3\n**Image Concept**: A topographic map of Nigeria, showing various elevations and geographical features.\n\n### Image 4\n**Image Concept**: A kangaroo standing on a grassy hill, with a natural background of trees and foliage.\n\n### Relation\n**Relation**: Geographic Connection\n\n### Explanation\nBoth Image 1 and Image 2 share a common theme of geography and natural landscapes. Image 1 is a topographic map of Australia, while Image 2 features a kangaroo in a natural setting. Similarly, Image 3 is a topographic map of Nigeria, and Image 4 depicts a kangaroo in a natural setting. The connection between Image 1 and Image 2 is their shared focus on geographical elements and natural environments, which is mirrored in the relationship between Image 3 and Image 4."
}

2025-07-28 14:29:02 - Successfully processed folder: Cultural Elements of Australianfootball(animal, country, relation, other, English), testid: 1
2025-07-28 14:29:02 - Processing folder: Cultural Elements of Australianfootball(animal, country, relation, other, English), testid: 2
Folder: Cultural Elements of Australianfootball(animal, country, relation, other, English)
TestID: 2
{
    "response": "### Image 1\n**Image Concept**: A majestic bald eagle perched on a wooden post, with a blurred natural background.\n\n### Image 2\n**Image Concept**: A topographic map of Nigeria, showcasing its varied terrain with green and brown regions.\n\n### Image 3\n**Image Concept**: A red kangaroo standing on grass, with a forested background.\n\n### Image 4\n**Image Concept**: A majestic bald eagle perched on a wooden post, with a blurred natural background.\n\n### Relation\n**Keyword**: Wildlife\n\n### Explanation\nBoth Image 1 and Image 4 feature a majestic bald eagle, creating a thematic connection. Similarly, Image 3 and Image 4 both depict wildlife, with Image 3 showing a red kangaroo. The consistent theme of wildlife is maintained across both pairs, linking the images through their natural and serene settings."
}

2025-07-28 14:29:26 - Successfully processed folder: Cultural Elements of Australianfootball(animal, country, relation, other, English), testid: 2
2025-07-28 14:29:26 - Processing folder: Cultural Elements of Australianfootball(animal, country, relation, other, English), testid: 3
2025-07-28 14:29:26 - Error in generate_response: CUDA out of memory. Tried to allocate 1.54 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 32.44 GiB is allocated by PyTorch, and 1.45 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:29:26 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.54 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 32.44 GiB is allocated by PyTorch, and 1.45 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Elements of Australianfootball(animal, country, relation, other, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:29:26 - Error occurred for folder: Cultural Elements of Australianfootball(animal, country, relation, other, English), testid: 3. See logs for details.
2025-07-28 14:29:26 - Processing folder: Cultural Elements of Nigeriafootball(animal, country, relation, other, English), testid: 0
2025-07-28 14:29:26 - Error in generate_response: CUDA out of memory. Tried to allocate 2.11 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 33.08 GiB is allocated by PyTorch, and 833.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:29:26 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.11 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 33.08 GiB is allocated by PyTorch, and 833.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Elements of Nigeriafootball(animal, country, relation, other, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:29:26 - Error occurred for folder: Cultural Elements of Nigeriafootball(animal, country, relation, other, English), testid: 0. See logs for details.
2025-07-28 14:29:26 - Processing folder: Cultural Elements of Nigeriafootball(animal, country, relation, other, English), testid: 1
2025-07-28 14:29:27 - Error in generate_response: CUDA out of memory. Tried to allocate 2.31 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 33.30 GiB is allocated by PyTorch, and 611.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:29:27 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.31 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 33.30 GiB is allocated by PyTorch, and 611.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Elements of Nigeriafootball(animal, country, relation, other, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:29:27 - Error occurred for folder: Cultural Elements of Nigeriafootball(animal, country, relation, other, English), testid: 1. See logs for details.
2025-07-28 14:29:27 - Processing folder: Cultural Elements of Nigeriafootball(animal, country, relation, other, English), testid: 2
2025-07-28 14:29:27 - Error in generate_response: CUDA out of memory. Tried to allocate 2.31 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 33.30 GiB is allocated by PyTorch, and 611.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:29:27 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.31 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.35 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.35 GiB memory in use. Of the allocated memory 33.30 GiB is allocated by PyTorch, and 611.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Elements of Nigeriafootball(animal, country, relation, other, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:29:27 - Error occurred for folder: Cultural Elements of Nigeriafootball(animal, country, relation, other, English), testid: 2. See logs for details.
2025-07-28 14:29:27 - Processing folder: Cultural Elements of Nigeriafootball(animal, country, relation, other, English), testid: 3
Folder: Cultural Elements of Nigeriafootball(animal, country, relation, other, English)
TestID: 3
{
    "response": "### Image 1\n**Image Concept**: Topographic Map of Liberia\n- The image is a topographic map of Liberia, a country in West Africa. It uses color gradients to represent different elevations, with green indicating lower elevations and orange indicating higher elevations. The map includes labels for major geographical features and a scale for altitude in meters.\n\n### Image 2\n**Image Concept**: Herd of Elephants\n- The image shows a herd of elephants walking together in a natural habitat. The elephants are of various sizes, suggesting a mix of adults and juveniles. The background features a grassy plain with a distant horizon, indicating a savanna or grassland environment.\n\n### Image 3\n**Image Concept**: Topographic Map of Nigeria\n- The image is a topographic map of Nigeria, another country in West Africa. Similar to the Liberia map, it uses color gradients to represent different elevations, with green indicating lower elevations and brown indicating higher elevations. The map provides a detailed view of Nigeria's terrain.\n\n### Image 4\n**Image Concept**: Herd of Elephants in a Natural Habitat\n- The image shows a herd of elephants walking together in a natural habitat. The elephants are of various sizes, suggesting a mix of adults and juveniles. The background features a grassy plain with a distant horizon, indicating a savanna or grassland environment.\n\n### Relation\n**Relation**: Geographical Context\n- Both pairs of images share a geographical context, focusing on the natural landscapes of West African countries (Liberia and Nigeria). The first pair (Image 1 and Image 2) connects the topography of Liberia with its wildlife, while the second pair (Image 3 and Image 4) connects the topography of Nigeria with its wildlife.\n\n### Explanation\n- The connection between Image 1 and Image 2 is established through the theme of natural landscapes and wildlife. Both images depict the geographical features of West African countries and their associated fauna. Image 1 shows the topographic map of Liberia, highlighting its elevation changes, while Image 2 shows a herd of elephants in a natural habitat, emphasizing the country's wildlife.\n- Similarly, Image 3 and Image 4 share the same geographical context. Image 3 is a topographic map of Nigeria, and Image 4 shows a herd of elephants in a natural habitat. Both pairs of images highlight the natural beauty and biodiversity of their respective countries, providing a comprehensive view of the geographical and ecological aspects of West Africa."
}

2025-07-28 14:30:36 - Successfully processed folder: Cultural Elements of Nigeriafootball(animal, country, relation, other, English), testid: 3
2025-07-28 14:30:36 - Processing complete. Results saved to ./moonshotai/result_moonshotai_Kimi-VL-A3B-Instruct.json
2025-07-28 14:40:24 - Initializing model...
2025-07-28 14:40:47 - Model initialized successfully.
2025-07-28 14:40:47 - Results already exist and are complete for folder Culture and Art three(animal, country, relation, USAEnglish, English)
2025-07-28 14:40:47 - Results exist but Error found for folder Culture and Art four(animal, country, relation, USAEnglish, English)
2025-07-28 14:40:47 - Processing folder: Culture and Art four(animal, country, relation, USAEnglish, English), testid: 0
2025-07-28 14:40:47 - Error in generate_response: CUDA out of memory. Tried to allocate 4.10 GiB. GPU 0 has a total capacity of 47.40 GiB of which 3.17 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 32.53 GiB memory in use. Of the allocated memory 32.02 GiB is allocated by PyTorch, and 63.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:40:47 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.10 GiB. GPU 0 has a total capacity of 47.40 GiB of which 3.17 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 32.53 GiB memory in use. Of the allocated memory 32.02 GiB is allocated by PyTorch, and 63.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Culture and Art four(animal, country, relation, USAEnglish, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:40:47 - Error occurred for folder: Culture and Art four(animal, country, relation, USAEnglish, English), testid: 0. See logs for details.
2025-07-28 14:40:47 - Processing folder: Culture and Art four(animal, country, relation, USAEnglish, English), testid: 1
2025-07-28 14:40:47 - Error in generate_response: CUDA out of memory. Tried to allocate 3.77 GiB. GPU 0 has a total capacity of 47.40 GiB of which 3.17 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 32.53 GiB memory in use. Of the allocated memory 31.99 GiB is allocated by PyTorch, and 95.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:40:47 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.77 GiB. GPU 0 has a total capacity of 47.40 GiB of which 3.17 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 32.53 GiB memory in use. Of the allocated memory 31.99 GiB is allocated by PyTorch, and 95.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Culture and Art four(animal, country, relation, USAEnglish, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:40:47 - Error occurred for folder: Culture and Art four(animal, country, relation, USAEnglish, English), testid: 1. See logs for details.
2025-07-28 14:40:47 - Processing folder: Culture and Art four(animal, country, relation, USAEnglish, English), testid: 2
2025-07-28 14:40:47 - Error in generate_response: CUDA out of memory. Tried to allocate 3.21 GiB. GPU 0 has a total capacity of 47.40 GiB of which 3.21 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 32.50 GiB memory in use. Of the allocated memory 31.94 GiB is allocated by PyTorch, and 108.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:40:47 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.21 GiB. GPU 0 has a total capacity of 47.40 GiB of which 3.21 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 32.50 GiB memory in use. Of the allocated memory 31.94 GiB is allocated by PyTorch, and 108.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Culture and Art four(animal, country, relation, USAEnglish, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:40:47 - Error occurred for folder: Culture and Art four(animal, country, relation, USAEnglish, English), testid: 2. See logs for details.
2025-07-28 14:40:47 - Processing folder: Culture and Art four(animal, country, relation, USAEnglish, English), testid: 3
2025-07-28 14:40:48 - Error in generate_response: CUDA out of memory. Tried to allocate 1.85 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.56 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.14 GiB memory in use. Of the allocated memory 33.63 GiB is allocated by PyTorch, and 65.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:40:48 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.85 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.56 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.14 GiB memory in use. Of the allocated memory 33.63 GiB is allocated by PyTorch, and 65.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Culture and Art four(animal, country, relation, USAEnglish, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:40:48 - Error occurred for folder: Culture and Art four(animal, country, relation, USAEnglish, English), testid: 3. See logs for details.
2025-07-28 14:40:48 - Results exist but Error found for folder Culture and Art five(animal, country, relation, USAEnglish, English)
2025-07-28 14:40:48 - Processing folder: Culture and Art five(animal, country, relation, USAEnglish, English), testid: 0
2025-07-28 14:40:48 - Error in generate_response: CUDA out of memory. Tried to allocate 2.45 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.56 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.14 GiB memory in use. Of the allocated memory 31.86 GiB is allocated by PyTorch, and 1.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:40:48 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.45 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.56 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.14 GiB memory in use. Of the allocated memory 31.86 GiB is allocated by PyTorch, and 1.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Culture and Art five(animal, country, relation, USAEnglish, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:40:48 - Error occurred for folder: Culture and Art five(animal, country, relation, USAEnglish, English), testid: 0. See logs for details.
2025-07-28 14:40:48 - Processing folder: Culture and Art five(animal, country, relation, USAEnglish, English), testid: 1
2025-07-28 14:40:48 - Error in generate_response: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.56 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.14 GiB memory in use. Of the allocated memory 31.85 GiB is allocated by PyTorch, and 1.84 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:40:48 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.56 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.14 GiB memory in use. Of the allocated memory 31.85 GiB is allocated by PyTorch, and 1.84 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Culture and Art five(animal, country, relation, USAEnglish, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:40:48 - Error occurred for folder: Culture and Art five(animal, country, relation, USAEnglish, English), testid: 1. See logs for details.
2025-07-28 14:40:48 - Processing folder: Culture and Art five(animal, country, relation, USAEnglish, English), testid: 2
2025-07-28 14:40:48 - Error in generate_response: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.56 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.14 GiB memory in use. Of the allocated memory 31.85 GiB is allocated by PyTorch, and 1.84 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:40:48 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.56 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.14 GiB memory in use. Of the allocated memory 31.85 GiB is allocated by PyTorch, and 1.84 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Culture and Art five(animal, country, relation, USAEnglish, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:40:48 - Error occurred for folder: Culture and Art five(animal, country, relation, USAEnglish, English), testid: 2. See logs for details.
2025-07-28 14:40:48 - Processing folder: Culture and Art five(animal, country, relation, USAEnglish, English), testid: 3
2025-07-28 14:40:48 - Error in generate_response: CUDA out of memory. Tried to allocate 2.88 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.59 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.12 GiB memory in use. Of the allocated memory 31.90 GiB is allocated by PyTorch, and 1.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:40:48 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.88 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.59 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 34.12 GiB memory in use. Of the allocated memory 31.90 GiB is allocated by PyTorch, and 1.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Culture and Art five(animal, country, relation, USAEnglish, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:40:48 - Error occurred for folder: Culture and Art five(animal, country, relation, USAEnglish, English), testid: 3. See logs for details.
2025-07-28 14:40:48 - Results exist but Error found for folder Culture and Art six(animal, country, relation, USAEnglish, English)
2025-07-28 14:40:48 - Processing folder: Culture and Art six(animal, country, relation, USAEnglish, English), testid: 2
2025-07-28 14:40:48 - Error in generate_response: CUDA out of memory. Tried to allocate 372.00 MiB. GPU 0 has a total capacity of 47.40 GiB of which 165.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.55 GiB memory in use. Of the allocated memory 34.63 GiB is allocated by PyTorch, and 470.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:40:48 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 372.00 MiB. GPU 0 has a total capacity of 47.40 GiB of which 165.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.55 GiB memory in use. Of the allocated memory 34.63 GiB is allocated by PyTorch, and 470.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Culture and Art six(animal, country, relation, USAEnglish, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:40:48 - Error occurred for folder: Culture and Art six(animal, country, relation, USAEnglish, English), testid: 2. See logs for details.
2025-07-28 14:40:48 - Results exist but Error found for folder Culture and Art seven(animal, country, relation, USAEnglish, English)
2025-07-28 14:40:48 - Processing folder: Culture and Art seven(animal, country, relation, USAEnglish, English), testid: 0
2025-07-28 14:40:48 - Error in generate_response: CUDA out of memory. Tried to allocate 1.66 GiB. GPU 0 has a total capacity of 47.40 GiB of which 185.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.53 GiB memory in use. Of the allocated memory 33.42 GiB is allocated by PyTorch, and 1.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:40:48 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.66 GiB. GPU 0 has a total capacity of 47.40 GiB of which 185.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.53 GiB memory in use. Of the allocated memory 33.42 GiB is allocated by PyTorch, and 1.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Culture and Art seven(animal, country, relation, USAEnglish, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:40:48 - Error occurred for folder: Culture and Art seven(animal, country, relation, USAEnglish, English), testid: 0. See logs for details.
2025-07-28 14:40:48 - Processing folder: Culture and Art seven(animal, country, relation, USAEnglish, English), testid: 2
2025-07-28 14:40:49 - Error in generate_response: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacity of 47.40 GiB of which 185.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.53 GiB memory in use. Of the allocated memory 33.56 GiB is allocated by PyTorch, and 1.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:40:49 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacity of 47.40 GiB of which 185.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.53 GiB memory in use. Of the allocated memory 33.56 GiB is allocated by PyTorch, and 1.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Culture and Art seven(animal, country, relation, USAEnglish, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:40:49 - Error occurred for folder: Culture and Art seven(animal, country, relation, USAEnglish, English), testid: 2. See logs for details.
2025-07-28 14:40:49 - Results already exist and are complete for folder Culture and Art eight(animal, country, relation, USAEnglish, English)
2025-07-28 14:40:49 - Results exist but Error found for folder Culture and Art nine(animal, country, relation, USAEnglish, English)
2025-07-28 14:40:49 - Processing folder: Culture and Art nine(animal, country, relation, USAEnglish, English), testid: 0
2025-07-28 14:40:49 - Error in generate_response: CUDA out of memory. Tried to allocate 1.77 GiB. GPU 0 has a total capacity of 47.40 GiB of which 185.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.53 GiB memory in use. Of the allocated memory 33.53 GiB is allocated by PyTorch, and 1.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:40:49 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.77 GiB. GPU 0 has a total capacity of 47.40 GiB of which 185.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.53 GiB memory in use. Of the allocated memory 33.53 GiB is allocated by PyTorch, and 1.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Culture and Art nine(animal, country, relation, USAEnglish, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:40:49 - Error occurred for folder: Culture and Art nine(animal, country, relation, USAEnglish, English), testid: 0. See logs for details.
2025-07-28 14:40:49 - Processing folder: Culture and Art nine(animal, country, relation, USAEnglish, English), testid: 2
2025-07-28 14:40:49 - Error in generate_response: CUDA out of memory. Tried to allocate 1.51 GiB. GPU 0 has a total capacity of 47.40 GiB of which 185.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.53 GiB memory in use. Of the allocated memory 33.25 GiB is allocated by PyTorch, and 1.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:40:49 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.51 GiB. GPU 0 has a total capacity of 47.40 GiB of which 185.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.53 GiB memory in use. Of the allocated memory 33.25 GiB is allocated by PyTorch, and 1.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Culture and Art nine(animal, country, relation, USAEnglish, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:40:49 - Error occurred for folder: Culture and Art nine(animal, country, relation, USAEnglish, English), testid: 2. See logs for details.
2025-07-28 14:40:49 - Results exist but Error found for folder Culture and Art ten(animal, country, relation, USAEnglish, English)
2025-07-28 14:40:49 - Processing folder: Culture and Art ten(animal, country, relation, USAEnglish, English), testid: 1
2025-07-28 14:40:49 - Error in generate_response: CUDA out of memory. Tried to allocate 1.52 GiB. GPU 0 has a total capacity of 47.40 GiB of which 185.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.53 GiB memory in use. Of the allocated memory 33.26 GiB is allocated by PyTorch, and 1.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:40:49 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.52 GiB. GPU 0 has a total capacity of 47.40 GiB of which 185.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.53 GiB memory in use. Of the allocated memory 33.26 GiB is allocated by PyTorch, and 1.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Culture and Art ten(animal, country, relation, USAEnglish, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:40:49 - Error occurred for folder: Culture and Art ten(animal, country, relation, USAEnglish, English), testid: 1. See logs for details.
2025-07-28 14:40:49 - Processing folder: Culture and Art ten(animal, country, relation, USAEnglish, English), testid: 2
2025-07-28 14:40:49 - Error in generate_response: CUDA out of memory. Tried to allocate 1.84 GiB. GPU 0 has a total capacity of 47.40 GiB of which 185.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.53 GiB memory in use. Of the allocated memory 33.62 GiB is allocated by PyTorch, and 1.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:40:49 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.84 GiB. GPU 0 has a total capacity of 47.40 GiB of which 185.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.53 GiB memory in use. Of the allocated memory 33.62 GiB is allocated by PyTorch, and 1.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Culture and Art ten(animal, country, relation, USAEnglish, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:40:49 - Error occurred for folder: Culture and Art ten(animal, country, relation, USAEnglish, English), testid: 2. See logs for details.
2025-07-28 14:40:49 - Results exist but Error found for folder Culture and Art eleven(animal, country, relation, USAEnglish, English)
2025-07-28 14:40:49 - Processing folder: Culture and Art eleven(animal, country, relation, USAEnglish, English), testid: 0
2025-07-28 14:40:49 - Error in generate_response: CUDA out of memory. Tried to allocate 1.92 GiB. GPU 0 has a total capacity of 47.40 GiB of which 119.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.59 GiB memory in use. Of the allocated memory 33.70 GiB is allocated by PyTorch, and 1.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:40:49 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.92 GiB. GPU 0 has a total capacity of 47.40 GiB of which 119.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.59 GiB memory in use. Of the allocated memory 33.70 GiB is allocated by PyTorch, and 1.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Culture and Art eleven(animal, country, relation, USAEnglish, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:40:49 - Error occurred for folder: Culture and Art eleven(animal, country, relation, USAEnglish, English), testid: 0. See logs for details.
2025-07-28 14:40:49 - Processing folder: Culture and Art eleven(animal, country, relation, USAEnglish, English), testid: 2
2025-07-28 14:40:49 - Error in generate_response: CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacity of 47.40 GiB of which 119.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.59 GiB memory in use. Of the allocated memory 33.45 GiB is allocated by PyTorch, and 1.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:40:49 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacity of 47.40 GiB of which 119.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.59 GiB memory in use. Of the allocated memory 33.45 GiB is allocated by PyTorch, and 1.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Culture and Art eleven(animal, country, relation, USAEnglish, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:40:49 - Error occurred for folder: Culture and Art eleven(animal, country, relation, USAEnglish, English), testid: 2. See logs for details.
2025-07-28 14:40:49 - Results already exist and are complete for folder Culture and Art twelve(animal, country, relation, USAEnglish, English)
2025-07-28 14:40:49 - Results exist but Error found for folder Culture and Art thirteen(animal, country, relation, USAEnglish, English)
2025-07-28 14:40:49 - Processing folder: Culture and Art thirteen(animal, country, relation, USAEnglish, English), testid: 0
2025-07-28 14:40:49 - Error in generate_response: CUDA out of memory. Tried to allocate 1.54 GiB. GPU 0 has a total capacity of 47.40 GiB of which 119.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.59 GiB memory in use. Of the allocated memory 33.28 GiB is allocated by PyTorch, and 1.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:40:49 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.54 GiB. GPU 0 has a total capacity of 47.40 GiB of which 119.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.59 GiB memory in use. Of the allocated memory 33.28 GiB is allocated by PyTorch, and 1.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Culture and Art thirteen(animal, country, relation, USAEnglish, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:40:49 - Error occurred for folder: Culture and Art thirteen(animal, country, relation, USAEnglish, English), testid: 0. See logs for details.
2025-07-28 14:40:49 - Processing folder: Culture and Art thirteen(animal, country, relation, USAEnglish, English), testid: 2
2025-07-28 14:40:50 - Error in generate_response: CUDA out of memory. Tried to allocate 1.66 GiB. GPU 0 has a total capacity of 47.40 GiB of which 119.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.59 GiB memory in use. Of the allocated memory 33.41 GiB is allocated by PyTorch, and 1.73 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:40:50 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.66 GiB. GPU 0 has a total capacity of 47.40 GiB of which 119.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.59 GiB memory in use. Of the allocated memory 33.41 GiB is allocated by PyTorch, and 1.73 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Culture and Art thirteen(animal, country, relation, USAEnglish, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:40:50 - Error occurred for folder: Culture and Art thirteen(animal, country, relation, USAEnglish, English), testid: 2. See logs for details.
2025-07-28 14:40:50 - Results exist but Error found for folder Culture and Art fourteen(animal, country, relation, USAEnglish, English)
2025-07-28 14:40:50 - Processing folder: Culture and Art fourteen(animal, country, relation, USAEnglish, English), testid: 0
2025-07-28 14:40:50 - Error in generate_response: CUDA out of memory. Tried to allocate 4.21 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.03 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.68 GiB memory in use. Of the allocated memory 32.03 GiB is allocated by PyTorch, and 1.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:40:50 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.21 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.03 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.68 GiB memory in use. Of the allocated memory 32.03 GiB is allocated by PyTorch, and 1.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Culture and Art fourteen(animal, country, relation, USAEnglish, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:40:50 - Error occurred for folder: Culture and Art fourteen(animal, country, relation, USAEnglish, English), testid: 0. See logs for details.
2025-07-28 14:40:50 - Processing folder: Culture and Art fourteen(animal, country, relation, USAEnglish, English), testid: 1
2025-07-28 14:40:50 - Error in generate_response: CUDA out of memory. Tried to allocate 6.37 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 32.21 GiB is allocated by PyTorch, and 1019.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:40:50 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 6.37 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 32.21 GiB is allocated by PyTorch, and 1019.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Culture and Art fourteen(animal, country, relation, USAEnglish, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:40:50 - Error occurred for folder: Culture and Art fourteen(animal, country, relation, USAEnglish, English), testid: 1. See logs for details.
2025-07-28 14:40:50 - Processing folder: Culture and Art fourteen(animal, country, relation, USAEnglish, English), testid: 2
2025-07-28 14:40:50 - Error in generate_response: CUDA out of memory. Tried to allocate 4.68 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 32.07 GiB is allocated by PyTorch, and 1.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:40:50 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.68 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 32.07 GiB is allocated by PyTorch, and 1.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Culture and Art fourteen(animal, country, relation, USAEnglish, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:40:50 - Error occurred for folder: Culture and Art fourteen(animal, country, relation, USAEnglish, English), testid: 2. See logs for details.
2025-07-28 14:40:50 - Processing folder: Culture and Art fourteen(animal, country, relation, USAEnglish, English), testid: 3
2025-07-28 14:40:50 - Error in generate_response: CUDA out of memory. Tried to allocate 6.42 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 32.21 GiB is allocated by PyTorch, and 1015.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:40:50 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 6.42 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 32.21 GiB is allocated by PyTorch, and 1015.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Culture and Art fourteen(animal, country, relation, USAEnglish, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:40:50 - Error occurred for folder: Culture and Art fourteen(animal, country, relation, USAEnglish, English), testid: 3. See logs for details.
2025-07-28 14:40:50 - Results exist but Error found for folder Culture and Art fifthteen(animal, country, relation, USAEnglish, English)
2025-07-28 14:40:50 - Processing folder: Culture and Art fifthteen(animal, country, relation, USAEnglish, English), testid: 0
2025-07-28 14:40:51 - Error in generate_response: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.91 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:40:51 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.91 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Culture and Art fifthteen(animal, country, relation, USAEnglish, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:40:51 - Error occurred for folder: Culture and Art fifthteen(animal, country, relation, USAEnglish, English), testid: 0. See logs for details.
2025-07-28 14:40:51 - Processing folder: Culture and Art fifthteen(animal, country, relation, USAEnglish, English), testid: 1
2025-07-28 14:40:51 - Error in generate_response: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacity of 47.40 GiB of which 75.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.63 GiB memory in use. Of the allocated memory 33.77 GiB is allocated by PyTorch, and 1.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:40:51 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacity of 47.40 GiB of which 75.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.63 GiB memory in use. Of the allocated memory 33.77 GiB is allocated by PyTorch, and 1.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Culture and Art fifthteen(animal, country, relation, USAEnglish, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:40:51 - Error occurred for folder: Culture and Art fifthteen(animal, country, relation, USAEnglish, English), testid: 1. See logs for details.
2025-07-28 14:40:51 - Processing folder: Culture and Art fifthteen(animal, country, relation, USAEnglish, English), testid: 2
2025-07-28 14:40:52 - Error in generate_response: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 47.40 GiB of which 75.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.63 GiB memory in use. Of the allocated memory 33.73 GiB is allocated by PyTorch, and 1.45 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:40:52 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 47.40 GiB of which 75.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.63 GiB memory in use. Of the allocated memory 33.73 GiB is allocated by PyTorch, and 1.45 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Culture and Art fifthteen(animal, country, relation, USAEnglish, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:40:52 - Error occurred for folder: Culture and Art fifthteen(animal, country, relation, USAEnglish, English), testid: 2. See logs for details.
2025-07-28 14:40:52 - Processing folder: Culture and Art fifthteen(animal, country, relation, USAEnglish, English), testid: 3
2025-07-28 14:40:53 - Error in generate_response: CUDA out of memory. Tried to allocate 1.97 GiB. GPU 0 has a total capacity of 47.40 GiB of which 75.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.63 GiB memory in use. Of the allocated memory 33.75 GiB is allocated by PyTorch, and 1.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:40:53 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.97 GiB. GPU 0 has a total capacity of 47.40 GiB of which 75.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.63 GiB memory in use. Of the allocated memory 33.75 GiB is allocated by PyTorch, and 1.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Culture and Art fifthteen(animal, country, relation, USAEnglish, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:40:53 - Error occurred for folder: Culture and Art fifthteen(animal, country, relation, USAEnglish, English), testid: 3. See logs for details.
2025-07-28 14:40:53 - Results exist but Error found for folder Animals and City(animal, city, relation, East Asia, English)
2025-07-28 14:40:53 - Processing folder: Animals and City(animal, city, relation, East Asia, English), testid: 0
2025-07-28 14:40:54 - Error in generate_response: CUDA out of memory. Tried to allocate 3.45 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.96 GiB is allocated by PyTorch, and 1.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:40:54 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.45 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.96 GiB is allocated by PyTorch, and 1.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Animals and City(animal, city, relation, East Asia, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:40:54 - Error occurred for folder: Animals and City(animal, city, relation, East Asia, English), testid: 0. See logs for details.
2025-07-28 14:40:54 - Processing folder: Animals and City(animal, city, relation, East Asia, English), testid: 1
2025-07-28 14:40:55 - Error in generate_response: CUDA out of memory. Tried to allocate 3.45 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.96 GiB is allocated by PyTorch, and 1.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:40:55 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.45 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.96 GiB is allocated by PyTorch, and 1.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Animals and City(animal, city, relation, East Asia, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:40:55 - Error occurred for folder: Animals and City(animal, city, relation, East Asia, English), testid: 1. See logs for details.
2025-07-28 14:40:55 - Processing folder: Animals and City(animal, city, relation, East Asia, English), testid: 2
2025-07-28 14:40:56 - Error in generate_response: CUDA out of memory. Tried to allocate 1.86 GiB. GPU 0 has a total capacity of 47.40 GiB of which 195.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.52 GiB memory in use. Of the allocated memory 33.64 GiB is allocated by PyTorch, and 1.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:40:56 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.86 GiB. GPU 0 has a total capacity of 47.40 GiB of which 195.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.52 GiB memory in use. Of the allocated memory 33.64 GiB is allocated by PyTorch, and 1.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Animals and City(animal, city, relation, East Asia, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:40:56 - Error occurred for folder: Animals and City(animal, city, relation, East Asia, English), testid: 2. See logs for details.
2025-07-28 14:40:56 - Processing folder: Animals and City(animal, city, relation, East Asia, English), testid: 3
2025-07-28 14:40:57 - Error in generate_response: CUDA out of memory. Tried to allocate 4.91 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 32.09 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:40:57 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.91 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 32.09 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Animals and City(animal, city, relation, East Asia, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:40:57 - Error occurred for folder: Animals and City(animal, city, relation, East Asia, English), testid: 3. See logs for details.
2025-07-28 14:40:57 - Results already exist and are complete for folder Culture and Art sixteen(animal, country, relation, USAEnglish, English)
2025-07-28 14:40:57 - Results exist but Error found for folder Specific Habitat Preferences and Their Climate Patterns(animal, city, relation, East Asia, English)
2025-07-28 14:40:57 - Processing folder: Specific Habitat Preferences and Their Climate Patterns(animal, city, relation, East Asia, English), testid: 0
2025-07-28 14:40:58 - Error in generate_response: CUDA out of memory. Tried to allocate 4.82 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 32.08 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:40:58 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.82 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 32.08 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Specific Habitat Preferences and Their Climate Patterns(animal, city, relation, East Asia, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:40:58 - Error occurred for folder: Specific Habitat Preferences and Their Climate Patterns(animal, city, relation, East Asia, English), testid: 0. See logs for details.
2025-07-28 14:40:58 - Processing folder: Specific Habitat Preferences and Their Climate Patterns(animal, city, relation, East Asia, English), testid: 1
2025-07-28 14:41:00 - Error in generate_response: CUDA out of memory. Tried to allocate 3.34 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.95 GiB is allocated by PyTorch, and 1.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:00 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.34 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.95 GiB is allocated by PyTorch, and 1.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Specific Habitat Preferences and Their Climate Patterns(animal, city, relation, East Asia, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:00 - Error occurred for folder: Specific Habitat Preferences and Their Climate Patterns(animal, city, relation, East Asia, English), testid: 1. See logs for details.
2025-07-28 14:41:00 - Processing folder: Specific Habitat Preferences and Their Climate Patterns(animal, city, relation, East Asia, English), testid: 2
2025-07-28 14:41:01 - Error in generate_response: CUDA out of memory. Tried to allocate 1.77 GiB. GPU 0 has a total capacity of 47.40 GiB of which 293.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.42 GiB memory in use. Of the allocated memory 33.53 GiB is allocated by PyTorch, and 1.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:01 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.77 GiB. GPU 0 has a total capacity of 47.40 GiB of which 293.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.42 GiB memory in use. Of the allocated memory 33.53 GiB is allocated by PyTorch, and 1.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Specific Habitat Preferences and Their Climate Patterns(animal, city, relation, East Asia, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:01 - Error occurred for folder: Specific Habitat Preferences and Their Climate Patterns(animal, city, relation, East Asia, English), testid: 2. See logs for details.
2025-07-28 14:41:01 - Processing folder: Specific Habitat Preferences and Their Climate Patterns(animal, city, relation, East Asia, English), testid: 3
2025-07-28 14:41:02 - Error in generate_response: CUDA out of memory. Tried to allocate 3.36 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.95 GiB is allocated by PyTorch, and 1.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:02 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.36 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.95 GiB is allocated by PyTorch, and 1.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Specific Habitat Preferences and Their Climate Patterns(animal, city, relation, East Asia, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:02 - Error occurred for folder: Specific Habitat Preferences and Their Climate Patterns(animal, city, relation, East Asia, English), testid: 3. See logs for details.
2025-07-28 14:41:02 - Results exist but Error found for folder Cultural Representation of Endangered Species from China(animal, people, relation, East Asia, English)
2025-07-28 14:41:02 - Processing folder: Cultural Representation of Endangered Species from China(animal, people, relation, East Asia, English), testid: 1
2025-07-28 14:41:02 - Error in generate_response: CUDA out of memory. Tried to allocate 2.11 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.83 GiB is allocated by PyTorch, and 1.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:02 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.11 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.83 GiB is allocated by PyTorch, and 1.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Representation of Endangered Species from China(animal, people, relation, East Asia, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:02 - Error occurred for folder: Cultural Representation of Endangered Species from China(animal, people, relation, East Asia, English), testid: 1. See logs for details.
2025-07-28 14:41:02 - Processing folder: Cultural Representation of Endangered Species from China(animal, people, relation, East Asia, English), testid: 2
2025-07-28 14:41:03 - Error in generate_response: CUDA out of memory. Tried to allocate 1.49 GiB. GPU 0 has a total capacity of 47.40 GiB of which 575.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.15 GiB memory in use. Of the allocated memory 33.23 GiB is allocated by PyTorch, and 1.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:03 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.49 GiB. GPU 0 has a total capacity of 47.40 GiB of which 575.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.15 GiB memory in use. Of the allocated memory 33.23 GiB is allocated by PyTorch, and 1.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Representation of Endangered Species from China(animal, people, relation, East Asia, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:03 - Error occurred for folder: Cultural Representation of Endangered Species from China(animal, people, relation, East Asia, English), testid: 2. See logs for details.
2025-07-28 14:41:03 - Results exist but Error found for folder Geographical Origin of Celebrities and Their Associated Climate Patterns(city, people, relation, East Asia, English)
2025-07-28 14:41:03 - Error opening image ./img/Geographical Origin of Celebrities and Their Associated Climate Patterns(city, people, relation, East Asia, English)/A precipitation map of Urumqi.jpg: cannot identify image file '/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/img/Geographical Origin of Celebrities and Their Associated Climate Patterns(city, people, relation, East Asia, English)/A precipitation map of Urumqi.jpg'
2025-07-28 14:41:03 - Error opening image ./img/Geographical Origin of Celebrities and Their Associated Climate Patterns(city, people, relation, East Asia, English)/A precipitation map of Beijing.jpg: cannot identify image file '/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/img/Geographical Origin of Celebrities and Their Associated Climate Patterns(city, people, relation, East Asia, English)/A precipitation map of Beijing.jpg'
2025-07-28 14:41:03 - Four valid images are required for processing.
2025-07-28 14:41:03 - Results exist but Error found for folder Geographical Significance(city, country, metaphor, East Asia, English)
2025-07-28 14:41:03 - Processing folder: Geographical Significance(city, country, metaphor, East Asia, English), testid: 0
2025-07-28 14:41:03 - Error in generate_response: CUDA out of memory. Tried to allocate 2.16 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.83 GiB is allocated by PyTorch, and 1.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:03 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.16 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.83 GiB is allocated by PyTorch, and 1.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Geographical Significance(city, country, metaphor, East Asia, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:03 - Error occurred for folder: Geographical Significance(city, country, metaphor, East Asia, English), testid: 0. See logs for details.
2025-07-28 14:41:03 - Processing folder: Geographical Significance(city, country, metaphor, East Asia, English), testid: 2
2025-07-28 14:41:04 - Error in generate_response: CUDA out of memory. Tried to allocate 1.92 GiB. GPU 0 has a total capacity of 47.40 GiB of which 137.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.57 GiB memory in use. Of the allocated memory 33.70 GiB is allocated by PyTorch, and 1.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:04 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.92 GiB. GPU 0 has a total capacity of 47.40 GiB of which 137.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.57 GiB memory in use. Of the allocated memory 33.70 GiB is allocated by PyTorch, and 1.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Geographical Significance(city, country, metaphor, East Asia, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:04 - Error occurred for folder: Geographical Significance(city, country, metaphor, East Asia, English), testid: 2. See logs for details.
2025-07-28 14:41:04 - Results exist but Error found for folder Cultural Significance and Population Centers(city, country, metaphor, East Asia, English)
2025-07-28 14:41:04 - Processing folder: Cultural Significance and Population Centers(city, country, metaphor, East Asia, English), testid: 0
2025-07-28 14:41:04 - Error in generate_response: CUDA out of memory. Tried to allocate 2.88 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.91 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:04 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.88 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.91 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Significance and Population Centers(city, country, metaphor, East Asia, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:04 - Error occurred for folder: Cultural Significance and Population Centers(city, country, metaphor, East Asia, English), testid: 0. See logs for details.
2025-07-28 14:41:04 - Processing folder: Cultural Significance and Population Centers(city, country, metaphor, East Asia, English), testid: 1
2025-07-28 14:41:04 - Error in generate_response: CUDA out of memory. Tried to allocate 2.79 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.90 GiB is allocated by PyTorch, and 1.31 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:04 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.79 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.90 GiB is allocated by PyTorch, and 1.31 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Significance and Population Centers(city, country, metaphor, East Asia, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:04 - Error occurred for folder: Cultural Significance and Population Centers(city, country, metaphor, East Asia, English), testid: 1. See logs for details.
2025-07-28 14:41:04 - Processing folder: Cultural Significance and Population Centers(city, country, metaphor, East Asia, English), testid: 2
2025-07-28 14:41:04 - Error in generate_response: CUDA out of memory. Tried to allocate 2.85 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.90 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:04 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.85 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.90 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Significance and Population Centers(city, country, metaphor, East Asia, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:04 - Error occurred for folder: Cultural Significance and Population Centers(city, country, metaphor, East Asia, English), testid: 2. See logs for details.
2025-07-28 14:41:04 - Processing folder: Cultural Significance and Population Centers(city, country, metaphor, East Asia, English), testid: 3
2025-07-28 14:41:04 - Error in generate_response: CUDA out of memory. Tried to allocate 2.82 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.90 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:04 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.82 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.90 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Significance and Population Centers(city, country, metaphor, East Asia, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:04 - Error occurred for folder: Cultural Significance and Population Centers(city, country, metaphor, East Asia, English), testid: 3. See logs for details.
2025-07-28 14:41:04 - Results exist but Error found for folder Cultural Symbolism and Environmental Influences(animal, country, metaphor, East Asia, English)
2025-07-28 14:41:04 - Processing folder: Cultural Symbolism and Environmental Influences(animal, country, metaphor, East Asia, English), testid: 1
2025-07-28 14:41:04 - Error in generate_response: CUDA out of memory. Tried to allocate 1.52 GiB. GPU 0 has a total capacity of 47.40 GiB of which 547.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.17 GiB memory in use. Of the allocated memory 33.26 GiB is allocated by PyTorch, and 1.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:04 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.52 GiB. GPU 0 has a total capacity of 47.40 GiB of which 547.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.17 GiB memory in use. Of the allocated memory 33.26 GiB is allocated by PyTorch, and 1.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Symbolism and Environmental Influences(animal, country, metaphor, East Asia, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:04 - Error occurred for folder: Cultural Symbolism and Environmental Influences(animal, country, metaphor, East Asia, English), testid: 1. See logs for details.
2025-07-28 14:41:04 - Processing folder: Cultural Symbolism and Environmental Influences(animal, country, metaphor, East Asia, English), testid: 2
2025-07-28 14:41:05 - Error in generate_response: CUDA out of memory. Tried to allocate 1.52 GiB. GPU 0 has a total capacity of 47.40 GiB of which 547.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.17 GiB memory in use. Of the allocated memory 33.26 GiB is allocated by PyTorch, and 1.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:05 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.52 GiB. GPU 0 has a total capacity of 47.40 GiB of which 547.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.17 GiB memory in use. Of the allocated memory 33.26 GiB is allocated by PyTorch, and 1.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Symbolism and Environmental Influences(animal, country, metaphor, East Asia, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:05 - Error occurred for folder: Cultural Symbolism and Environmental Influences(animal, country, metaphor, East Asia, English), testid: 2. See logs for details.
2025-07-28 14:41:05 - Results exist but Error found for folder Cultural Roots and Historical Influence(animal, country, metaphor, East Asia, English)
2025-07-28 14:41:05 - Error opening image ./img/Cultural Roots and Historical Influence(animal, country, metaphor, East Asia, English)/A historical map depicting the Warring States situation in Japan.jpg: cannot identify image file '/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/img/Cultural Roots and Historical Influence(animal, country, metaphor, East Asia, English)/A historical map depicting the Warring States situation in Japan.jpg'
2025-07-28 14:41:05 - Four valid images are required for processing.
2025-07-28 14:41:05 - Results exist but Error found for folder Cultural Symbols and Urban Infrastructure(animal, city, metaphor, East Asia, English)
2025-07-28 14:41:05 - Processing folder: Cultural Symbols and Urban Infrastructure(animal, city, metaphor, East Asia, English), testid: 0
2025-07-28 14:41:05 - Error in generate_response: CUDA out of memory. Tried to allocate 1.68 GiB. GPU 0 has a total capacity of 47.40 GiB of which 381.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.34 GiB memory in use. Of the allocated memory 33.44 GiB is allocated by PyTorch, and 1.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:05 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.68 GiB. GPU 0 has a total capacity of 47.40 GiB of which 381.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.34 GiB memory in use. Of the allocated memory 33.44 GiB is allocated by PyTorch, and 1.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Symbols and Urban Infrastructure(animal, city, metaphor, East Asia, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:05 - Error occurred for folder: Cultural Symbols and Urban Infrastructure(animal, city, metaphor, East Asia, English), testid: 0. See logs for details.
2025-07-28 14:41:05 - Processing folder: Cultural Symbols and Urban Infrastructure(animal, city, metaphor, East Asia, English), testid: 1
2025-07-28 14:41:05 - Error in generate_response: CUDA out of memory. Tried to allocate 1.68 GiB. GPU 0 has a total capacity of 47.40 GiB of which 381.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.34 GiB memory in use. Of the allocated memory 33.44 GiB is allocated by PyTorch, and 1.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:05 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.68 GiB. GPU 0 has a total capacity of 47.40 GiB of which 381.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.34 GiB memory in use. Of the allocated memory 33.44 GiB is allocated by PyTorch, and 1.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Symbols and Urban Infrastructure(animal, city, metaphor, East Asia, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:05 - Error occurred for folder: Cultural Symbols and Urban Infrastructure(animal, city, metaphor, East Asia, English), testid: 1. See logs for details.
2025-07-28 14:41:05 - Processing folder: Cultural Symbols and Urban Infrastructure(animal, city, metaphor, East Asia, English), testid: 2
2025-07-28 14:41:05 - Error in generate_response: CUDA out of memory. Tried to allocate 2.79 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.90 GiB is allocated by PyTorch, and 1.31 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:05 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.79 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.90 GiB is allocated by PyTorch, and 1.31 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Symbols and Urban Infrastructure(animal, city, metaphor, East Asia, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:05 - Error occurred for folder: Cultural Symbols and Urban Infrastructure(animal, city, metaphor, East Asia, English), testid: 2. See logs for details.
2025-07-28 14:41:05 - Processing folder: Cultural Symbols and Urban Infrastructure(animal, city, metaphor, East Asia, English), testid: 3
2025-07-28 14:41:05 - Error in generate_response: CUDA out of memory. Tried to allocate 1.68 GiB. GPU 0 has a total capacity of 47.40 GiB of which 381.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.34 GiB memory in use. Of the allocated memory 33.44 GiB is allocated by PyTorch, and 1.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:05 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.68 GiB. GPU 0 has a total capacity of 47.40 GiB of which 381.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.34 GiB memory in use. Of the allocated memory 33.44 GiB is allocated by PyTorch, and 1.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Symbols and Urban Infrastructure(animal, city, metaphor, East Asia, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:05 - Error occurred for folder: Cultural Symbols and Urban Infrastructure(animal, city, metaphor, East Asia, English), testid: 3. See logs for details.
2025-07-28 14:41:05 - Results exist but Error found for folder Cultural Symbols and Historical Contexts(animal, country, metaphor, East Asia, English)
2025-07-28 14:41:05 - Processing folder: Cultural Symbols and Historical Contexts(animal, country, metaphor, East Asia, English), testid: 0
2025-07-28 14:41:05 - Error in generate_response: CUDA out of memory. Tried to allocate 1.78 GiB. GPU 0 has a total capacity of 47.40 GiB of which 283.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.43 GiB memory in use. Of the allocated memory 33.54 GiB is allocated by PyTorch, and 1.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:05 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.78 GiB. GPU 0 has a total capacity of 47.40 GiB of which 283.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.43 GiB memory in use. Of the allocated memory 33.54 GiB is allocated by PyTorch, and 1.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Symbols and Historical Contexts(animal, country, metaphor, East Asia, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:05 - Error occurred for folder: Cultural Symbols and Historical Contexts(animal, country, metaphor, East Asia, English), testid: 0. See logs for details.
2025-07-28 14:41:05 - Processing folder: Cultural Symbols and Historical Contexts(animal, country, metaphor, East Asia, English), testid: 2
2025-07-28 14:41:06 - Error in generate_response: CUDA out of memory. Tried to allocate 1.73 GiB. GPU 0 has a total capacity of 47.40 GiB of which 283.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.43 GiB memory in use. Of the allocated memory 33.49 GiB is allocated by PyTorch, and 1.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:06 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.73 GiB. GPU 0 has a total capacity of 47.40 GiB of which 283.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.43 GiB memory in use. Of the allocated memory 33.49 GiB is allocated by PyTorch, and 1.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Symbols and Historical Contexts(animal, country, metaphor, East Asia, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:06 - Error occurred for folder: Cultural Symbols and Historical Contexts(animal, country, metaphor, East Asia, English), testid: 2. See logs for details.
2025-07-28 14:41:06 - Results already exist and are complete for folder Cultural Icons and National Significance two(animal, country, metaphor, East Asia, English)
2025-07-28 14:41:06 - Results already exist and are complete for folder Cultural Icons and Endangered Species two(people, animal, metaphor, East Asia, English)
2025-07-28 14:41:06 - Results exist but Error found for folder Cultural Icons and National Significance three(animal, country, metaphor, East Asia, English)
2025-07-28 14:41:06 - Processing folder: Cultural Icons and National Significance three(animal, country, metaphor, East Asia, English), testid: 0
2025-07-28 14:41:06 - Error in generate_response: CUDA out of memory. Tried to allocate 1.70 GiB. GPU 0 has a total capacity of 47.40 GiB of which 283.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.43 GiB memory in use. Of the allocated memory 33.46 GiB is allocated by PyTorch, and 1.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:06 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.70 GiB. GPU 0 has a total capacity of 47.40 GiB of which 283.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.43 GiB memory in use. Of the allocated memory 33.46 GiB is allocated by PyTorch, and 1.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Icons and National Significance three(animal, country, metaphor, East Asia, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:06 - Error occurred for folder: Cultural Icons and National Significance three(animal, country, metaphor, East Asia, English), testid: 0. See logs for details.
2025-07-28 14:41:06 - Processing folder: Cultural Icons and National Significance three(animal, country, metaphor, East Asia, English), testid: 2
2025-07-28 14:41:06 - Error in generate_response: CUDA out of memory. Tried to allocate 2.02 GiB. GPU 0 has a total capacity of 47.40 GiB of which 35.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.67 GiB memory in use. Of the allocated memory 33.81 GiB is allocated by PyTorch, and 1.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:06 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.02 GiB. GPU 0 has a total capacity of 47.40 GiB of which 35.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.67 GiB memory in use. Of the allocated memory 33.81 GiB is allocated by PyTorch, and 1.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Icons and National Significance three(animal, country, metaphor, East Asia, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:06 - Error occurred for folder: Cultural Icons and National Significance three(animal, country, metaphor, East Asia, English), testid: 2. See logs for details.
2025-07-28 14:41:06 - Results already exist and are complete for folder Cultural Symbols and Animals(animal, country, metaphor, East Asia, English)
2025-07-28 14:41:06 - Results already exist and are complete for folder Cultural Symbols and Animals three(animal, country, metaphor, East Asia, English)
2025-07-28 14:41:06 - Results exist but Error found for folder Cultural Symbols and Animals four(animal, country, metaphor, East Asia, English)
2025-07-28 14:41:06 - Processing folder: Cultural Symbols and Animals four(animal, country, metaphor, East Asia, English), testid: 0
2025-07-28 14:41:07 - Error in generate_response: CUDA out of memory. Tried to allocate 2.20 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.84 GiB is allocated by PyTorch, and 1.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:07 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.20 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.84 GiB is allocated by PyTorch, and 1.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Symbols and Animals four(animal, country, metaphor, East Asia, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:07 - Error occurred for folder: Cultural Symbols and Animals four(animal, country, metaphor, East Asia, English), testid: 0. See logs for details.
2025-07-28 14:41:07 - Processing folder: Cultural Symbols and Animals four(animal, country, metaphor, East Asia, English), testid: 1
2025-07-28 14:41:07 - Error in generate_response: CUDA out of memory. Tried to allocate 2.20 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.84 GiB is allocated by PyTorch, and 1.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:07 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.20 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.84 GiB is allocated by PyTorch, and 1.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Symbols and Animals four(animal, country, metaphor, East Asia, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:07 - Error occurred for folder: Cultural Symbols and Animals four(animal, country, metaphor, East Asia, English), testid: 1. See logs for details.
2025-07-28 14:41:07 - Results exist but Error found for folder Cultural Symbols and Animals five(animal, country, metaphor, East Asia, English)
2025-07-28 14:41:07 - Processing folder: Cultural Symbols and Animals five(animal, country, metaphor, East Asia, English), testid: 0
2025-07-28 14:41:07 - Error in generate_response: CUDA out of memory. Tried to allocate 3.87 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 1.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:07 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.87 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 1.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Symbols and Animals five(animal, country, metaphor, East Asia, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:07 - Error occurred for folder: Cultural Symbols and Animals five(animal, country, metaphor, East Asia, English), testid: 0. See logs for details.
2025-07-28 14:41:07 - Processing folder: Cultural Symbols and Animals five(animal, country, metaphor, East Asia, English), testid: 1
2025-07-28 14:41:07 - Error in generate_response: CUDA out of memory. Tried to allocate 4.78 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 32.08 GiB is allocated by PyTorch, and 1.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:07 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.78 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 32.08 GiB is allocated by PyTorch, and 1.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Symbols and Animals five(animal, country, metaphor, East Asia, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:07 - Error occurred for folder: Cultural Symbols and Animals five(animal, country, metaphor, East Asia, English), testid: 1. See logs for details.
2025-07-28 14:41:07 - Processing folder: Cultural Symbols and Animals five(animal, country, metaphor, East Asia, English), testid: 2
2025-07-28 14:41:08 - Error in generate_response: CUDA out of memory. Tried to allocate 2.17 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.83 GiB is allocated by PyTorch, and 1.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:08 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.17 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.83 GiB is allocated by PyTorch, and 1.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Symbols and Animals five(animal, country, metaphor, East Asia, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:08 - Error occurred for folder: Cultural Symbols and Animals five(animal, country, metaphor, East Asia, English), testid: 2. See logs for details.
2025-07-28 14:41:08 - Processing folder: Cultural Symbols and Animals five(animal, country, metaphor, East Asia, English), testid: 3
2025-07-28 14:41:08 - Error in generate_response: CUDA out of memory. Tried to allocate 3.78 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.99 GiB is allocated by PyTorch, and 1.22 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:08 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.78 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.99 GiB is allocated by PyTorch, and 1.22 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Symbols and Animals five(animal, country, metaphor, East Asia, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:08 - Error occurred for folder: Cultural Symbols and Animals five(animal, country, metaphor, East Asia, English), testid: 3. See logs for details.
2025-07-28 14:41:08 - Results already exist and are complete for folder Cultural Symbols and Animals six(animal, country, metaphor, East Asia, English)
2025-07-28 14:41:08 - Results exist but Error found for folder Cultural Symbols and Animals seven(animal, country, metaphor, East Asia, English)
2025-07-28 14:41:08 - Processing folder: Cultural Symbols and Animals seven(animal, country, metaphor, East Asia, English), testid: 1
2025-07-28 14:41:08 - Error in generate_response: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.91 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:08 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.91 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Symbols and Animals seven(animal, country, metaphor, East Asia, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:08 - Error occurred for folder: Cultural Symbols and Animals seven(animal, country, metaphor, East Asia, English), testid: 1. See logs for details.
2025-07-28 14:41:08 - Processing folder: Cultural Symbols and Animals seven(animal, country, metaphor, East Asia, English), testid: 2
2025-07-28 14:41:08 - Error in generate_response: CUDA out of memory. Tried to allocate 1.64 GiB. GPU 0 has a total capacity of 47.40 GiB of which 421.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.30 GiB memory in use. Of the allocated memory 33.39 GiB is allocated by PyTorch, and 1.45 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:08 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.64 GiB. GPU 0 has a total capacity of 47.40 GiB of which 421.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.30 GiB memory in use. Of the allocated memory 33.39 GiB is allocated by PyTorch, and 1.45 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Symbols and Animals seven(animal, country, metaphor, East Asia, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:08 - Error occurred for folder: Cultural Symbols and Animals seven(animal, country, metaphor, East Asia, English), testid: 2. See logs for details.
2025-07-28 14:41:08 - Processing folder: Cultural Symbols and Animals seven(animal, country, metaphor, East Asia, English), testid: 3
2025-07-28 14:41:08 - Error in generate_response: CUDA out of memory. Tried to allocate 1.61 GiB. GPU 0 has a total capacity of 47.40 GiB of which 421.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.30 GiB memory in use. Of the allocated memory 33.36 GiB is allocated by PyTorch, and 1.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:08 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.61 GiB. GPU 0 has a total capacity of 47.40 GiB of which 421.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.30 GiB memory in use. Of the allocated memory 33.36 GiB is allocated by PyTorch, and 1.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Symbols and Animals seven(animal, country, metaphor, East Asia, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:08 - Error occurred for folder: Cultural Symbols and Animals seven(animal, country, metaphor, East Asia, English), testid: 3. See logs for details.
2025-07-28 14:41:08 - Results exist but Error found for folder Cultural Symbols and Animals eight(animal, country, metaphor, East Asia, English)
2025-07-28 14:41:08 - Processing folder: Cultural Symbols and Animals eight(animal, country, metaphor, East Asia, English), testid: 1
2025-07-28 14:41:08 - Error in generate_response: CUDA out of memory. Tried to allocate 1.68 GiB. GPU 0 has a total capacity of 47.40 GiB of which 385.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.33 GiB memory in use. Of the allocated memory 33.43 GiB is allocated by PyTorch, and 1.45 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:08 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.68 GiB. GPU 0 has a total capacity of 47.40 GiB of which 385.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.33 GiB memory in use. Of the allocated memory 33.43 GiB is allocated by PyTorch, and 1.45 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Symbols and Animals eight(animal, country, metaphor, East Asia, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:08 - Error occurred for folder: Cultural Symbols and Animals eight(animal, country, metaphor, East Asia, English), testid: 1. See logs for details.
2025-07-28 14:41:08 - Processing folder: Cultural Symbols and Animals eight(animal, country, metaphor, East Asia, English), testid: 2
2025-07-28 14:41:09 - Error in generate_response: CUDA out of memory. Tried to allocate 2.42 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.86 GiB is allocated by PyTorch, and 1.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:09 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.42 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.86 GiB is allocated by PyTorch, and 1.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Symbols and Animals eight(animal, country, metaphor, East Asia, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:09 - Error occurred for folder: Cultural Symbols and Animals eight(animal, country, metaphor, East Asia, English), testid: 2. See logs for details.
2025-07-28 14:41:09 - Results already exist and are complete for folder Cultural Symbols and Animals nine(animal, country, metaphor, East Asia, English)
2025-07-28 14:41:09 - Results already exist and are complete for folder Cultural Symbols and Animals ten(animal, country, metaphor, East Asia, English)
2025-07-28 14:41:09 - Results exist but Error found for folder Cultural Symbols and Animals eleven(animal, country, metaphor, East Asia, English)
2025-07-28 14:41:09 - Processing folder: Cultural Symbols and Animals eleven(animal, country, metaphor, East Asia, English), testid: 2
2025-07-28 14:41:09 - Error in generate_response: CUDA out of memory. Tried to allocate 2.03 GiB. GPU 0 has a total capacity of 47.40 GiB of which 21.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.69 GiB memory in use. Of the allocated memory 33.82 GiB is allocated by PyTorch, and 1.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:09 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.03 GiB. GPU 0 has a total capacity of 47.40 GiB of which 21.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.69 GiB memory in use. Of the allocated memory 33.82 GiB is allocated by PyTorch, and 1.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Symbols and Animals eleven(animal, country, metaphor, East Asia, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:09 - Error occurred for folder: Cultural Symbols and Animals eleven(animal, country, metaphor, East Asia, English), testid: 2. See logs for details.
2025-07-28 14:41:09 - Processing folder: Cultural Symbols and Animals eleven(animal, country, metaphor, East Asia, English), testid: 3
2025-07-28 14:41:10 - Error in generate_response: CUDA out of memory. Tried to allocate 1.80 GiB. GPU 0 has a total capacity of 47.40 GiB of which 21.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.69 GiB memory in use. Of the allocated memory 33.57 GiB is allocated by PyTorch, and 1.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:10 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.80 GiB. GPU 0 has a total capacity of 47.40 GiB of which 21.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.69 GiB memory in use. Of the allocated memory 33.57 GiB is allocated by PyTorch, and 1.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Symbols and Animals eleven(animal, country, metaphor, East Asia, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:10 - Error occurred for folder: Cultural Symbols and Animals eleven(animal, country, metaphor, East Asia, English), testid: 3. See logs for details.
2025-07-28 14:41:10 - Results exist but Error found for folder Cultural Symbols and Animals twelve(animal, country, metaphor, East Asia, English)
2025-07-28 14:41:10 - Processing folder: Cultural Symbols and Animals twelve(animal, country, metaphor, East Asia, English), testid: 1
2025-07-28 14:41:10 - Error in generate_response: CUDA out of memory. Tried to allocate 2.78 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.90 GiB is allocated by PyTorch, and 1.31 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:10 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.78 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.90 GiB is allocated by PyTorch, and 1.31 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Symbols and Animals twelve(animal, country, metaphor, East Asia, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:10 - Error occurred for folder: Cultural Symbols and Animals twelve(animal, country, metaphor, East Asia, English), testid: 1. See logs for details.
2025-07-28 14:41:10 - Processing folder: Cultural Symbols and Animals twelve(animal, country, metaphor, East Asia, English), testid: 2
2025-07-28 14:41:10 - Error in generate_response: CUDA out of memory. Tried to allocate 3.43 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.96 GiB is allocated by PyTorch, and 1.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:10 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.43 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.96 GiB is allocated by PyTorch, and 1.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Symbols and Animals twelve(animal, country, metaphor, East Asia, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:10 - Error occurred for folder: Cultural Symbols and Animals twelve(animal, country, metaphor, East Asia, English), testid: 2. See logs for details.
2025-07-28 14:41:10 - Processing folder: Cultural Symbols and Animals twelve(animal, country, metaphor, East Asia, English), testid: 3
2025-07-28 14:41:10 - Error in generate_response: CUDA out of memory. Tried to allocate 2.06 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.82 GiB is allocated by PyTorch, and 1.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:10 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.06 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.82 GiB is allocated by PyTorch, and 1.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Symbols and Animals twelve(animal, country, metaphor, East Asia, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:10 - Error occurred for folder: Cultural Symbols and Animals twelve(animal, country, metaphor, East Asia, English), testid: 3. See logs for details.
2025-07-28 14:41:10 - Results exist but Error found for folder Cultural Symbols and Animals thirteen(animal, country, metaphor, East Asia, English)
2025-07-28 14:41:10 - Processing folder: Cultural Symbols and Animals thirteen(animal, country, metaphor, East Asia, English), testid: 0
2025-07-28 14:41:10 - Error in generate_response: CUDA out of memory. Tried to allocate 2.31 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.85 GiB is allocated by PyTorch, and 1.35 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:10 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.31 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.85 GiB is allocated by PyTorch, and 1.35 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Symbols and Animals thirteen(animal, country, metaphor, East Asia, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:10 - Error occurred for folder: Cultural Symbols and Animals thirteen(animal, country, metaphor, East Asia, English), testid: 0. See logs for details.
2025-07-28 14:41:10 - Processing folder: Cultural Symbols and Animals thirteen(animal, country, metaphor, East Asia, English), testid: 1
2025-07-28 14:41:10 - Error in generate_response: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.84 GiB is allocated by PyTorch, and 1.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:10 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.84 GiB is allocated by PyTorch, and 1.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Symbols and Animals thirteen(animal, country, metaphor, East Asia, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:10 - Error occurred for folder: Cultural Symbols and Animals thirteen(animal, country, metaphor, East Asia, English), testid: 1. See logs for details.
2025-07-28 14:41:10 - Processing folder: Cultural Symbols and Animals thirteen(animal, country, metaphor, East Asia, English), testid: 2
2025-07-28 14:41:11 - Error in generate_response: CUDA out of memory. Tried to allocate 2.95 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.91 GiB is allocated by PyTorch, and 1.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:11 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.95 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.91 GiB is allocated by PyTorch, and 1.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Symbols and Animals thirteen(animal, country, metaphor, East Asia, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:11 - Error occurred for folder: Cultural Symbols and Animals thirteen(animal, country, metaphor, East Asia, English), testid: 2. See logs for details.
2025-07-28 14:41:11 - Processing folder: Cultural Symbols and Animals thirteen(animal, country, metaphor, East Asia, English), testid: 3
2025-07-28 14:41:11 - Error in generate_response: CUDA out of memory. Tried to allocate 2.28 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.84 GiB is allocated by PyTorch, and 1.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:11 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.28 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.84 GiB is allocated by PyTorch, and 1.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Symbols and Animals thirteen(animal, country, metaphor, East Asia, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:11 - Error occurred for folder: Cultural Symbols and Animals thirteen(animal, country, metaphor, East Asia, English), testid: 3. See logs for details.
2025-07-28 14:41:11 - Results exist but Error found for folder Cultural Symbols and Animals forteen(animal, country, metaphor, East Asia, English)
2025-07-28 14:41:11 - Processing folder: Cultural Symbols and Animals forteen(animal, country, metaphor, East Asia, English), testid: 0
2025-07-28 14:41:11 - Error in generate_response: CUDA out of memory. Tried to allocate 2.25 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.84 GiB is allocated by PyTorch, and 1.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:11 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.25 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.84 GiB is allocated by PyTorch, and 1.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Symbols and Animals forteen(animal, country, metaphor, East Asia, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:11 - Error occurred for folder: Cultural Symbols and Animals forteen(animal, country, metaphor, East Asia, English), testid: 0. See logs for details.
2025-07-28 14:41:11 - Processing folder: Cultural Symbols and Animals forteen(animal, country, metaphor, East Asia, English), testid: 1
2025-07-28 14:41:11 - Error in generate_response: CUDA out of memory. Tried to allocate 2.81 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.90 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:11 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.81 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.90 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Symbols and Animals forteen(animal, country, metaphor, East Asia, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:11 - Error occurred for folder: Cultural Symbols and Animals forteen(animal, country, metaphor, East Asia, English), testid: 1. See logs for details.
2025-07-28 14:41:11 - Processing folder: Cultural Symbols and Animals forteen(animal, country, metaphor, East Asia, English), testid: 2
2025-07-28 14:41:11 - Error in generate_response: CUDA out of memory. Tried to allocate 2.20 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.84 GiB is allocated by PyTorch, and 1.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:11 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.20 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.84 GiB is allocated by PyTorch, and 1.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Symbols and Animals forteen(animal, country, metaphor, East Asia, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:11 - Error occurred for folder: Cultural Symbols and Animals forteen(animal, country, metaphor, East Asia, English), testid: 2. See logs for details.
2025-07-28 14:41:11 - Processing folder: Cultural Symbols and Animals forteen(animal, country, metaphor, East Asia, English), testid: 3
2025-07-28 14:41:11 - Error in generate_response: CUDA out of memory. Tried to allocate 2.19 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.84 GiB is allocated by PyTorch, and 1.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:11 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.19 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.84 GiB is allocated by PyTorch, and 1.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Symbols and Animals forteen(animal, country, metaphor, East Asia, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:11 - Error occurred for folder: Cultural Symbols and Animals forteen(animal, country, metaphor, East Asia, English), testid: 3. See logs for details.
2025-07-28 14:41:11 - Results exist but Error found for folder National Anthems and Their Associated Transit Systems(country, city, relation, East Asia, English)
2025-07-28 14:41:11 - Processing folder: National Anthems and Their Associated Transit Systems(country, city, relation, East Asia, English), testid: 0
2025-07-28 14:41:11 - Error in generate_response: CUDA out of memory. Tried to allocate 2.49 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.87 GiB is allocated by PyTorch, and 1.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:11 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.49 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.87 GiB is allocated by PyTorch, and 1.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: National Anthems and Their Associated Transit Systems(country, city, relation, East Asia, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:11 - Error occurred for folder: National Anthems and Their Associated Transit Systems(country, city, relation, East Asia, English), testid: 0. See logs for details.
2025-07-28 14:41:11 - Processing folder: National Anthems and Their Associated Transit Systems(country, city, relation, East Asia, English), testid: 1
2025-07-28 14:41:12 - Error in generate_response: CUDA out of memory. Tried to allocate 2.34 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.85 GiB is allocated by PyTorch, and 1.35 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:12 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.34 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.85 GiB is allocated by PyTorch, and 1.35 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: National Anthems and Their Associated Transit Systems(country, city, relation, East Asia, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:12 - Error occurred for folder: National Anthems and Their Associated Transit Systems(country, city, relation, East Asia, English), testid: 1. See logs for details.
2025-07-28 14:41:12 - Processing folder: National Anthems and Their Associated Transit Systems(country, city, relation, East Asia, English), testid: 2
2025-07-28 14:41:12 - Error in generate_response: CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.87 GiB is allocated by PyTorch, and 1.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:12 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.87 GiB is allocated by PyTorch, and 1.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: National Anthems and Their Associated Transit Systems(country, city, relation, East Asia, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:12 - Error occurred for folder: National Anthems and Their Associated Transit Systems(country, city, relation, East Asia, English), testid: 2. See logs for details.
2025-07-28 14:41:12 - Processing folder: National Anthems and Their Associated Transit Systems(country, city, relation, East Asia, English), testid: 3
2025-07-28 14:41:12 - Error in generate_response: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.92 GiB is allocated by PyTorch, and 1.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:12 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.92 GiB is allocated by PyTorch, and 1.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: National Anthems and Their Associated Transit Systems(country, city, relation, East Asia, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:12 - Error occurred for folder: National Anthems and Their Associated Transit Systems(country, city, relation, East Asia, English), testid: 3. See logs for details.
2025-07-28 14:41:12 - Results already exist and are complete for folder Symbolic Connections in Chinese Culture(animal, city, relation, East Asia, English)
2025-07-28 14:41:12 - Results exist but Error found for folder Symbolic Connections in Chinese Culture two(animal, city, relation, East Asia, English)
2025-07-28 14:41:12 - Processing folder: Symbolic Connections in Chinese Culture two(animal, city, relation, East Asia, English), testid: 1
2025-07-28 14:41:12 - Error in generate_response: CUDA out of memory. Tried to allocate 1.83 GiB. GPU 0 has a total capacity of 47.40 GiB of which 225.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.49 GiB memory in use. Of the allocated memory 33.61 GiB is allocated by PyTorch, and 1.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:12 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.83 GiB. GPU 0 has a total capacity of 47.40 GiB of which 225.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.49 GiB memory in use. Of the allocated memory 33.61 GiB is allocated by PyTorch, and 1.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Symbolic Connections in Chinese Culture two(animal, city, relation, East Asia, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:12 - Error occurred for folder: Symbolic Connections in Chinese Culture two(animal, city, relation, East Asia, English), testid: 1. See logs for details.
2025-07-28 14:41:12 - Processing folder: Symbolic Connections in Chinese Culture two(animal, city, relation, East Asia, English), testid: 3
2025-07-28 14:41:12 - Error in generate_response: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacity of 47.40 GiB of which 225.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.49 GiB memory in use. Of the allocated memory 33.56 GiB is allocated by PyTorch, and 1.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:12 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacity of 47.40 GiB of which 225.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.49 GiB memory in use. Of the allocated memory 33.56 GiB is allocated by PyTorch, and 1.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Symbolic Connections in Chinese Culture two(animal, city, relation, East Asia, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:12 - Error occurred for folder: Symbolic Connections in Chinese Culture two(animal, city, relation, East Asia, English), testid: 3. See logs for details.
2025-07-28 14:41:12 - Results exist but Error found for folder Symbolic Connections in Chinese Culture three(animal, city, relation, East Asia, English)
2025-07-28 14:41:12 - Processing folder: Symbolic Connections in Chinese Culture three(animal, city, relation, East Asia, English), testid: 0
2025-07-28 14:41:12 - Error in generate_response: CUDA out of memory. Tried to allocate 1.73 GiB. GPU 0 has a total capacity of 47.40 GiB of which 225.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.49 GiB memory in use. Of the allocated memory 33.49 GiB is allocated by PyTorch, and 1.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:12 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.73 GiB. GPU 0 has a total capacity of 47.40 GiB of which 225.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.49 GiB memory in use. Of the allocated memory 33.49 GiB is allocated by PyTorch, and 1.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Symbolic Connections in Chinese Culture three(animal, city, relation, East Asia, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:12 - Error occurred for folder: Symbolic Connections in Chinese Culture three(animal, city, relation, East Asia, English), testid: 0. See logs for details.
2025-07-28 14:41:12 - Processing folder: Symbolic Connections in Chinese Culture three(animal, city, relation, East Asia, English), testid: 1
2025-07-28 14:41:13 - Error in generate_response: CUDA out of memory. Tried to allocate 1.71 GiB. GPU 0 has a total capacity of 47.40 GiB of which 225.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.49 GiB memory in use. Of the allocated memory 33.47 GiB is allocated by PyTorch, and 1.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:13 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.71 GiB. GPU 0 has a total capacity of 47.40 GiB of which 225.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.49 GiB memory in use. Of the allocated memory 33.47 GiB is allocated by PyTorch, and 1.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Symbolic Connections in Chinese Culture three(animal, city, relation, East Asia, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:13 - Error occurred for folder: Symbolic Connections in Chinese Culture three(animal, city, relation, East Asia, English), testid: 1. See logs for details.
2025-07-28 14:41:13 - Processing folder: Symbolic Connections in Chinese Culture three(animal, city, relation, East Asia, English), testid: 2
2025-07-28 14:41:13 - Error in generate_response: CUDA out of memory. Tried to allocate 1.71 GiB. GPU 0 has a total capacity of 47.40 GiB of which 225.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.49 GiB memory in use. Of the allocated memory 33.47 GiB is allocated by PyTorch, and 1.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:13 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.71 GiB. GPU 0 has a total capacity of 47.40 GiB of which 225.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.49 GiB memory in use. Of the allocated memory 33.47 GiB is allocated by PyTorch, and 1.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Symbolic Connections in Chinese Culture three(animal, city, relation, East Asia, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:13 - Error occurred for folder: Symbolic Connections in Chinese Culture three(animal, city, relation, East Asia, English), testid: 2. See logs for details.
2025-07-28 14:41:13 - Processing folder: Symbolic Connections in Chinese Culture three(animal, city, relation, East Asia, English), testid: 3
2025-07-28 14:41:14 - Error in generate_response: CUDA out of memory. Tried to allocate 2.86 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.90 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:14 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.86 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.90 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Symbolic Connections in Chinese Culture three(animal, city, relation, East Asia, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:14 - Error occurred for folder: Symbolic Connections in Chinese Culture three(animal, city, relation, East Asia, English), testid: 3. See logs for details.
2025-07-28 14:41:14 - Results exist but Error found for folder Symbolic Connections in Chinese Culture four(animal, city, relation, East Asia, English)
2025-07-28 14:41:14 - Processing folder: Symbolic Connections in Chinese Culture four(animal, city, relation, East Asia, English), testid: 1
2025-07-28 14:41:15 - Error in generate_response: CUDA out of memory. Tried to allocate 1.75 GiB. GPU 0 has a total capacity of 47.40 GiB of which 309.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.41 GiB memory in use. Of the allocated memory 33.51 GiB is allocated by PyTorch, and 1.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:15 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.75 GiB. GPU 0 has a total capacity of 47.40 GiB of which 309.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.41 GiB memory in use. Of the allocated memory 33.51 GiB is allocated by PyTorch, and 1.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Symbolic Connections in Chinese Culture four(animal, city, relation, East Asia, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:15 - Error occurred for folder: Symbolic Connections in Chinese Culture four(animal, city, relation, East Asia, English), testid: 1. See logs for details.
2025-07-28 14:41:15 - Processing folder: Symbolic Connections in Chinese Culture four(animal, city, relation, East Asia, English), testid: 3
2025-07-28 14:41:16 - Error in generate_response: CUDA out of memory. Tried to allocate 1.88 GiB. GPU 0 has a total capacity of 47.40 GiB of which 173.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.54 GiB memory in use. Of the allocated memory 33.67 GiB is allocated by PyTorch, and 1.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:16 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.88 GiB. GPU 0 has a total capacity of 47.40 GiB of which 173.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.54 GiB memory in use. Of the allocated memory 33.67 GiB is allocated by PyTorch, and 1.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Symbolic Connections in Chinese Culture four(animal, city, relation, East Asia, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:16 - Error occurred for folder: Symbolic Connections in Chinese Culture four(animal, city, relation, East Asia, English), testid: 3. See logs for details.
2025-07-28 14:41:16 - Results already exist and are complete for folder Symbolic Connections in Chinese Culture five(animal, city, relation, East Asia, English)
2025-07-28 14:41:16 - Results exist but Error found for folder Symbolic Connections in Chinese Culture six(animal, city, relation, East Asia, English)
2025-07-28 14:41:16 - Processing folder: Symbolic Connections in Chinese Culture six(animal, city, relation, East Asia, English), testid: 0
2025-07-28 14:41:17 - Error in generate_response: CUDA out of memory. Tried to allocate 2.86 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.90 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:17 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.86 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.90 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Symbolic Connections in Chinese Culture six(animal, city, relation, East Asia, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:17 - Error occurred for folder: Symbolic Connections in Chinese Culture six(animal, city, relation, East Asia, English), testid: 0. See logs for details.
2025-07-28 14:41:17 - Processing folder: Symbolic Connections in Chinese Culture six(animal, city, relation, East Asia, English), testid: 1
2025-07-28 14:41:18 - Error in generate_response: CUDA out of memory. Tried to allocate 2.86 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.90 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:18 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.86 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.90 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Symbolic Connections in Chinese Culture six(animal, city, relation, East Asia, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:18 - Error occurred for folder: Symbolic Connections in Chinese Culture six(animal, city, relation, East Asia, English), testid: 1. See logs for details.
2025-07-28 14:41:18 - Processing folder: Symbolic Connections in Chinese Culture six(animal, city, relation, East Asia, English), testid: 2
2025-07-28 14:41:19 - Error in generate_response: CUDA out of memory. Tried to allocate 2.86 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.90 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:19 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.86 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.90 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Symbolic Connections in Chinese Culture six(animal, city, relation, East Asia, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:19 - Error occurred for folder: Symbolic Connections in Chinese Culture six(animal, city, relation, East Asia, English), testid: 2. See logs for details.
2025-07-28 14:41:19 - Processing folder: Symbolic Connections in Chinese Culture six(animal, city, relation, East Asia, English), testid: 3
2025-07-28 14:41:21 - Error in generate_response: CUDA out of memory. Tried to allocate 2.89 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.91 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:21 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.89 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.91 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Symbolic Connections in Chinese Culture six(animal, city, relation, East Asia, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:21 - Error occurred for folder: Symbolic Connections in Chinese Culture six(animal, city, relation, East Asia, English), testid: 3. See logs for details.
2025-07-28 14:41:21 - Results exist but Error found for folder Symbolic Connections in Chinese Culture seven(animal, city, relation, East Asia, English)
2025-07-28 14:41:21 - Processing folder: Symbolic Connections in Chinese Culture seven(animal, city, relation, East Asia, English), testid: 0
2025-07-28 14:41:22 - Error in generate_response: CUDA out of memory. Tried to allocate 2.82 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.90 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:22 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.82 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.90 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Symbolic Connections in Chinese Culture seven(animal, city, relation, East Asia, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:22 - Error occurred for folder: Symbolic Connections in Chinese Culture seven(animal, city, relation, East Asia, English), testid: 0. See logs for details.
2025-07-28 14:41:22 - Processing folder: Symbolic Connections in Chinese Culture seven(animal, city, relation, East Asia, English), testid: 1
2025-07-28 14:41:22 - Error in generate_response: CUDA out of memory. Tried to allocate 2.86 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.90 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:22 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.86 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.90 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Symbolic Connections in Chinese Culture seven(animal, city, relation, East Asia, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:22 - Error occurred for folder: Symbolic Connections in Chinese Culture seven(animal, city, relation, East Asia, English), testid: 1. See logs for details.
2025-07-28 14:41:22 - Processing folder: Symbolic Connections in Chinese Culture seven(animal, city, relation, East Asia, English), testid: 2
2025-07-28 14:41:24 - Error in generate_response: CUDA out of memory. Tried to allocate 2.86 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.90 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:24 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.86 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.90 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Symbolic Connections in Chinese Culture seven(animal, city, relation, East Asia, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:24 - Error occurred for folder: Symbolic Connections in Chinese Culture seven(animal, city, relation, East Asia, English), testid: 2. See logs for details.
2025-07-28 14:41:24 - Processing folder: Symbolic Connections in Chinese Culture seven(animal, city, relation, East Asia, English), testid: 3
2025-07-28 14:41:25 - Error in generate_response: CUDA out of memory. Tried to allocate 2.82 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.90 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:25 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.82 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.90 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Symbolic Connections in Chinese Culture seven(animal, city, relation, East Asia, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:25 - Error occurred for folder: Symbolic Connections in Chinese Culture seven(animal, city, relation, East Asia, English), testid: 3. See logs for details.
2025-07-28 14:41:25 - Results exist but Error found for folder Symbolic Connections in Chinese Culture eight(animal, city, relation, East Asia, English)
2025-07-28 14:41:25 - Processing folder: Symbolic Connections in Chinese Culture eight(animal, city, relation, East Asia, English), testid: 0
2025-07-28 14:41:25 - Error in generate_response: CUDA out of memory. Tried to allocate 2.22 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.84 GiB is allocated by PyTorch, and 1.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:25 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.22 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.84 GiB is allocated by PyTorch, and 1.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Symbolic Connections in Chinese Culture eight(animal, city, relation, East Asia, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:25 - Error occurred for folder: Symbolic Connections in Chinese Culture eight(animal, city, relation, East Asia, English), testid: 0. See logs for details.
2025-07-28 14:41:25 - Processing folder: Symbolic Connections in Chinese Culture eight(animal, city, relation, East Asia, English), testid: 1
2025-07-28 14:41:26 - Error in generate_response: CUDA out of memory. Tried to allocate 2.18 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.83 GiB is allocated by PyTorch, and 1.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:26 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.18 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.83 GiB is allocated by PyTorch, and 1.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Symbolic Connections in Chinese Culture eight(animal, city, relation, East Asia, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:26 - Error occurred for folder: Symbolic Connections in Chinese Culture eight(animal, city, relation, East Asia, English), testid: 1. See logs for details.
2025-07-28 14:41:26 - Processing folder: Symbolic Connections in Chinese Culture eight(animal, city, relation, East Asia, English), testid: 2
2025-07-28 14:41:27 - Error in generate_response: CUDA out of memory. Tried to allocate 2.16 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.83 GiB is allocated by PyTorch, and 1.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:27 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.16 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.83 GiB is allocated by PyTorch, and 1.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Symbolic Connections in Chinese Culture eight(animal, city, relation, East Asia, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:27 - Error occurred for folder: Symbolic Connections in Chinese Culture eight(animal, city, relation, East Asia, English), testid: 2. See logs for details.
2025-07-28 14:41:27 - Processing folder: Symbolic Connections in Chinese Culture eight(animal, city, relation, East Asia, English), testid: 3
2025-07-28 14:41:27 - Error in generate_response: CUDA out of memory. Tried to allocate 2.88 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.90 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:27 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.88 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.90 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Symbolic Connections in Chinese Culture eight(animal, city, relation, East Asia, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:27 - Error occurred for folder: Symbolic Connections in Chinese Culture eight(animal, city, relation, East Asia, English), testid: 3. See logs for details.
2025-07-28 14:41:27 - Results exist but Error found for folder Cultural Icons and National Significance four(people, country, metaphor, East Asia, English)
2025-07-28 14:41:27 - Processing folder: Cultural Icons and National Significance four(people, country, metaphor, East Asia, English), testid: 0
2025-07-28 14:41:27 - Error in generate_response: CUDA out of memory. Tried to allocate 2.89 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.91 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:27 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.89 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.91 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Icons and National Significance four(people, country, metaphor, East Asia, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:27 - Error occurred for folder: Cultural Icons and National Significance four(people, country, metaphor, East Asia, English), testid: 0. See logs for details.
2025-07-28 14:41:28 - Processing folder: Cultural Icons and National Significance four(people, country, metaphor, East Asia, English), testid: 1
2025-07-28 14:41:28 - Error in generate_response: CUDA out of memory. Tried to allocate 2.91 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.91 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:28 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.91 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.91 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Icons and National Significance four(people, country, metaphor, East Asia, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:28 - Error occurred for folder: Cultural Icons and National Significance four(people, country, metaphor, East Asia, English), testid: 1. See logs for details.
2025-07-28 14:41:28 - Processing folder: Cultural Icons and National Significance four(people, country, metaphor, East Asia, English), testid: 2
2025-07-28 14:41:28 - Error in generate_response: CUDA out of memory. Tried to allocate 2.87 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.90 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:28 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.87 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.90 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Icons and National Significance four(people, country, metaphor, East Asia, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:28 - Error occurred for folder: Cultural Icons and National Significance four(people, country, metaphor, East Asia, English), testid: 2. See logs for details.
2025-07-28 14:41:28 - Processing folder: Cultural Icons and National Significance four(people, country, metaphor, East Asia, English), testid: 3
2025-07-28 14:41:28 - Error in generate_response: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.91 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:28 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.91 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Icons and National Significance four(people, country, metaphor, East Asia, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:28 - Error occurred for folder: Cultural Icons and National Significance four(people, country, metaphor, East Asia, English), testid: 3. See logs for details.
2025-07-28 14:41:28 - Results exist but Error found for folder Cultural Icons and National Significance five(people, country, metaphor, East Asia, English)
2025-07-28 14:41:28 - Processing folder: Cultural Icons and National Significance five(people, country, metaphor, East Asia, English), testid: 0
2025-07-28 14:41:28 - Error in generate_response: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.84 GiB is allocated by PyTorch, and 1.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:28 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.84 GiB is allocated by PyTorch, and 1.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Icons and National Significance five(people, country, metaphor, East Asia, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:28 - Error occurred for folder: Cultural Icons and National Significance five(people, country, metaphor, East Asia, English), testid: 0. See logs for details.
2025-07-28 14:41:28 - Processing folder: Cultural Icons and National Significance five(people, country, metaphor, East Asia, English), testid: 1
2025-07-28 14:41:28 - Error in generate_response: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.91 GiB is allocated by PyTorch, and 1.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:28 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.91 GiB is allocated by PyTorch, and 1.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Icons and National Significance five(people, country, metaphor, East Asia, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:28 - Error occurred for folder: Cultural Icons and National Significance five(people, country, metaphor, East Asia, English), testid: 1. See logs for details.
2025-07-28 14:41:28 - Processing folder: Cultural Icons and National Significance five(people, country, metaphor, East Asia, English), testid: 2
2025-07-28 14:41:28 - Error in generate_response: CUDA out of memory. Tried to allocate 2.29 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.85 GiB is allocated by PyTorch, and 1.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:28 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.29 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.85 GiB is allocated by PyTorch, and 1.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Icons and National Significance five(people, country, metaphor, East Asia, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:28 - Error occurred for folder: Cultural Icons and National Significance five(people, country, metaphor, East Asia, English), testid: 2. See logs for details.
2025-07-28 14:41:28 - Processing folder: Cultural Icons and National Significance five(people, country, metaphor, East Asia, English), testid: 3
2025-07-28 14:41:29 - Error in generate_response: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.84 GiB is allocated by PyTorch, and 1.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:29 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.84 GiB is allocated by PyTorch, and 1.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Icons and National Significance five(people, country, metaphor, East Asia, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:29 - Error occurred for folder: Cultural Icons and National Significance five(people, country, metaphor, East Asia, English), testid: 3. See logs for details.
2025-07-28 14:41:29 - Results exist but Error found for folder Cultural Icons and National Significance six(people, country, metaphor, East Asia, English)
2025-07-28 14:41:29 - Processing folder: Cultural Icons and National Significance six(people, country, metaphor, East Asia, English), testid: 0
2025-07-28 14:41:29 - Error in generate_response: CUDA out of memory. Tried to allocate 2.33 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.85 GiB is allocated by PyTorch, and 1.35 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:29 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.33 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.85 GiB is allocated by PyTorch, and 1.35 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Icons and National Significance six(people, country, metaphor, East Asia, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:29 - Error occurred for folder: Cultural Icons and National Significance six(people, country, metaphor, East Asia, English), testid: 0. See logs for details.
2025-07-28 14:41:29 - Processing folder: Cultural Icons and National Significance six(people, country, metaphor, East Asia, English), testid: 1
2025-07-28 14:41:29 - Error in generate_response: CUDA out of memory. Tried to allocate 2.34 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.85 GiB is allocated by PyTorch, and 1.35 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:29 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.34 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.85 GiB is allocated by PyTorch, and 1.35 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Icons and National Significance six(people, country, metaphor, East Asia, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:29 - Error occurred for folder: Cultural Icons and National Significance six(people, country, metaphor, East Asia, English), testid: 1. See logs for details.
2025-07-28 14:41:29 - Processing folder: Cultural Icons and National Significance six(people, country, metaphor, East Asia, English), testid: 2
2025-07-28 14:41:29 - Error in generate_response: CUDA out of memory. Tried to allocate 3.58 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.97 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:29 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.58 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.97 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Icons and National Significance six(people, country, metaphor, East Asia, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:29 - Error occurred for folder: Cultural Icons and National Significance six(people, country, metaphor, East Asia, English), testid: 2. See logs for details.
2025-07-28 14:41:29 - Processing folder: Cultural Icons and National Significance six(people, country, metaphor, East Asia, English), testid: 3
2025-07-28 14:41:29 - Error in generate_response: CUDA out of memory. Tried to allocate 1.77 GiB. GPU 0 has a total capacity of 47.40 GiB of which 293.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.42 GiB memory in use. Of the allocated memory 33.53 GiB is allocated by PyTorch, and 1.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:29 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.77 GiB. GPU 0 has a total capacity of 47.40 GiB of which 293.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.42 GiB memory in use. Of the allocated memory 33.53 GiB is allocated by PyTorch, and 1.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Icons and National Significance six(people, country, metaphor, East Asia, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:29 - Error occurred for folder: Cultural Icons and National Significance six(people, country, metaphor, East Asia, English), testid: 3. See logs for details.
2025-07-28 14:41:29 - Results exist but Error found for folder Cultural Icons and National Significance seven(people, country, metaphor, East Asia, English)
2025-07-28 14:41:29 - Processing folder: Cultural Icons and National Significance seven(people, country, metaphor, East Asia, English), testid: 2
2025-07-28 14:41:29 - Error in generate_response: CUDA out of memory. Tried to allocate 1.47 GiB. GPU 0 has a total capacity of 47.40 GiB of which 293.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.42 GiB memory in use. Of the allocated memory 33.21 GiB is allocated by PyTorch, and 1.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:29 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.47 GiB. GPU 0 has a total capacity of 47.40 GiB of which 293.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.42 GiB memory in use. Of the allocated memory 33.21 GiB is allocated by PyTorch, and 1.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Icons and National Significance seven(people, country, metaphor, East Asia, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:29 - Error occurred for folder: Cultural Icons and National Significance seven(people, country, metaphor, East Asia, English), testid: 2. See logs for details.
2025-07-28 14:41:29 - Results exist but Error found for folder Cultural Icons and National Significance eight(people, country, metaphor, East Asia, English)
2025-07-28 14:41:29 - Processing folder: Cultural Icons and National Significance eight(people, country, metaphor, East Asia, English), testid: 0
2025-07-28 14:41:30 - Error in generate_response: CUDA out of memory. Tried to allocate 3.77 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.99 GiB is allocated by PyTorch, and 1.22 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:30 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.77 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.99 GiB is allocated by PyTorch, and 1.22 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Icons and National Significance eight(people, country, metaphor, East Asia, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:30 - Error occurred for folder: Cultural Icons and National Significance eight(people, country, metaphor, East Asia, English), testid: 0. See logs for details.
2025-07-28 14:41:30 - Processing folder: Cultural Icons and National Significance eight(people, country, metaphor, East Asia, English), testid: 1
2025-07-28 14:41:30 - Error in generate_response: CUDA out of memory. Tried to allocate 2.85 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.90 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:30 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.85 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.90 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Icons and National Significance eight(people, country, metaphor, East Asia, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:30 - Error occurred for folder: Cultural Icons and National Significance eight(people, country, metaphor, East Asia, English), testid: 1. See logs for details.
2025-07-28 14:41:30 - Processing folder: Cultural Icons and National Significance eight(people, country, metaphor, East Asia, English), testid: 2
2025-07-28 14:41:30 - Error in generate_response: CUDA out of memory. Tried to allocate 3.77 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.99 GiB is allocated by PyTorch, and 1.22 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:30 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.77 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.99 GiB is allocated by PyTorch, and 1.22 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Icons and National Significance eight(people, country, metaphor, East Asia, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:30 - Error occurred for folder: Cultural Icons and National Significance eight(people, country, metaphor, East Asia, English), testid: 2. See logs for details.
2025-07-28 14:41:30 - Processing folder: Cultural Icons and National Significance eight(people, country, metaphor, East Asia, English), testid: 3
2025-07-28 14:41:30 - Error in generate_response: CUDA out of memory. Tried to allocate 3.82 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.99 GiB is allocated by PyTorch, and 1.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:30 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.82 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.99 GiB is allocated by PyTorch, and 1.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Icons and National Significance eight(people, country, metaphor, East Asia, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:30 - Error occurred for folder: Cultural Icons and National Significance eight(people, country, metaphor, East Asia, English), testid: 3. See logs for details.
2025-07-28 14:41:30 - Results already exist and are complete for folder National Anthems and Their Associated Transit Systems two(country, city, relation, East Asia, English)
2025-07-28 14:41:30 - Results exist but Error found for folder National Anthems and Their Associated Transit Systems three(country, city, relation, Non-English European, English)
2025-07-28 14:41:30 - Error opening image ./img/National Anthems and Their Associated Transit Systems three(country, city, relation, Non-English European, English)/Lyrics of 'God Save the Queen'.jpg: cannot identify image file "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/img/National Anthems and Their Associated Transit Systems three(country, city, relation, Non-English European, English)/Lyrics of 'God Save the Queen'.jpg"
2025-07-28 14:41:30 - Error opening image ./img/National Anthems and Their Associated Transit Systems three(country, city, relation, Non-English European, English)/A map of the London Underground.jpg: cannot identify image file '/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/img/National Anthems and Their Associated Transit Systems three(country, city, relation, Non-English European, English)/A map of the London Underground.jpg'
2025-07-28 14:41:30 - Four valid images are required for processing.
2025-07-28 14:41:30 - Results exist but Error found for folder National Anthems and Their Associated Transit Systems four(country, city, relation, other, English)
2025-07-28 14:41:30 - Processing folder: National Anthems and Their Associated Transit Systems four(country, city, relation, other, English), testid: 0
2025-07-28 14:41:30 - Error in generate_response: CUDA out of memory. Tried to allocate 2.86 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.90 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:30 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.86 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.90 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: National Anthems and Their Associated Transit Systems four(country, city, relation, other, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:30 - Error occurred for folder: National Anthems and Their Associated Transit Systems four(country, city, relation, other, English), testid: 0. See logs for details.
2025-07-28 14:41:30 - Processing folder: National Anthems and Their Associated Transit Systems four(country, city, relation, other, English), testid: 1
2025-07-28 14:41:30 - Error in generate_response: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.91 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:30 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.91 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: National Anthems and Their Associated Transit Systems four(country, city, relation, other, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:30 - Error occurred for folder: National Anthems and Their Associated Transit Systems four(country, city, relation, other, English), testid: 1. See logs for details.
2025-07-28 14:41:30 - Processing folder: National Anthems and Their Associated Transit Systems four(country, city, relation, other, English), testid: 2
2025-07-28 14:41:31 - Error in generate_response: CUDA out of memory. Tried to allocate 2.87 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.90 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:31 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.87 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.90 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: National Anthems and Their Associated Transit Systems four(country, city, relation, other, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:31 - Error occurred for folder: National Anthems and Their Associated Transit Systems four(country, city, relation, other, English), testid: 2. See logs for details.
2025-07-28 14:41:31 - Processing folder: National Anthems and Their Associated Transit Systems four(country, city, relation, other, English), testid: 3
2025-07-28 14:41:31 - Error in generate_response: CUDA out of memory. Tried to allocate 2.83 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.90 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:31 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.83 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.90 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: National Anthems and Their Associated Transit Systems four(country, city, relation, other, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:31 - Error occurred for folder: National Anthems and Their Associated Transit Systems four(country, city, relation, other, English), testid: 3. See logs for details.
2025-07-28 14:41:31 - Results exist but Error found for folder National Anthems and Their Associated Transit Systems five(country, city, relation, South Asia and South-East Asia, English)
2025-07-28 14:41:31 - Error opening image ./img/National Anthems and Their Associated Transit Systems five(country, city, relation, South Asia and South-East Asia, English)/Lyrics of 'Jana Gana Mana'.jpg: cannot identify image file "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/img/National Anthems and Their Associated Transit Systems five(country, city, relation, South Asia and South-East Asia, English)/Lyrics of 'Jana Gana Mana'.jpg"
2025-07-28 14:41:31 - Error opening image ./img/National Anthems and Their Associated Transit Systems five(country, city, relation, South Asia and South-East Asia, English)/A map of the Delhi Metro.jpg: cannot identify image file '/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/img/National Anthems and Their Associated Transit Systems five(country, city, relation, South Asia and South-East Asia, English)/A map of the Delhi Metro.jpg'
2025-07-28 14:41:31 - Error opening image ./img/National Anthems and Their Associated Transit Systems five(country, city, relation, South Asia and South-East Asia, English)/Lyrics of 'The Star-Spangled Banner'.jpg: cannot identify image file "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/img/National Anthems and Their Associated Transit Systems five(country, city, relation, South Asia and South-East Asia, English)/Lyrics of 'The Star-Spangled Banner'.jpg"
2025-07-28 14:41:31 - Error opening image ./img/National Anthems and Their Associated Transit Systems five(country, city, relation, South Asia and South-East Asia, English)/A map of the New York City subway.jpg: cannot identify image file '/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/img/National Anthems and Their Associated Transit Systems five(country, city, relation, South Asia and South-East Asia, English)/A map of the New York City subway.jpg'
2025-07-28 14:41:31 - Four valid images are required for processing.
2025-07-28 14:41:31 - Results exist but Error found for folder National Anthems and Their Associated Transit Systems six(country, city, relation, East Asia, English)
2025-07-28 14:41:31 - Processing folder: National Anthems and Their Associated Transit Systems six(country, city, relation, East Asia, English), testid: 0
2025-07-28 14:41:31 - Error in generate_response: CUDA out of memory. Tried to allocate 3.51 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.96 GiB is allocated by PyTorch, and 1.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:31 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.51 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.96 GiB is allocated by PyTorch, and 1.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: National Anthems and Their Associated Transit Systems six(country, city, relation, East Asia, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:31 - Error occurred for folder: National Anthems and Their Associated Transit Systems six(country, city, relation, East Asia, English), testid: 0. See logs for details.
2025-07-28 14:41:31 - Processing folder: National Anthems and Their Associated Transit Systems six(country, city, relation, East Asia, English), testid: 1
2025-07-28 14:41:31 - Error in generate_response: CUDA out of memory. Tried to allocate 2.88 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.91 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:31 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.88 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.91 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: National Anthems and Their Associated Transit Systems six(country, city, relation, East Asia, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:31 - Error occurred for folder: National Anthems and Their Associated Transit Systems six(country, city, relation, East Asia, English), testid: 1. See logs for details.
2025-07-28 14:41:31 - Processing folder: National Anthems and Their Associated Transit Systems six(country, city, relation, East Asia, English), testid: 2
2025-07-28 14:41:31 - Error in generate_response: CUDA out of memory. Tried to allocate 4.16 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 32.02 GiB is allocated by PyTorch, and 1.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:31 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.16 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 32.02 GiB is allocated by PyTorch, and 1.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: National Anthems and Their Associated Transit Systems six(country, city, relation, East Asia, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:31 - Error occurred for folder: National Anthems and Their Associated Transit Systems six(country, city, relation, East Asia, English), testid: 2. See logs for details.
2025-07-28 14:41:31 - Processing folder: National Anthems and Their Associated Transit Systems six(country, city, relation, East Asia, English), testid: 3
2025-07-28 14:41:32 - Error in generate_response: CUDA out of memory. Tried to allocate 1.45 GiB. GPU 0 has a total capacity of 47.40 GiB of which 613.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.11 GiB memory in use. Of the allocated memory 33.19 GiB is allocated by PyTorch, and 1.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:32 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.45 GiB. GPU 0 has a total capacity of 47.40 GiB of which 613.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.11 GiB memory in use. Of the allocated memory 33.19 GiB is allocated by PyTorch, and 1.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: National Anthems and Their Associated Transit Systems six(country, city, relation, East Asia, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:32 - Error occurred for folder: National Anthems and Their Associated Transit Systems six(country, city, relation, East Asia, English), testid: 3. See logs for details.
2025-07-28 14:41:32 - Results exist but Error found for folder Symbolic Representation two(country, city, relation, USAEnglish, English)
2025-07-28 14:41:32 - Processing folder: Symbolic Representation two(country, city, relation, USAEnglish, English), testid: 0
2025-07-28 14:41:33 - Error in generate_response: CUDA out of memory. Tried to allocate 1.64 GiB. GPU 0 has a total capacity of 47.40 GiB of which 421.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.30 GiB memory in use. Of the allocated memory 33.39 GiB is allocated by PyTorch, and 1.45 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:33 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.64 GiB. GPU 0 has a total capacity of 47.40 GiB of which 421.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.30 GiB memory in use. Of the allocated memory 33.39 GiB is allocated by PyTorch, and 1.45 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Symbolic Representation two(country, city, relation, USAEnglish, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:33 - Error occurred for folder: Symbolic Representation two(country, city, relation, USAEnglish, English), testid: 0. See logs for details.
2025-07-28 14:41:33 - Processing folder: Symbolic Representation two(country, city, relation, USAEnglish, English), testid: 1
2025-07-28 14:41:33 - Error in generate_response: CUDA out of memory. Tried to allocate 3.01 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.92 GiB is allocated by PyTorch, and 1.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:33 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.01 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.92 GiB is allocated by PyTorch, and 1.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Symbolic Representation two(country, city, relation, USAEnglish, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:33 - Error occurred for folder: Symbolic Representation two(country, city, relation, USAEnglish, English), testid: 1. See logs for details.
2025-07-28 14:41:33 - Processing folder: Symbolic Representation two(country, city, relation, USAEnglish, English), testid: 2
2025-07-28 14:41:34 - Error in generate_response: CUDA out of memory. Tried to allocate 3.19 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.93 GiB is allocated by PyTorch, and 1.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:34 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.19 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.93 GiB is allocated by PyTorch, and 1.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Symbolic Representation two(country, city, relation, USAEnglish, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:34 - Error occurred for folder: Symbolic Representation two(country, city, relation, USAEnglish, English), testid: 2. See logs for details.
2025-07-28 14:41:34 - Processing folder: Symbolic Representation two(country, city, relation, USAEnglish, English), testid: 3
2025-07-28 14:41:34 - Error in generate_response: CUDA out of memory. Tried to allocate 4.41 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 32.04 GiB is allocated by PyTorch, and 1.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:34 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.41 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 32.04 GiB is allocated by PyTorch, and 1.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Symbolic Representation two(country, city, relation, USAEnglish, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:34 - Error occurred for folder: Symbolic Representation two(country, city, relation, USAEnglish, English), testid: 3. See logs for details.
2025-07-28 14:41:34 - Results exist but Error found for folder Iconic Monuments and Transit Systems in Chinese Cities two(animal, city, relation, East Asia, English)
2025-07-28 14:41:34 - Processing folder: Iconic Monuments and Transit Systems in Chinese Cities two(animal, city, relation, East Asia, English), testid: 0
2025-07-28 14:41:34 - Error in generate_response: CUDA out of memory. Tried to allocate 2.45 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.86 GiB is allocated by PyTorch, and 1.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:34 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.45 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.86 GiB is allocated by PyTorch, and 1.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Iconic Monuments and Transit Systems in Chinese Cities two(animal, city, relation, East Asia, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:34 - Error occurred for folder: Iconic Monuments and Transit Systems in Chinese Cities two(animal, city, relation, East Asia, English), testid: 0. See logs for details.
2025-07-28 14:41:34 - Processing folder: Iconic Monuments and Transit Systems in Chinese Cities two(animal, city, relation, East Asia, English), testid: 3
2025-07-28 14:41:34 - Error in generate_response: CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacity of 47.40 GiB of which 373.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.34 GiB memory in use. Of the allocated memory 33.45 GiB is allocated by PyTorch, and 1.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:34 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacity of 47.40 GiB of which 373.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.34 GiB memory in use. Of the allocated memory 33.45 GiB is allocated by PyTorch, and 1.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Iconic Monuments and Transit Systems in Chinese Cities two(animal, city, relation, East Asia, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:34 - Error occurred for folder: Iconic Monuments and Transit Systems in Chinese Cities two(animal, city, relation, East Asia, English), testid: 3. See logs for details.
2025-07-28 14:41:34 - Results exist but Error found for folder Landmarks and Their Associated Transit Systems(country, city, relation, Non-English European, English)
2025-07-28 14:41:35 - Processing folder: Landmarks and Their Associated Transit Systems(country, city, relation, Non-English European, English), testid: 0
2025-07-28 14:41:35 - Error in generate_response: CUDA out of memory. Tried to allocate 4.67 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 32.07 GiB is allocated by PyTorch, and 1.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:35 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.67 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 32.07 GiB is allocated by PyTorch, and 1.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Landmarks and Their Associated Transit Systems(country, city, relation, Non-English European, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:35 - Error occurred for folder: Landmarks and Their Associated Transit Systems(country, city, relation, Non-English European, English), testid: 0. See logs for details.
2025-07-28 14:41:35 - Processing folder: Landmarks and Their Associated Transit Systems(country, city, relation, Non-English European, English), testid: 1
2025-07-28 14:41:35 - Error in generate_response: CUDA out of memory. Tried to allocate 4.65 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 32.06 GiB is allocated by PyTorch, and 1.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:35 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.65 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 32.06 GiB is allocated by PyTorch, and 1.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Landmarks and Their Associated Transit Systems(country, city, relation, Non-English European, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:35 - Error occurred for folder: Landmarks and Their Associated Transit Systems(country, city, relation, Non-English European, English), testid: 1. See logs for details.
2025-07-28 14:41:35 - Processing folder: Landmarks and Their Associated Transit Systems(country, city, relation, Non-English European, English), testid: 2
2025-07-28 14:41:35 - Error in generate_response: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.91 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:35 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.91 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Landmarks and Their Associated Transit Systems(country, city, relation, Non-English European, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:35 - Error occurred for folder: Landmarks and Their Associated Transit Systems(country, city, relation, Non-English European, English), testid: 2. See logs for details.
2025-07-28 14:41:35 - Processing folder: Landmarks and Their Associated Transit Systems(country, city, relation, Non-English European, English), testid: 3
2025-07-28 14:41:35 - Error in generate_response: CUDA out of memory. Tried to allocate 4.62 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 32.06 GiB is allocated by PyTorch, and 1.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:35 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.62 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 32.06 GiB is allocated by PyTorch, and 1.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Landmarks and Their Associated Transit Systems(country, city, relation, Non-English European, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:35 - Error occurred for folder: Landmarks and Their Associated Transit Systems(country, city, relation, Non-English European, English), testid: 3. See logs for details.
2025-07-28 14:41:35 - Results exist but Error found for folder Landmarks and Their Associated Transit Systems two(country, city, relation, East Asia, English)
2025-07-28 14:41:35 - Processing folder: Landmarks and Their Associated Transit Systems two(country, city, relation, East Asia, English), testid: 0
2025-07-28 14:41:35 - Error in generate_response: CUDA out of memory. Tried to allocate 2.82 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.90 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:35 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.82 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.90 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Landmarks and Their Associated Transit Systems two(country, city, relation, East Asia, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:35 - Error occurred for folder: Landmarks and Their Associated Transit Systems two(country, city, relation, East Asia, English), testid: 0. See logs for details.
2025-07-28 14:41:35 - Processing folder: Landmarks and Their Associated Transit Systems two(country, city, relation, East Asia, English), testid: 1
2025-07-28 14:41:36 - Error in generate_response: CUDA out of memory. Tried to allocate 2.82 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.90 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:36 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.82 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.90 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Landmarks and Their Associated Transit Systems two(country, city, relation, East Asia, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:36 - Error occurred for folder: Landmarks and Their Associated Transit Systems two(country, city, relation, East Asia, English), testid: 1. See logs for details.
2025-07-28 14:41:36 - Processing folder: Landmarks and Their Associated Transit Systems two(country, city, relation, East Asia, English), testid: 2
2025-07-28 14:41:36 - Error in generate_response: CUDA out of memory. Tried to allocate 2.89 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.91 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:36 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.89 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.91 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Landmarks and Their Associated Transit Systems two(country, city, relation, East Asia, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:36 - Error occurred for folder: Landmarks and Their Associated Transit Systems two(country, city, relation, East Asia, English), testid: 2. See logs for details.
2025-07-28 14:41:36 - Processing folder: Landmarks and Their Associated Transit Systems two(country, city, relation, East Asia, English), testid: 3
2025-07-28 14:41:36 - Error in generate_response: CUDA out of memory. Tried to allocate 2.82 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.90 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:36 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.82 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.90 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Landmarks and Their Associated Transit Systems two(country, city, relation, East Asia, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:36 - Error occurred for folder: Landmarks and Their Associated Transit Systems two(country, city, relation, East Asia, English), testid: 3. See logs for details.
2025-07-28 14:41:36 - Results exist but Error found for folder Landmarks and Their Associated Transit Systems three(country, city, relation, Latin American, English)
2025-07-28 14:41:36 - Processing folder: Landmarks and Their Associated Transit Systems three(country, city, relation, Latin American, English), testid: 2
2025-07-28 14:41:36 - Error in generate_response: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacity of 47.40 GiB of which 297.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.42 GiB memory in use. Of the allocated memory 33.53 GiB is allocated by PyTorch, and 1.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:36 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacity of 47.40 GiB of which 297.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.42 GiB memory in use. Of the allocated memory 33.53 GiB is allocated by PyTorch, and 1.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Landmarks and Their Associated Transit Systems three(country, city, relation, Latin American, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:36 - Error occurred for folder: Landmarks and Their Associated Transit Systems three(country, city, relation, Latin American, English), testid: 2. See logs for details.
2025-07-28 14:41:36 - Processing folder: Landmarks and Their Associated Transit Systems three(country, city, relation, Latin American, English), testid: 3
2025-07-28 14:41:36 - Error in generate_response: CUDA out of memory. Tried to allocate 2.18 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.83 GiB is allocated by PyTorch, and 1.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:36 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.18 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.83 GiB is allocated by PyTorch, and 1.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Landmarks and Their Associated Transit Systems three(country, city, relation, Latin American, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:36 - Error occurred for folder: Landmarks and Their Associated Transit Systems three(country, city, relation, Latin American, English), testid: 3. See logs for details.
2025-07-28 14:41:36 - Results exist but Error found for folder Landmarks and Their Associated Transit System four(country, city, relation, Arabic-Islamic, English)
2025-07-28 14:41:36 - Processing folder: Landmarks and Their Associated Transit System four(country, city, relation, Arabic-Islamic, English), testid: 0
2025-07-28 14:41:36 - Error in generate_response: CUDA out of memory. Tried to allocate 1.50 GiB. GPU 0 has a total capacity of 47.40 GiB of which 569.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.15 GiB memory in use. Of the allocated memory 33.23 GiB is allocated by PyTorch, and 1.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:36 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.50 GiB. GPU 0 has a total capacity of 47.40 GiB of which 569.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.15 GiB memory in use. Of the allocated memory 33.23 GiB is allocated by PyTorch, and 1.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Landmarks and Their Associated Transit System four(country, city, relation, Arabic-Islamic, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:36 - Error occurred for folder: Landmarks and Their Associated Transit System four(country, city, relation, Arabic-Islamic, English), testid: 0. See logs for details.
2025-07-28 14:41:36 - Processing folder: Landmarks and Their Associated Transit System four(country, city, relation, Arabic-Islamic, English), testid: 1
2025-07-28 14:41:37 - Error in generate_response: CUDA out of memory. Tried to allocate 2.51 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.87 GiB is allocated by PyTorch, and 1.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:37 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.51 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.87 GiB is allocated by PyTorch, and 1.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Landmarks and Their Associated Transit System four(country, city, relation, Arabic-Islamic, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:37 - Error occurred for folder: Landmarks and Their Associated Transit System four(country, city, relation, Arabic-Islamic, English), testid: 1. See logs for details.
2025-07-28 14:41:37 - Processing folder: Landmarks and Their Associated Transit System four(country, city, relation, Arabic-Islamic, English), testid: 2
2025-07-28 14:41:37 - Error in generate_response: CUDA out of memory. Tried to allocate 1.50 GiB. GPU 0 has a total capacity of 47.40 GiB of which 561.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.16 GiB memory in use. Of the allocated memory 33.24 GiB is allocated by PyTorch, and 1.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:37 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.50 GiB. GPU 0 has a total capacity of 47.40 GiB of which 561.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.16 GiB memory in use. Of the allocated memory 33.24 GiB is allocated by PyTorch, and 1.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Landmarks and Their Associated Transit System four(country, city, relation, Arabic-Islamic, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:37 - Error occurred for folder: Landmarks and Their Associated Transit System four(country, city, relation, Arabic-Islamic, English), testid: 2. See logs for details.
2025-07-28 14:41:37 - Processing folder: Landmarks and Their Associated Transit System four(country, city, relation, Arabic-Islamic, English), testid: 3
2025-07-28 14:41:37 - Error in generate_response: CUDA out of memory. Tried to allocate 1.74 GiB. GPU 0 has a total capacity of 47.40 GiB of which 317.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.40 GiB memory in use. Of the allocated memory 33.51 GiB is allocated by PyTorch, and 1.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:37 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.74 GiB. GPU 0 has a total capacity of 47.40 GiB of which 317.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.40 GiB memory in use. Of the allocated memory 33.51 GiB is allocated by PyTorch, and 1.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Landmarks and Their Associated Transit System four(country, city, relation, Arabic-Islamic, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:37 - Error occurred for folder: Landmarks and Their Associated Transit System four(country, city, relation, Arabic-Islamic, English), testid: 3. See logs for details.
2025-07-28 14:41:37 - Results already exist and are complete for folder Cultural Elements of Cameroon football(animal, country, relation, other, English)
2025-07-28 14:41:37 - Results exist but Error found for folder Cultural Elements ofCameroon football(animal, country, relation, other, English)
2025-07-28 14:41:37 - Processing folder: Cultural Elements ofCameroon football(animal, country, relation, other, English), testid: 0
2025-07-28 14:41:38 - Error in generate_response: CUDA out of memory. Tried to allocate 3.35 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.95 GiB is allocated by PyTorch, and 1.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:38 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.35 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.95 GiB is allocated by PyTorch, and 1.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Elements ofCameroon football(animal, country, relation, other, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:38 - Error occurred for folder: Cultural Elements ofCameroon football(animal, country, relation, other, English), testid: 0. See logs for details.
2025-07-28 14:41:38 - Processing folder: Cultural Elements ofCameroon football(animal, country, relation, other, English), testid: 1
2025-07-28 14:41:39 - Error in generate_response: CUDA out of memory. Tried to allocate 2.24 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.84 GiB is allocated by PyTorch, and 1.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:39 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.24 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.84 GiB is allocated by PyTorch, and 1.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Elements ofCameroon football(animal, country, relation, other, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:39 - Error occurred for folder: Cultural Elements ofCameroon football(animal, country, relation, other, English), testid: 1. See logs for details.
2025-07-28 14:41:39 - Processing folder: Cultural Elements ofCameroon football(animal, country, relation, other, English), testid: 2
2025-07-28 14:41:40 - Error in generate_response: CUDA out of memory. Tried to allocate 2.28 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.84 GiB is allocated by PyTorch, and 1.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:40 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.28 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.84 GiB is allocated by PyTorch, and 1.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Elements ofCameroon football(animal, country, relation, other, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:40 - Error occurred for folder: Cultural Elements ofCameroon football(animal, country, relation, other, English), testid: 2. See logs for details.
2025-07-28 14:41:40 - Processing folder: Cultural Elements ofCameroon football(animal, country, relation, other, English), testid: 3
2025-07-28 14:41:41 - Error in generate_response: CUDA out of memory. Tried to allocate 1.83 GiB. GPU 0 has a total capacity of 47.40 GiB of which 227.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.49 GiB memory in use. Of the allocated memory 33.60 GiB is allocated by PyTorch, and 1.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:41 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.83 GiB. GPU 0 has a total capacity of 47.40 GiB of which 227.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.49 GiB memory in use. Of the allocated memory 33.60 GiB is allocated by PyTorch, and 1.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Elements ofCameroon football(animal, country, relation, other, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:41 - Error occurred for folder: Cultural Elements ofCameroon football(animal, country, relation, other, English), testid: 3. See logs for details.
2025-07-28 14:41:41 - Results exist but Error found for folder Cultural Elements of Argentina football(animal, country, relation, Latin American, English)
2025-07-28 14:41:41 - Processing folder: Cultural Elements of Argentina football(animal, country, relation, Latin American, English), testid: 0
2025-07-28 14:41:42 - Error in generate_response: CUDA out of memory. Tried to allocate 5.29 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 32.12 GiB is allocated by PyTorch, and 1.08 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:42 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 5.29 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 32.12 GiB is allocated by PyTorch, and 1.08 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Elements of Argentina football(animal, country, relation, Latin American, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:42 - Error occurred for folder: Cultural Elements of Argentina football(animal, country, relation, Latin American, English), testid: 0. See logs for details.
2025-07-28 14:41:42 - Processing folder: Cultural Elements of Argentina football(animal, country, relation, Latin American, English), testid: 1
2025-07-28 14:41:44 - Error in generate_response: CUDA out of memory. Tried to allocate 3.51 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.96 GiB is allocated by PyTorch, and 1.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:44 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.51 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.96 GiB is allocated by PyTorch, and 1.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Elements of Argentina football(animal, country, relation, Latin American, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:44 - Error occurred for folder: Cultural Elements of Argentina football(animal, country, relation, Latin American, English), testid: 1. See logs for details.
2025-07-28 14:41:44 - Processing folder: Cultural Elements of Argentina football(animal, country, relation, Latin American, English), testid: 2
2025-07-28 14:41:45 - Error in generate_response: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 32.02 GiB is allocated by PyTorch, and 1.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:45 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 32.02 GiB is allocated by PyTorch, and 1.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Elements of Argentina football(animal, country, relation, Latin American, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:45 - Error occurred for folder: Cultural Elements of Argentina football(animal, country, relation, Latin American, English), testid: 2. See logs for details.
2025-07-28 14:41:45 - Processing folder: Cultural Elements of Argentina football(animal, country, relation, Latin American, English), testid: 3
2025-07-28 14:41:46 - Error in generate_response: CUDA out of memory. Tried to allocate 2.41 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.86 GiB is allocated by PyTorch, and 1.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:46 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.41 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.86 GiB is allocated by PyTorch, and 1.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Elements of Argentina football(animal, country, relation, Latin American, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:46 - Error occurred for folder: Cultural Elements of Argentina football(animal, country, relation, Latin American, English), testid: 3. See logs for details.
2025-07-28 14:41:46 - Results exist but Error found for folder Cultural Elements of Latin footballmap(animal, country, relation, Latin American, English)
2025-07-28 14:41:46 - Processing folder: Cultural Elements of Latin footballmap(animal, country, relation, Latin American, English), testid: 2
2025-07-28 14:41:47 - Error in generate_response: CUDA out of memory. Tried to allocate 1.89 GiB. GPU 0 has a total capacity of 47.40 GiB of which 165.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.55 GiB memory in use. Of the allocated memory 33.67 GiB is allocated by PyTorch, and 1.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:47 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.89 GiB. GPU 0 has a total capacity of 47.40 GiB of which 165.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.55 GiB memory in use. Of the allocated memory 33.67 GiB is allocated by PyTorch, and 1.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Elements of Latin footballmap(animal, country, relation, Latin American, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:47 - Error occurred for folder: Cultural Elements of Latin footballmap(animal, country, relation, Latin American, English), testid: 2. See logs for details.
2025-07-28 14:41:47 - Processing folder: Cultural Elements of Latin footballmap(animal, country, relation, Latin American, English), testid: 3
2025-07-28 14:41:48 - Error in generate_response: CUDA out of memory. Tried to allocate 1.61 GiB. GPU 0 has a total capacity of 47.40 GiB of which 165.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.55 GiB memory in use. Of the allocated memory 33.36 GiB is allocated by PyTorch, and 1.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:48 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.61 GiB. GPU 0 has a total capacity of 47.40 GiB of which 165.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.55 GiB memory in use. Of the allocated memory 33.36 GiB is allocated by PyTorch, and 1.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Elements of Latin footballmap(animal, country, relation, Latin American, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:48 - Error occurred for folder: Cultural Elements of Latin footballmap(animal, country, relation, Latin American, English), testid: 3. See logs for details.
2025-07-28 14:41:48 - Results exist but Error found for folder Cultural Elements of Latin football(animal, country, relation, Latin American, English)
2025-07-28 14:41:48 - Processing folder: Cultural Elements of Latin football(animal, country, relation, Latin American, English), testid: 0
2025-07-28 14:41:49 - Error in generate_response: CUDA out of memory. Tried to allocate 2.59 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.88 GiB is allocated by PyTorch, and 1.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:49 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.59 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.88 GiB is allocated by PyTorch, and 1.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Elements of Latin football(animal, country, relation, Latin American, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:49 - Error occurred for folder: Cultural Elements of Latin football(animal, country, relation, Latin American, English), testid: 0. See logs for details.
2025-07-28 14:41:49 - Processing folder: Cultural Elements of Latin football(animal, country, relation, Latin American, English), testid: 1
2025-07-28 14:41:49 - Error in generate_response: CUDA out of memory. Tried to allocate 2.87 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.90 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:49 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.87 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.90 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Elements of Latin football(animal, country, relation, Latin American, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:49 - Error occurred for folder: Cultural Elements of Latin football(animal, country, relation, Latin American, English), testid: 1. See logs for details.
2025-07-28 14:41:49 - Processing folder: Cultural Elements of Latin football(animal, country, relation, Latin American, English), testid: 2
2025-07-28 14:41:50 - Error in generate_response: CUDA out of memory. Tried to allocate 2.28 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.84 GiB is allocated by PyTorch, and 1.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:50 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.28 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.84 GiB is allocated by PyTorch, and 1.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Elements of Latin football(animal, country, relation, Latin American, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:50 - Error occurred for folder: Cultural Elements of Latin football(animal, country, relation, Latin American, English), testid: 2. See logs for details.
2025-07-28 14:41:50 - Results exist but Error found for folder Cultural Elements of city football(animal, city, relation, Non-English European, English)
2025-07-28 14:41:50 - Processing folder: Cultural Elements of city football(animal, city, relation, Non-English European, English), testid: 0
2025-07-28 14:41:51 - Error in generate_response: CUDA out of memory. Tried to allocate 2.82 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.90 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:51 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.82 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.90 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Elements of city football(animal, city, relation, Non-English European, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:51 - Error occurred for folder: Cultural Elements of city football(animal, city, relation, Non-English European, English), testid: 0. See logs for details.
2025-07-28 14:41:51 - Processing folder: Cultural Elements of city football(animal, city, relation, Non-English European, English), testid: 1
2025-07-28 14:41:51 - Error in generate_response: CUDA out of memory. Tried to allocate 1.89 GiB. GPU 0 has a total capacity of 47.40 GiB of which 169.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.54 GiB memory in use. Of the allocated memory 33.67 GiB is allocated by PyTorch, and 1.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:51 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.89 GiB. GPU 0 has a total capacity of 47.40 GiB of which 169.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.54 GiB memory in use. Of the allocated memory 33.67 GiB is allocated by PyTorch, and 1.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Elements of city football(animal, city, relation, Non-English European, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:51 - Error occurred for folder: Cultural Elements of city football(animal, city, relation, Non-English European, English), testid: 1. See logs for details.
2025-07-28 14:41:51 - Processing folder: Cultural Elements of city football(animal, city, relation, Non-English European, English), testid: 2
2025-07-28 14:41:51 - Error in generate_response: CUDA out of memory. Tried to allocate 1.87 GiB. GPU 0 has a total capacity of 47.40 GiB of which 169.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.54 GiB memory in use. Of the allocated memory 33.64 GiB is allocated by PyTorch, and 1.45 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:51 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.87 GiB. GPU 0 has a total capacity of 47.40 GiB of which 169.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.54 GiB memory in use. Of the allocated memory 33.64 GiB is allocated by PyTorch, and 1.45 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Elements of city football(animal, city, relation, Non-English European, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:51 - Error occurred for folder: Cultural Elements of city football(animal, city, relation, Non-English European, English), testid: 2. See logs for details.
2025-07-28 14:41:51 - Processing folder: Cultural Elements of city football(animal, city, relation, Non-English European, English), testid: 3
2025-07-28 14:41:52 - Error in generate_response: CUDA out of memory. Tried to allocate 1.86 GiB. GPU 0 has a total capacity of 47.40 GiB of which 169.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.54 GiB memory in use. Of the allocated memory 33.64 GiB is allocated by PyTorch, and 1.45 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:52 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.86 GiB. GPU 0 has a total capacity of 47.40 GiB of which 169.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.54 GiB memory in use. Of the allocated memory 33.64 GiB is allocated by PyTorch, and 1.45 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Elements of city football(animal, city, relation, Non-English European, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:52 - Error occurred for folder: Cultural Elements of city football(animal, city, relation, Non-English European, English), testid: 3. See logs for details.
2025-07-28 14:41:52 - Results exist but Error found for folder Cultural Elements of city football2(animal, city, relation, Non-English European, English)
2025-07-28 14:41:52 - Processing folder: Cultural Elements of city football2(animal, city, relation, Non-English European, English), testid: 0
2025-07-28 14:41:52 - Error in generate_response: CUDA out of memory. Tried to allocate 4.50 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 32.05 GiB is allocated by PyTorch, and 1.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:52 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.50 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 32.05 GiB is allocated by PyTorch, and 1.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Elements of city football2(animal, city, relation, Non-English European, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:52 - Error occurred for folder: Cultural Elements of city football2(animal, city, relation, Non-English European, English), testid: 0. See logs for details.
2025-07-28 14:41:52 - Processing folder: Cultural Elements of city football2(animal, city, relation, Non-English European, English), testid: 1
2025-07-28 14:41:52 - Error in generate_response: CUDA out of memory. Tried to allocate 3.47 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.96 GiB is allocated by PyTorch, and 1.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:52 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.47 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.96 GiB is allocated by PyTorch, and 1.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Elements of city football2(animal, city, relation, Non-English European, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:52 - Error occurred for folder: Cultural Elements of city football2(animal, city, relation, Non-English European, English), testid: 1. See logs for details.
2025-07-28 14:41:52 - Processing folder: Cultural Elements of city football2(animal, city, relation, Non-English European, English), testid: 2
2025-07-28 14:41:52 - Error in generate_response: CUDA out of memory. Tried to allocate 4.50 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 32.05 GiB is allocated by PyTorch, and 1.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:52 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.50 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 32.05 GiB is allocated by PyTorch, and 1.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Elements of city football2(animal, city, relation, Non-English European, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:52 - Error occurred for folder: Cultural Elements of city football2(animal, city, relation, Non-English European, English), testid: 2. See logs for details.
2025-07-28 14:41:52 - Processing folder: Cultural Elements of city football2(animal, city, relation, Non-English European, English), testid: 3
2025-07-28 14:41:52 - Error in generate_response: CUDA out of memory. Tried to allocate 3.79 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.99 GiB is allocated by PyTorch, and 1.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:52 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.79 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.99 GiB is allocated by PyTorch, and 1.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Elements of city football2(animal, city, relation, Non-English European, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:52 - Error occurred for folder: Cultural Elements of city football2(animal, city, relation, Non-English European, English), testid: 3. See logs for details.
2025-07-28 14:41:52 - Results already exist and are complete for folder Culture and Sports(animal, country, relation, East Asia, English)
2025-07-28 14:41:52 - Results exist but Error found for folder Culture and Sports two(animal, country, relation, East Asia, English)
2025-07-28 14:41:52 - Processing folder: Culture and Sports two(animal, country, relation, East Asia, English), testid: 1
2025-07-28 14:41:52 - Error in generate_response: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 47.40 GiB of which 109.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.60 GiB memory in use. Of the allocated memory 33.73 GiB is allocated by PyTorch, and 1.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:52 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 47.40 GiB of which 109.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.60 GiB memory in use. Of the allocated memory 33.73 GiB is allocated by PyTorch, and 1.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Culture and Sports two(animal, country, relation, East Asia, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:52 - Error occurred for folder: Culture and Sports two(animal, country, relation, East Asia, English), testid: 1. See logs for details.
2025-07-28 14:41:52 - Processing folder: Culture and Sports two(animal, country, relation, East Asia, English), testid: 2
2025-07-28 14:41:53 - Error in generate_response: CUDA out of memory. Tried to allocate 2.09 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.82 GiB is allocated by PyTorch, and 1.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:53 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.09 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.82 GiB is allocated by PyTorch, and 1.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Culture and Sports two(animal, country, relation, East Asia, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:53 - Error occurred for folder: Culture and Sports two(animal, country, relation, East Asia, English), testid: 2. See logs for details.
2025-07-28 14:41:53 - Processing folder: Culture and Sports two(animal, country, relation, East Asia, English), testid: 3
2025-07-28 14:41:53 - Error in generate_response: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacity of 47.40 GiB of which 61.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.65 GiB memory in use. Of the allocated memory 33.78 GiB is allocated by PyTorch, and 1.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:53 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacity of 47.40 GiB of which 61.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.65 GiB memory in use. Of the allocated memory 33.78 GiB is allocated by PyTorch, and 1.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Culture and Sports two(animal, country, relation, East Asia, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:53 - Error occurred for folder: Culture and Sports two(animal, country, relation, East Asia, English), testid: 3. See logs for details.
2025-07-28 14:41:53 - Results exist but Error found for folder Symbols(country, animal, relation, Latin American, English)
2025-07-28 14:41:53 - Processing folder: Symbols(country, animal, relation, Latin American, English), testid: 0
2025-07-28 14:41:53 - Error in generate_response: CUDA out of memory. Tried to allocate 2.51 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.87 GiB is allocated by PyTorch, and 1.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:53 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.51 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.87 GiB is allocated by PyTorch, and 1.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Symbols(country, animal, relation, Latin American, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:53 - Error occurred for folder: Symbols(country, animal, relation, Latin American, English), testid: 0. See logs for details.
2025-07-28 14:41:53 - Processing folder: Symbols(country, animal, relation, Latin American, English), testid: 1
2025-07-28 14:41:53 - Error in generate_response: CUDA out of memory. Tried to allocate 2.49 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.87 GiB is allocated by PyTorch, and 1.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:53 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.49 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.87 GiB is allocated by PyTorch, and 1.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Symbols(country, animal, relation, Latin American, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:53 - Error occurred for folder: Symbols(country, animal, relation, Latin American, English), testid: 1. See logs for details.
2025-07-28 14:41:53 - Processing folder: Symbols(country, animal, relation, Latin American, English), testid: 2
2025-07-28 14:41:53 - Error in generate_response: CUDA out of memory. Tried to allocate 1.83 GiB. GPU 0 has a total capacity of 47.40 GiB of which 225.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.49 GiB memory in use. Of the allocated memory 33.61 GiB is allocated by PyTorch, and 1.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:53 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.83 GiB. GPU 0 has a total capacity of 47.40 GiB of which 225.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.49 GiB memory in use. Of the allocated memory 33.61 GiB is allocated by PyTorch, and 1.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Symbols(country, animal, relation, Latin American, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:53 - Error occurred for folder: Symbols(country, animal, relation, Latin American, English), testid: 2. See logs for details.
2025-07-28 14:41:53 - Processing folder: Symbols(country, animal, relation, Latin American, English), testid: 3
2025-07-28 14:41:54 - Error in generate_response: CUDA out of memory. Tried to allocate 3.84 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.99 GiB is allocated by PyTorch, and 1.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:54 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.84 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.99 GiB is allocated by PyTorch, and 1.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Symbols(country, animal, relation, Latin American, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:54 - Error occurred for folder: Symbols(country, animal, relation, Latin American, English), testid: 3. See logs for details.
2025-07-28 14:41:54 - Results exist but Error found for folder Famous Symbols(city, animal, relation, USAEnglish, English)
2025-07-28 14:41:54 - Processing folder: Famous Symbols(city, animal, relation, USAEnglish, English), testid: 0
2025-07-28 14:41:54 - Error in generate_response: CUDA out of memory. Tried to allocate 1.80 GiB. GPU 0 has a total capacity of 47.40 GiB of which 259.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.46 GiB memory in use. Of the allocated memory 33.57 GiB is allocated by PyTorch, and 1.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:54 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.80 GiB. GPU 0 has a total capacity of 47.40 GiB of which 259.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.46 GiB memory in use. Of the allocated memory 33.57 GiB is allocated by PyTorch, and 1.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Famous Symbols(city, animal, relation, USAEnglish, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:54 - Error occurred for folder: Famous Symbols(city, animal, relation, USAEnglish, English), testid: 0. See logs for details.
2025-07-28 14:41:54 - Processing folder: Famous Symbols(city, animal, relation, USAEnglish, English), testid: 1
2025-07-28 14:41:54 - Error in generate_response: CUDA out of memory. Tried to allocate 1.85 GiB. GPU 0 has a total capacity of 47.40 GiB of which 211.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.50 GiB memory in use. Of the allocated memory 33.62 GiB is allocated by PyTorch, and 1.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:54 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.85 GiB. GPU 0 has a total capacity of 47.40 GiB of which 211.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.50 GiB memory in use. Of the allocated memory 33.62 GiB is allocated by PyTorch, and 1.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Famous Symbols(city, animal, relation, USAEnglish, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:54 - Error occurred for folder: Famous Symbols(city, animal, relation, USAEnglish, English), testid: 1. See logs for details.
2025-07-28 14:41:54 - Processing folder: Famous Symbols(city, animal, relation, USAEnglish, English), testid: 2
2025-07-28 14:41:54 - Error in generate_response: CUDA out of memory. Tried to allocate 1.85 GiB. GPU 0 has a total capacity of 47.40 GiB of which 211.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.50 GiB memory in use. Of the allocated memory 33.62 GiB is allocated by PyTorch, and 1.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:54 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.85 GiB. GPU 0 has a total capacity of 47.40 GiB of which 211.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.50 GiB memory in use. Of the allocated memory 33.62 GiB is allocated by PyTorch, and 1.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Famous Symbols(city, animal, relation, USAEnglish, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:54 - Error occurred for folder: Famous Symbols(city, animal, relation, USAEnglish, English), testid: 2. See logs for details.
2025-07-28 14:41:54 - Processing folder: Famous Symbols(city, animal, relation, USAEnglish, English), testid: 3
2025-07-28 14:41:54 - Error in generate_response: CUDA out of memory. Tried to allocate 2.91 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.91 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:54 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.91 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.91 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Famous Symbols(city, animal, relation, USAEnglish, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:54 - Error occurred for folder: Famous Symbols(city, animal, relation, USAEnglish, English), testid: 3. See logs for details.
2025-07-28 14:41:54 - Results already exist and are complete for folder Famous Symbols of cat(city, animal, relation, USAEnglish, English)
2025-07-28 14:41:54 - Results exist but Error found for folder Cultural Elements of football(animal, country, relation, Non-English European, English)
2025-07-28 14:41:54 - Processing folder: Cultural Elements of football(animal, country, relation, Non-English European, English), testid: 0
2025-07-28 14:41:54 - Error in generate_response: CUDA out of memory. Tried to allocate 3.86 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 1.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:54 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.86 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 1.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Elements of football(animal, country, relation, Non-English European, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:54 - Error occurred for folder: Cultural Elements of football(animal, country, relation, Non-English European, English), testid: 0. See logs for details.
2025-07-28 14:41:54 - Processing folder: Cultural Elements of football(animal, country, relation, Non-English European, English), testid: 1
2025-07-28 14:41:54 - Error in generate_response: CUDA out of memory. Tried to allocate 2.24 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.84 GiB is allocated by PyTorch, and 1.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:54 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.24 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.84 GiB is allocated by PyTorch, and 1.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Elements of football(animal, country, relation, Non-English European, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:54 - Error occurred for folder: Cultural Elements of football(animal, country, relation, Non-English European, English), testid: 1. See logs for details.
2025-07-28 14:41:54 - Processing folder: Cultural Elements of football(animal, country, relation, Non-English European, English), testid: 2
2025-07-28 14:41:55 - Error in generate_response: CUDA out of memory. Tried to allocate 4.87 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 32.08 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:55 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.87 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 32.08 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Elements of football(animal, country, relation, Non-English European, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:55 - Error occurred for folder: Cultural Elements of football(animal, country, relation, Non-English European, English), testid: 2. See logs for details.
2025-07-28 14:41:55 - Processing folder: Cultural Elements of football(animal, country, relation, Non-English European, English), testid: 3
2025-07-28 14:41:55 - Error in generate_response: CUDA out of memory. Tried to allocate 3.94 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 1.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:55 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.94 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 1.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Elements of football(animal, country, relation, Non-English European, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:55 - Error occurred for folder: Cultural Elements of football(animal, country, relation, Non-English European, English), testid: 3. See logs for details.
2025-07-28 14:41:55 - Results already exist and are complete for folder Cultural Elements of Spanish football(animal, country, relation, Non-English European, English)
2025-07-28 14:41:55 - Results exist but Error found for folder Cultural Elements of Korean football(animal, country, relation, East Asia, English)
2025-07-28 14:41:55 - Processing folder: Cultural Elements of Korean football(animal, country, relation, East Asia, English), testid: 2
2025-07-28 14:41:55 - Error in generate_response: CUDA out of memory. Tried to allocate 2.13 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.83 GiB is allocated by PyTorch, and 1.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:55 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.13 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.83 GiB is allocated by PyTorch, and 1.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Elements of Korean football(animal, country, relation, East Asia, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:55 - Error occurred for folder: Cultural Elements of Korean football(animal, country, relation, East Asia, English), testid: 2. See logs for details.
2025-07-28 14:41:55 - Processing folder: Cultural Elements of Korean football(animal, country, relation, East Asia, English), testid: 3
2025-07-28 14:41:55 - Error in generate_response: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 47.40 GiB of which 109.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.60 GiB memory in use. Of the allocated memory 33.73 GiB is allocated by PyTorch, and 1.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:55 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 47.40 GiB of which 109.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.60 GiB memory in use. Of the allocated memory 33.73 GiB is allocated by PyTorch, and 1.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Elements of Korean football(animal, country, relation, East Asia, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:55 - Error occurred for folder: Cultural Elements of Korean football(animal, country, relation, East Asia, English), testid: 3. See logs for details.
2025-07-28 14:41:55 - Results exist but Error found for folder Symbols of horse(city, animal, relation, Non-English European, English)
2025-07-28 14:41:55 - Processing folder: Symbols of horse(city, animal, relation, Non-English European, English), testid: 0
2025-07-28 14:41:55 - Error in generate_response: CUDA out of memory. Tried to allocate 1.96 GiB. GPU 0 has a total capacity of 47.40 GiB of which 89.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.62 GiB memory in use. Of the allocated memory 33.75 GiB is allocated by PyTorch, and 1.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:55 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.96 GiB. GPU 0 has a total capacity of 47.40 GiB of which 89.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.62 GiB memory in use. Of the allocated memory 33.75 GiB is allocated by PyTorch, and 1.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Symbols of horse(city, animal, relation, Non-English European, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:55 - Error occurred for folder: Symbols of horse(city, animal, relation, Non-English European, English), testid: 0. See logs for details.
2025-07-28 14:41:55 - Processing folder: Symbols of horse(city, animal, relation, Non-English European, English), testid: 1
2025-07-28 14:41:56 - Error in generate_response: CUDA out of memory. Tried to allocate 1.96 GiB. GPU 0 has a total capacity of 47.40 GiB of which 89.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.62 GiB memory in use. Of the allocated memory 33.74 GiB is allocated by PyTorch, and 1.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:56 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.96 GiB. GPU 0 has a total capacity of 47.40 GiB of which 89.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.62 GiB memory in use. Of the allocated memory 33.74 GiB is allocated by PyTorch, and 1.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Symbols of horse(city, animal, relation, Non-English European, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:56 - Error occurred for folder: Symbols of horse(city, animal, relation, Non-English European, English), testid: 1. See logs for details.
2025-07-28 14:41:56 - Processing folder: Symbols of horse(city, animal, relation, Non-English European, English), testid: 2
2025-07-28 14:41:56 - Error in generate_response: CUDA out of memory. Tried to allocate 2.80 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.90 GiB is allocated by PyTorch, and 1.31 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:56 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.80 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.90 GiB is allocated by PyTorch, and 1.31 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Symbols of horse(city, animal, relation, Non-English European, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:56 - Error occurred for folder: Symbols of horse(city, animal, relation, Non-English European, English), testid: 2. See logs for details.
2025-07-28 14:41:56 - Processing folder: Symbols of horse(city, animal, relation, Non-English European, English), testid: 3
2025-07-28 14:41:56 - Error in generate_response: CUDA out of memory. Tried to allocate 1.94 GiB. GPU 0 has a total capacity of 47.40 GiB of which 115.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.60 GiB memory in use. Of the allocated memory 33.73 GiB is allocated by PyTorch, and 1.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:56 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.94 GiB. GPU 0 has a total capacity of 47.40 GiB of which 115.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.60 GiB memory in use. Of the allocated memory 33.73 GiB is allocated by PyTorch, and 1.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Symbols of horse(city, animal, relation, Non-English European, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:56 - Error occurred for folder: Symbols of horse(city, animal, relation, Non-English European, English), testid: 3. See logs for details.
2025-07-28 14:41:56 - Results exist but Error found for folder Symbols ofhorse(city, animal, relation, Non-English European, English)
2025-07-28 14:41:56 - Processing folder: Symbols ofhorse(city, animal, relation, Non-English European, English), testid: 1
2025-07-28 14:41:56 - Error in generate_response: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacity of 47.40 GiB of which 15.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.69 GiB memory in use. Of the allocated memory 33.83 GiB is allocated by PyTorch, and 1.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:56 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacity of 47.40 GiB of which 15.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.69 GiB memory in use. Of the allocated memory 33.83 GiB is allocated by PyTorch, and 1.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Symbols ofhorse(city, animal, relation, Non-English European, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:56 - Error occurred for folder: Symbols ofhorse(city, animal, relation, Non-English European, English), testid: 1. See logs for details.
2025-07-28 14:41:56 - Processing folder: Symbols ofhorse(city, animal, relation, Non-English European, English), testid: 2
2025-07-28 14:41:56 - Error in generate_response: CUDA out of memory. Tried to allocate 1.81 GiB. GPU 0 has a total capacity of 47.40 GiB of which 15.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.69 GiB memory in use. Of the allocated memory 33.58 GiB is allocated by PyTorch, and 1.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:56 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.81 GiB. GPU 0 has a total capacity of 47.40 GiB of which 15.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.69 GiB memory in use. Of the allocated memory 33.58 GiB is allocated by PyTorch, and 1.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Symbols ofhorse(city, animal, relation, Non-English European, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:56 - Error occurred for folder: Symbols ofhorse(city, animal, relation, Non-English European, English), testid: 2. See logs for details.
2025-07-28 14:41:56 - Results exist but Error found for folder Symbolsofhorse(city, animal, relation, Non-English European, English)
2025-07-28 14:41:56 - Processing folder: Symbolsofhorse(city, animal, relation, Non-English European, English), testid: 0
2025-07-28 14:41:56 - Error in generate_response: CUDA out of memory. Tried to allocate 2.88 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.90 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:56 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.88 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.90 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Symbolsofhorse(city, animal, relation, Non-English European, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:56 - Error occurred for folder: Symbolsofhorse(city, animal, relation, Non-English European, English), testid: 0. See logs for details.
2025-07-28 14:41:56 - Processing folder: Symbolsofhorse(city, animal, relation, Non-English European, English), testid: 1
2025-07-28 14:41:57 - Error in generate_response: CUDA out of memory. Tried to allocate 2.88 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.90 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:57 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.88 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.90 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Symbolsofhorse(city, animal, relation, Non-English European, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:57 - Error occurred for folder: Symbolsofhorse(city, animal, relation, Non-English European, English), testid: 1. See logs for details.
2025-07-28 14:41:57 - Processing folder: Symbolsofhorse(city, animal, relation, Non-English European, English), testid: 2
2025-07-28 14:41:57 - Error in generate_response: CUDA out of memory. Tried to allocate 2.88 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.90 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:57 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.88 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.90 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Symbolsofhorse(city, animal, relation, Non-English European, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:57 - Error occurred for folder: Symbolsofhorse(city, animal, relation, Non-English European, English), testid: 2. See logs for details.
2025-07-28 14:41:57 - Processing folder: Symbolsofhorse(city, animal, relation, Non-English European, English), testid: 3
2025-07-28 14:41:57 - Error in generate_response: CUDA out of memory. Tried to allocate 2.97 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.91 GiB is allocated by PyTorch, and 1.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:57 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.97 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.91 GiB is allocated by PyTorch, and 1.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Symbolsofhorse(city, animal, relation, Non-English European, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:57 - Error occurred for folder: Symbolsofhorse(city, animal, relation, Non-English European, English), testid: 3. See logs for details.
2025-07-28 14:41:57 - Results already exist and are complete for folder Cultural Elements of Koreanfootball(animal, country, relation, East Asia, English)
2025-07-28 14:41:57 - Results exist but Error found for folder Cultural Elements of Australianfootball(animal, country, relation, other, English)
2025-07-28 14:41:57 - Processing folder: Cultural Elements of Australianfootball(animal, country, relation, other, English), testid: 0
2025-07-28 14:41:57 - Error in generate_response: CUDA out of memory. Tried to allocate 1.45 GiB. GPU 0 has a total capacity of 47.40 GiB of which 613.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.11 GiB memory in use. Of the allocated memory 33.19 GiB is allocated by PyTorch, and 1.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:57 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.45 GiB. GPU 0 has a total capacity of 47.40 GiB of which 613.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.11 GiB memory in use. Of the allocated memory 33.19 GiB is allocated by PyTorch, and 1.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Elements of Australianfootball(animal, country, relation, other, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:57 - Error occurred for folder: Cultural Elements of Australianfootball(animal, country, relation, other, English), testid: 0. See logs for details.
2025-07-28 14:41:57 - Processing folder: Cultural Elements of Australianfootball(animal, country, relation, other, English), testid: 3
2025-07-28 14:41:57 - Error in generate_response: CUDA out of memory. Tried to allocate 1.54 GiB. GPU 0 has a total capacity of 47.40 GiB of which 529.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.19 GiB memory in use. Of the allocated memory 33.28 GiB is allocated by PyTorch, and 1.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:57 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.54 GiB. GPU 0 has a total capacity of 47.40 GiB of which 529.12 MiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 35.19 GiB memory in use. Of the allocated memory 33.28 GiB is allocated by PyTorch, and 1.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Elements of Australianfootball(animal, country, relation, other, English)
TestID: 3
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:57 - Error occurred for folder: Cultural Elements of Australianfootball(animal, country, relation, other, English), testid: 3. See logs for details.
2025-07-28 14:41:57 - Results exist but Error found for folder Cultural Elements of Nigeriafootball(animal, country, relation, other, English)
2025-07-28 14:41:57 - Processing folder: Cultural Elements of Nigeriafootball(animal, country, relation, other, English), testid: 0
2025-07-28 14:41:57 - Error in generate_response: CUDA out of memory. Tried to allocate 2.11 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.83 GiB is allocated by PyTorch, and 1.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:57 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.11 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.83 GiB is allocated by PyTorch, and 1.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Elements of Nigeriafootball(animal, country, relation, other, English)
TestID: 0
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:57 - Error occurred for folder: Cultural Elements of Nigeriafootball(animal, country, relation, other, English), testid: 0. See logs for details.
2025-07-28 14:41:57 - Processing folder: Cultural Elements of Nigeriafootball(animal, country, relation, other, English), testid: 1
2025-07-28 14:41:58 - Error in generate_response: CUDA out of memory. Tried to allocate 2.31 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.85 GiB is allocated by PyTorch, and 1.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:58 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.31 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.85 GiB is allocated by PyTorch, and 1.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Elements of Nigeriafootball(animal, country, relation, other, English)
TestID: 1
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:58 - Error occurred for folder: Cultural Elements of Nigeriafootball(animal, country, relation, other, English), testid: 1. See logs for details.
2025-07-28 14:41:58 - Processing folder: Cultural Elements of Nigeriafootball(animal, country, relation, other, English), testid: 2
2025-07-28 14:41:58 - Error in generate_response: CUDA out of memory. Tried to allocate 2.31 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.85 GiB is allocated by PyTorch, and 1.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-28 14:41:58 - Traceback (most recent call last):
  File "/mnt/SSD_4TB/jusheng/mmopera/Incontext_Images/wjl/2.py", line 137, in generate_response
    generated_ids = model.generate(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2594, in forward
    image_features: torch.Tensor = self._extract_image_features(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2535, in _extract_image_features
    image_features: list[torch.Tensor] = self.vision_tower(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 2368, in forward
    hidden_states = self.encoder(hidden_states, grid_hws)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 551, in forward
    hidden_states = block(
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jusheng/anaconda3/envs/mmopera/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 508, in forward
    attn_out = self.attention_qkvpacked(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 486, in attention_qkvpacked
    attn_out = attn_func(
  File "/home/jusheng/.cache/huggingface/modules/transformers_modules/moonshotai/Kimi-VL-A3B-Instruct/cc6452511d00c99f3b3bed213e96ab7802c415c8/modeling_kimi_vl.py", line 172, in sdpa_attention
    attn_output = F.scaled_dot_product_attention(q, k, v, attention_mask, dropout_p=0.0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.31 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Process 3582107 has 940.00 MiB memory in use. Process 3582190 has 940.00 MiB memory in use. Process 3582109 has 780.00 MiB memory in use. Process 2906600 has 4.83 GiB memory in use. Process 2915086 has 4.23 GiB memory in use. Including non-PyTorch memory, this process has 33.66 GiB memory in use. Of the allocated memory 31.85 GiB is allocated by PyTorch, and 1.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Folder: Cultural Elements of Nigeriafootball(animal, country, relation, other, English)
TestID: 2
{
    "response": "Error: response generation failed"
}

2025-07-28 14:41:58 - Error occurred for folder: Cultural Elements of Nigeriafootball(animal, country, relation, other, English), testid: 2. See logs for details.
2025-07-28 14:41:58 - Processing complete. Results saved to ./moonshotai/result_moonshotai_Kimi-VL-A3B-Instruct.json
